{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKLZCsggWxBs",
        "outputId": "94a7355a-d03c-41ba-87cb-0a45cbcb3c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchextractor\n",
            "  Downloading torchextractor-0.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchextractor) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchextractor) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->torchextractor) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->torchextractor) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->torchextractor) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->torchextractor) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->torchextractor) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->torchextractor) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4.0->torchextractor)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->torchextractor) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->torchextractor)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->torchextractor) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->torchextractor) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchextractor\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torchextractor-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchextractor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from os.path import join as oj\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import TensorDataset, ConcatDataset\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from numpy.random import randint\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import copy\n",
        "import gc\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "jxkdE71HXvdI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC2BZL5vX0Zf",
        "outputId": "1fdb1404-82ee-4e24-cf54-f2215cccbeab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = oj(dir_path, \"models\", \"initial_classifier\")\n",
        "model_training_path = oj(model_path, \"training_224\")\n",
        "data_path = oj(dir_path, \"data\")\n",
        "\n",
        "not_waterbird_path = oj(data_path, \"processed\", \"no_waterbird_224\")\n",
        "waterbird_path = oj(data_path, \"processed\", \"waterbird_224\")"
      ],
      "metadata": {
        "id": "nzTBjMXCX5nY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "mean = np.asarray([0.485, 0.456, 0.406])\n",
        "std = np.asarray([0.229, 0.224, 0.225])\n",
        "\n",
        "# Define arguments\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.batch_size = 16\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.00001\n",
        "        self.momentum = 0.9\n",
        "        self.seed = 42\n",
        "        self.regularizer_rate = 0.0\n",
        "\n",
        "args = Args()\n",
        "\n",
        "regularizer_rate = args.regularizer_rate\n",
        "num_epochs = args.epochs\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the classifier (replace the last fully connected layer) it is called fc for resnet18\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.to(device)\n",
        "params_to_update = model.fc.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqd7jg-jYLxY",
        "outputId": "ca452b1b-80a5-4d49-e4b4-7f58dd167a34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 123MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_up_empty_files(path):\n",
        "    list_files= os.listdir(path)\n",
        "    num_files = len(list_files)\n",
        "    for i in tqdm(range(num_files)):\n",
        "        if os.path.getsize(oj(path, list_files[i])) < 100:\n",
        "            os.remove(oj(path, list_files[i]))\n",
        "            print(\"File \" + str(i) + \"deleted!\")\n",
        "'''\n",
        "def clean_up_duplicates(path1, path2):\n",
        "    newfiles = os.listdir(path1)\n",
        "    oldfiles = os.listdir(path2)\n",
        "    diff = [f for f in newfiles if f not in oldfiles]\n",
        "    for i in tqdm(diff):\n",
        "        os.remove(oj(path1, i))\n",
        "        print(\"File \" + str(i) + \"deleted!\")\n",
        "\n",
        "def check_img_sizes(path):\n",
        "    list_files= os.listdir(path)\n",
        "    num_files = len(list_files)\n",
        "    for i in tqdm(range(num_files)):\n",
        "        im = Image.open(oj(path, list_files[i]))\n",
        "        if im.width != 224 or im.height != 224:\n",
        "            print(list_files[i])\n",
        "'''\n",
        "# clean_up_empty_files(cancer_path)\n",
        "# clean_up_empty_files(not_cancer_path)\n",
        "\n",
        "# newpath = oj(data_path, \"no_cancer_224_inpainted\")\n",
        "# oldpath = oj(data_path, \"processed\", \"no_cancer_224\")\n",
        "# clean_up_duplicates(newpath, oldpath)\n",
        "\n",
        "# check_img_sizes(not_cancer_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Wb0yOBCxYRJx",
        "outputId": "87ae3e2c-a0a9-444f-ef3c-718ef3266fe3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef clean_up_duplicates(path1, path2):\\n    newfiles = os.listdir(path1)\\n    oldfiles = os.listdir(path2)\\n    diff = [f for f in newfiles if f not in oldfiles]\\n    for i in tqdm(diff):\\n        os.remove(oj(path1, i))\\n        print(\"File \" + str(i) + \"deleted!\")\\n\\ndef check_img_sizes(path):\\n    list_files= os.listdir(path)\\n    num_files = len(list_files)\\n    for i in tqdm(range(num_files)):\\n        im = Image.open(oj(path, list_files[i]))\\n        if im.width != 224 or im.height != 224:\\n            print(list_files[i])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WaterbirdDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path: str = None, is_waterbird: int = None, data_files = None, labels = None):\n",
        "        \"\"\"\n",
        "        Expects path and is_waterbird both to be supplied if the relevant images all lie in the same directory and have the same class\n",
        "        or a list of full filepaths and list of all labels are both supplied using data_files and labels otherwise.\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Initializes the WaterbirdDataset.\n",
        "\n",
        "        If 'path' and 'is_waterbird' are provided, it assumes that all images in the directory specified\n",
        "        by 'path' belong to the same class 'is_waterbird'.\n",
        "\n",
        "        Alternatively, if 'data_files' and 'labels' are provided, it uses these lists directly\n",
        "        for file paths and corresponding labels.\n",
        "\n",
        "        Args:\n",
        "            path (str): Directory containing images, all belonging to the same class.\n",
        "            is_waterbird (int): The class label (e.g., 1 for waterbird, 0 for non-waterbird) for all images in the directory.\n",
        "            data_files (list): List of full file paths to images.\n",
        "            labels (list): List of labels corresponding to 'data_files'.\n",
        "        \"\"\"\n",
        "        if path: # If a path is provided, list all files in the directory and assign the class label\n",
        "            self.path = path\n",
        "            self.data_files = os.listdir(self.path)\n",
        "            self.is_waterbird = is_waterbird\n",
        "\n",
        "        else: # Otherwise, use provided lists of data files and labels\n",
        "            self.path = ''\n",
        "            self.data_files = data_files\n",
        "            self.labels = labels\n",
        "            self.is_waterbird = None\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        \"\"\"\n",
        "        Retrieves an image and its label at index 'i'.\n",
        "\n",
        "        Args:\n",
        "            i (int): Index of the image to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image tensor, label)\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        # Read in the image, convert to float between [0,1] and standardise , and convert to a PyTorch tensor\n",
        "        img = Image.open(oj(self.path, self.data_files[i]))\n",
        "        img_array = np.asarray(img)/255.0 # Convert image to float and scale to [0, 1]\n",
        "        img_array -= mean[None, None, :] # Subtract the mean for normalization\n",
        "        img_array /= std[None, None, :] # Divide by the standard deviation for normalization\n",
        "        img.close()\n",
        "        torch_img = torch.from_numpy(img_array.swapaxes(0,2).swapaxes(1,2)).float() # Convert the numpy array to a PyTorch tensor and rearrange the axes\n",
        "        # Determine the label: use the global class label if provided, otherwise extract the relevant label from the list of labels.\n",
        "        is_waterbird = self.is_waterbird if self.is_waterbird is not None else self.labels[i]\n",
        "        return (torch_img, is_waterbird)\n",
        "\n",
        "    def __len__(self): # Returns the total number of images in the dataset.\n",
        "        return len(self.data_files)"
      ],
      "metadata": {
        "id": "O-Sjxg4eYWoI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for Training"
      ],
      "metadata": {
        "id": "WztOCsqEYahv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_sum(im, target, model, crit, device='cuda'):\n",
        "    '''assume that eveything is already on cuda'''\n",
        "    im.requires_grad = True # Enable gradient computation for the input image\n",
        "    grad_params = torch.abs(torch.autograd.grad(crit(model(im), target), im,create_graph = True)[0].sum(dim=1)).sum()\n",
        "    return grad_params\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, resume_training=False):\n",
        "    since = time.time()\n",
        "    # train_loss_history = []\n",
        "    # train_acc_history = []\n",
        "    # train_cd_history= []\n",
        "\n",
        "\n",
        "    # Initialize best_loss, patience, and cur_patience to manage early stopping.\n",
        "    best_loss = 10.0\n",
        "    patience = 3 # Number of epochs to wait for improvement\n",
        "    cur_patience = 0 # Current patience counter\n",
        "\n",
        "    if len(os.listdir(model_training_path)) > 0 and resume_training:\n",
        "      # Check if there are saved model files and resume training if needed\n",
        "        model_list = [(f, os.path.getmtime(oj(model_training_path,f))) for f in os.listdir(model_training_path) if f.endswith('.pt')]\n",
        "        model_list.sort(key=lambda tup: tup[1], reverse=True)  # Sort models by modification time in place from most to least recent\n",
        "        model_name = model_list[0][0]\n",
        "        model.fc.load_state_dict(torch.load(oj(model_training_path, model_name)))\n",
        "        print(\"Model loaded!\")\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        optimizer.step() # Update the model parameters\n",
        "        model.train()  # Set model to training mode\n",
        "        phase = 'train'\n",
        "        running_loss = 0.0\n",
        "        running_loss_cd = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data , moving inputs and labels to the specified device.\n",
        "        for i, (inputs, labels) in tqdm(enumerate(dataloaders[phase])):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                # need to do calc beforehand because we do need the gradients\n",
        "                if phase == 'train' and regularizer_rate !=0:\n",
        "                  # Apply gradient regularization if specified , compute additional loss from gradients and update the model.\n",
        "                    inputs.requires_grad = True\n",
        "                    add_loss = gradient_sum(inputs, labels, model, criterion)\n",
        "                    if add_loss!=0:\n",
        "                        (regularizer_rate*add_loss).backward()\n",
        "                        optimizer.step()\n",
        "                    #print(torch.cuda.memory_allocated()/(np.power(10,9)))\n",
        "                    optimizer.zero_grad()\n",
        "                    running_loss_cd += add_loss.item() * inputs.size(0)\n",
        "\n",
        "                    #inputs.require_grad = False\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    (loss).backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_cd_loss = running_loss_cd / dataset_sizes[phase]\n",
        "\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f} CD Loss : {:.4f}'.format(\n",
        "            phase, epoch_loss, epoch_acc, epoch_cd_loss))\n",
        "\n",
        "        # train_loss_history.append(epoch_loss)\n",
        "        # train_cd_history.append(epoch_cd_loss)\n",
        "        # train_acc_history.append(epoch_acc.item())\n",
        "        torch.save(model.fc.state_dict(), oj(model_training_path, datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".pt\"))\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60)\n",
        "    )\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    return model"
      ],
      "metadata": {
        "id": "FHF45c9XYfPw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for Evaluation"
      ],
      "metadata": {
        "id": "s-WWUvuiYgs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import auc,average_precision_score, roc_curve,roc_auc_score,precision_recall_curve, f1_score\n",
        "\n",
        "def get_output(model, dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "    model = model.eval()\n",
        "    y = []\n",
        "    y_hat = []\n",
        "    softmax= torch.nn.Softmax() #Creates a Softmax function to convert logits to probabilities.\n",
        "    with torch.no_grad() : # Disables gradient computation for the operations within this block, saving memory and computation.\n",
        "\n",
        "        # Iterate over the DataLoader, moves inputs to GPU, and appends true labels and predicted probabilities to their respective lists.\n",
        "        for inputs, labels in data_loader:\n",
        "            y_hat.append((labels).cpu().numpy())\n",
        "            y.append(torch.nn.Softmax(dim=1)( model(inputs.cuda()))[:,1].detach().cpu().numpy()) # take the probability for beard\n",
        "    y_hat = np.concatenate( y_hat, axis=0 )\n",
        "    y = np.concatenate( y, axis=0 )\n",
        "    return y, y_hat # in the training set the values were switched\n",
        "\n",
        "def get_auc_f1(model, dataset,fname = None, ):\n",
        "    if fname !=None:\n",
        "        with open(fname, 'rb') as f:\n",
        "            weights = torch.load(f)\n",
        "        if \"classifier.0.weight\" in weights.keys(): #for the gradient models we unfortunately saved all of the weights\n",
        "            model.load_state_dict(weights)\n",
        "        else:\n",
        "            model.fc.load_state_dict(weights)\n",
        "        y, y_hat = get_output(model.fc, dataset)\n",
        "    else:\n",
        "        y, y_hat = get_output(model, dataset)\n",
        "    auc =roc_auc_score(y_hat, y)\n",
        "    f1 = np.asarray([f1_score(y_hat, y > x) for x in np.linspace(0.1,1, num = 10) if (y >x).any() and (y<x).any()]).max()\n",
        "    return auc, f1"
      ],
      "metadata": {
        "id": "-MIuY7JnYw8Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Classifier Training (on waterbirds no patch and not waterbirds with & without patch)"
      ],
      "metadata": {
        "id": "exWk0me3YyI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "waterbird_no_patch_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbirds_nopatch_224\""
      ],
      "metadata": {
        "id": "wZAVa0Oku8OA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waterbird_no_patch_dataset = WaterbirdDataset(path=waterbird_no_patch_path, is_waterbird=1)\n",
        "not_waterbird_dataset = WaterbirdDataset(path=not_waterbird_path, is_waterbird=0)\n",
        "complete_dataset = ConcatDataset((waterbird_no_patch_dataset, not_waterbird_dataset))\n",
        "\n",
        "num_total = len(complete_dataset)\n",
        "num_train = int(0.8 * num_total)\n",
        "num_test = num_total - num_train\n",
        "torch.manual_seed(0);\n",
        "print(\"num_train:\", num_train)\n",
        "print(\"num_test:\", num_test)\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(complete_dataset, [num_train, num_test])\n",
        "datasets = {'train' : train_dataset, 'test':test_dataset}\n",
        "dataset_sizes = {'train' : len(train_dataset), 'test':len(test_dataset)}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=args.batch_size,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'test']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nNFkym2Y6xA",
        "outputId": "b86f8206-f89d-4b66-ebc5-72e4a2e205c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_train: 8758\n",
            "num_test: 2190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_to_file(li, filename):\n",
        "  with open(filename, 'w') as f:\n",
        "    for item in li:\n",
        "      f.write(\"%s\\n\" % item)\n",
        "\n",
        "def extract_filenames(train_subset, test_subset):\n",
        "  # Extract the relevant indices of the concat dataset\n",
        "  train_idx, test_idx = train_subset.indices, test_subset.indices\n",
        "\n",
        "  # Extract the filenames for the beard_dataset and not_beard_dataset and concatenate with their directory path.\n",
        "  # Each original dataset is stored by the ConcatDataset class. So even though train_subset is a subset, the info for the whole beard dataset is stored in train_subset.dataset.datasets[0]\n",
        "  beard_no_patch_filepaths      = [oj(train_subset.dataset.datasets[0].path, file) for file in train_subset.dataset.datasets[0].data_files]\n",
        "  not_beard_filepaths  = [oj(train_subset.dataset.datasets[1].path, file) for file in train_subset.dataset.datasets[1].data_files]\n",
        "\n",
        "  filepaths = beard_no_patch_filepaths + not_beard_filepaths    # Append the lists together, this combined list is what the indices are based on.\n",
        "\n",
        "  train_files = [filepaths[i] for i in train_idx]\n",
        "  test_files  = [filepaths[i] for i in test_idx]\n",
        "\n",
        "  return train_files, test_files"
      ],
      "metadata": {
        "id": "qw-Bj-oxZhhY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function and get the full file paths.\n",
        "train_files, test_files = extract_filenames(train_dataset, test_dataset)\n",
        "list_to_file(train_files, oj(dir_path, 'models', 'train_files.txt'))   # Write the training filepaths to a text file.\n",
        "list_to_file(test_files,  oj(dir_path, 'models', 'test_files.txt'))    # Write the testing filepaths to a text file."
      ],
      "metadata": {
        "id": "jpiE8sGrZr1o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weights for Training"
      ],
      "metadata": {
        "id": "7kYYzFLOZvsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "waterbird_ratio = len(waterbird_no_patch_dataset)/len(complete_dataset)\n",
        "\n",
        "not_waterbird_ratio = 1 - waterbird_ratio\n",
        "waterbird_weight = 1/waterbird_ratio\n",
        "not_waterbird_weight = 1/ not_waterbird_ratio\n",
        "weights = np.asarray([not_waterbird_weight, waterbird_weight])\n",
        "weights /= weights.sum()\n",
        "weights = torch.tensor(weights).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = weights.double().float())\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=args.lr, momentum=args.momentum)"
      ],
      "metadata": {
        "id": "CkB0DfxrZxUX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, resume_training=False)\n",
        "pid = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "torch.save(model.fc.state_dict(),oj(dir_path, model_path, pid + \".pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IdfnB2qZ83g",
        "outputId": "32ef53be-a5ba-4b4e-d273-246df56e12bb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23it [00:02,  8.41it/s]<function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "25it [00:03,  6.54it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "548it [00:52, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4527 Acc: 0.8301 CD Loss : 0.0000\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "self._shutdown_workers()\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "self._shutdown_workers()    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "548it [00:52, 10.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4237 Acc: 0.8383 CD Loss : 0.0000\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "self._shutdown_workers()AssertionError\n",
            ":   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "can only test a child process    \n",
            "if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "548it [00:50, 10.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4035 Acc: 0.8479 CD Loss : 0.0000\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    Traceback (most recent call last):\n",
            "self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "self._shutdown_workers()    \n",
            "if w.is_alive():  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: \n",
            "AssertionErrorcan only test a child process: can only test a child process\n",
            "\n",
            "548it [00:50, 10.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3836 Acc: 0.8501 CD Loss : 0.0000\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>if w.is_alive():\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
            "\n",
            "AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            ": can only test a child process\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "548it [00:51, 10.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3752 Acc: 0.8527 CD Loss : 0.0000\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    \n",
            "self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "if w.is_alive():    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionError:   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "can only test a child process    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "\n",
            "548it [00:51, 10.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3604 Acc: 0.8607 CD Loss : 0.0000\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "self._shutdown_workers()    \n",
            "self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: : can only test a child process\n",
            "can only test a child process\n",
            "548it [00:52, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3556 Acc: 0.8623 CD Loss : 0.0000\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    : if w.is_alive():\n",
            "can only test a child process\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "548it [00:50, 10.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3514 Acc: 0.8647 CD Loss : 0.0000\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "548it [00:50, 10.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3417 Acc: 0.8685 CD Loss : 0.0000\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()Exception ignored in: \n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x79fe547ab7f0>    \n",
            "Traceback (most recent call last):\n",
            "if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            ":     can only test a child process\n",
            "if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "548it [00:50, 10.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3357 Acc: 0.8713 CD Loss : 0.0000\n",
            "Training complete in 8m 35s\n",
            "Best val loss: 10.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auc, f1 = get_auc_f1(model, test_dataset)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"F1: \", f1)"
      ],
      "metadata": {
        "id": "VPQX68GHZ-1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c79b21-463d-43ec-98be-f2eb336e70e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC:  0.9470408607976631\n",
            "F1:  0.7416020671834624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_file_path = oj(dir_path, \"auc_f1_224_resnet18_waterbird_no_patch.txt\")\n",
        "print(results_file_path)\n",
        "with open(results_file_path, 'w') as f:\n",
        "    f.write('AUC: ' + str(auc) + \"\\n\")\n",
        "    f.write('F1: ' + str(f1) + \"\\n\")"
      ],
      "metadata": {
        "id": "iaVVMalgaAnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9803ea9f-b9ef-4df7-ab29-9e4a19ee944b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/auc_f1_224_resnet18_waterbird_no_patch.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reload the model to skip retrainig and test with waterbird patched images"
      ],
      "metadata": {
        "id": "kSnURsI9aEBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "waterbird_patch_path = '/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbirds_patch_224'\n",
        "not_waterbird_path = '/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/data/processed/no_waterbird_224'"
      ],
      "metadata": {
        "id": "lZLm8md2scbB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waterbird_patch_dataset = WaterbirdDataset(path=waterbird_patch_path, is_waterbird=1)\n",
        "not_waterbird_dataset = WaterbirdDataset(path=not_waterbird_path, is_waterbird=0)\n",
        "complete_patch_dataset = ConcatDataset((waterbird_patch_dataset, not_waterbird_dataset))\n",
        "\n",
        "num_total = len(complete_patch_dataset)\n",
        "num_train = int(0.8 * num_total)\n",
        "num_test = num_total - num_train\n",
        "torch.manual_seed(0);\n",
        "print(\"num_train:\", num_train)\n",
        "print(\"num_test:\", num_test)\n",
        "\n",
        "train_patch_dataset, test_patch_dataset = torch.utils.data.random_split(complete_patch_dataset, [num_train, num_test])\n",
        "datasets = {'train' : train_patch_dataset, 'test':test_patch_dataset}\n",
        "dataset_sizes = {'train' : len(train_patch_dataset), 'test':len(test_patch_dataset)}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=args.batch_size,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'test']}\n"
      ],
      "metadata": {
        "id": "0taIZkOmaIX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3bf859-c929-4ff8-fd57-9cbe0362f038"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_train: 7972\n",
            "num_test: 1993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def list_to_file(li, filename):\n",
        "  with open(filename, 'w') as f:\n",
        "    for item in li:\n",
        "      f.write(\"%s\\n\" % item)\n",
        "\n",
        "def extract_filenames(train_subset, test_subset):\n",
        "  # Extract the relevant indices of the concat dataset\n",
        "  train_idx, test_idx = train_subset.indices, test_subset.indices\n",
        "\n",
        "  # Extract the filenames for the waterbird_dataset and not_waterbird_dataset and concatenate with their directory path.\n",
        "  # Each original dataset is stored by the ConcatDataset class. So even though train_subset is a subset, the info for the whole waterbird dataset is stored in train_subset.dataset.datasets[0]\n",
        "  waterbird_filepaths      = [oj(train_subset.dataset.datasets[0].path, file) for file in train_subset.dataset.datasets[0].data_files]\n",
        "  not_waterbird_filepaths  = [oj(train_subset.dataset.datasets[1].path, file) for file in train_subset.dataset.datasets[1].data_files]\n",
        "\n",
        "  filepaths = waterbird_filepaths + not_waterbird_filepaths    # Append the lists together, this combined list is what the indices are based on.\n",
        "\n",
        "  train_files = [filepaths[i] for i in train_idx]\n",
        "  test_files  = [filepaths[i] for i in test_idx]\n",
        "\n",
        "  return train_files, test_files\n"
      ],
      "metadata": {
        "id": "1FUiJI3eaVaI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_auc_f1(model, dataset,fname = None, ):\n",
        "    if fname !=None:\n",
        "        with open(fname, 'rb') as f:\n",
        "            weights = torch.load(f)\n",
        "        if \"classifier.0.weight\" in weights.keys(): #for the gradient models they saved all of the weights\n",
        "            model.load_state_dict(weights)\n",
        "        else:\n",
        "            model.fc.load_state_dict(weights)\n",
        "        y, y_hat = get_output(model.fc, dataset)\n",
        "    else:\n",
        "        y, y_hat = get_output(model, dataset)\n",
        "    auc =roc_auc_score(y_hat, y)\n",
        "    f1 = np.asarray([f1_score(y_hat, y > x) for x in np.linspace(0.1,1, num = 10) if (y >x).any() and (y<x).any()]).max()\n",
        "    return auc, f1"
      ],
      "metadata": {
        "id": "zmRzzc7_pfgX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions(model, dataset, filename):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Iterate over the dataset\n",
        "    for inputs, labels in dataset:\n",
        "        inputs = inputs.unsqueeze(0)  # Add batch dimension\n",
        "        inputs = inputs.to(device)  # Move data to appropriate device\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Append predictions to the list\n",
        "        predictions.append(predicted.item())\n",
        "\n",
        "        # Check if labels are integers or tensors\n",
        "        if isinstance(labels, torch.Tensor):\n",
        "            true_labels.append(labels.item())\n",
        "        else:\n",
        "            true_labels.append(labels)  # Assume labels are integers\n",
        "\n",
        "    # Create a DataFrame to store predictions and true labels\n",
        "    df = pd.DataFrame({\n",
        "        'Prediction': predictions,\n",
        "        'True Label': true_labels\n",
        "    })\n",
        "\n",
        "    # Save DataFrame to CSV file\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Predictions saved to {filename}\")"
      ],
      "metadata": {
        "id": "CRf2aUylagRo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = torch.nn.Linear(num_ftrs, 2)  # Modify classifier\n",
        "\n",
        "# Load the saved parameters into the model\n",
        "saved_model_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/models/initial_classifier/20240601205521.pt\"\n",
        "model.fc.load_state_dict(torch.load(saved_model_path))\n",
        "\n",
        "# Move model to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# waterbird_dataset and complete_dataset are already defined\n",
        "waterbird_ratio = len(waterbird_patch_dataset) / len(complete_dataset)\n",
        "not_waterbird_ratio = 1 - waterbird_ratio\n",
        "waterbird_weight = 1 / waterbird_ratio\n",
        "not_waterbird_weight = 1 / not_waterbird_ratio\n",
        "weights = torch.tensor([not_waterbird_weight, waterbird_weight], device=device, dtype=torch.float)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# Define arguments\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.batch_size = 16\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.00001\n",
        "        self.momentum = 0.9\n",
        "        self.seed = 42\n",
        "        self.regularizer_rate = 0.0\n",
        "\n",
        "args = Args()\n",
        "\n",
        "regularizer_rate = args.regularizer_rate\n",
        "num_epochs = args.epochs\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "#params_to_update = model.fc.parameters()\n",
        "params_to_update = model.parameters()\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=args.lr, momentum=args.momentum)\n"
      ],
      "metadata": {
        "id": "n6fMrLJWajKg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc, f1 = get_auc_f1(model, test_patch_dataset)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"F1: \", f1)"
      ],
      "metadata": {
        "id": "K8_Ahmdgawn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577f6d08-2a37-493b-8459-5291be2e5a18"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC:  0.7811743546469728\n",
            "F1:  0.336734693877551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_predictions(model, test_patch_dataset, '/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/models/initial_classifier/patch_predictions.csv')"
      ],
      "metadata": {
        "id": "Pkn1ZI-waxnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de4b681-c55c-4d65-f74c-df7b2c4a6f6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to /content/drive/MyDrive/Masterthesis/Datasets/Waterbird/models/initial_classifier/patch_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and extract activations from last layer"
      ],
      "metadata": {
        "id": "Q_rl1OCAa1uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Check the number of input features to the final fully connected layer\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "# Replace the final fully connected layer with a new linear layer for binary classification\n",
        "model.fc = torch.nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Load the saved parameters into the model\n",
        "saved_model_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/models/initial_classifier/20240601205521.pt\"\n",
        "model.fc.load_state_dict(torch.load(saved_model_path))\n",
        "\n",
        "# Move model to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define preprocessing transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def preprocess_and_extract_activations(image_path):\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        # Forward pass through the model up to the last fully connected layer\n",
        "        features = model.conv1(image_tensor)\n",
        "        features = model.bn1(features)\n",
        "        features = model.relu(features)\n",
        "        features = model.maxpool(features)\n",
        "\n",
        "        features = model.layer1(features)\n",
        "        features = model.layer2(features)\n",
        "        features = model.layer3(features)\n",
        "        features = model.layer4(features)\n",
        "\n",
        "        features = model.avgpool(features)\n",
        "        features = torch.flatten(features, 1)\n",
        "\n",
        "        # Extract activations from the last fully connected layer before the final classification layer\n",
        "        activations = features.squeeze().cpu().detach().numpy()\n",
        "\n",
        "    return activations\n",
        "\n",
        "\n",
        "# Function to recursively traverse folders and process images\n",
        "def process_images_in_folder(folder_path):\n",
        "    all_activations = []\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                activations = preprocess_and_extract_activations(image_path)\n",
        "                if activations is not None:\n",
        "                    all_activations.append(activations)\n",
        "    return all_activations\n",
        "\n",
        "# Folder path containing images\n",
        "patch_waterbird_folder_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbirds_patch_224\"\n",
        "no_patch_waterbird_folder_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbirds_nopatch_224\"\n",
        "\n",
        "# Extract activations for all images in the folder\n",
        "wp_waterbird_all_activations = process_images_in_folder(patch_waterbird_folder_path)\n",
        "wo_waterbird_all_activations = process_images_in_folder(no_patch_waterbird_folder_path)\n",
        "\n",
        "if wp_waterbird_all_activations:\n",
        "    print(\"wp_waterbird_all_activations shape:\", np.vstack(wp_waterbird_all_activations).shape)\n",
        "else:\n",
        "    print(\"No activations found in wp_waterbird_all_activations\")\n",
        "\n",
        "if wo_waterbird_all_activations:\n",
        "    print(\"wo_waterbird_all_activations shape:\", np.vstack(wo_waterbird_all_activations).shape)\n",
        "else:\n",
        "    print(\"No activations found in wo_waterbird_all_activations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2-QBtnUSLKo",
        "outputId": "1fc1594e-eeb8-4151-cc3c-40a3ba39bd1a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wp_waterbird_all_activations shape: (840, 512)\n",
            "wo_waterbird_all_activations shape: (1823, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# each row corresponds to the activations of one image.\n",
        "#np.vstack(wp_beard_all_activations).shape"
      ],
      "metadata": {
        "id": "0O61P8r3bMLY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save activations for malignant wit patches as npy array (Sari likes npy, I like csv)\n",
        "np.save('/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbird_test_wp_activations.npy',np.vstack(wp_waterbird_all_activations))\n",
        "np.save('/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbird_test_wo_activations.npy',np.vstack(wo_waterbird_all_activations))"
      ],
      "metadata": {
        "id": "hepYH_LCbOJI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#folder_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbirds_patch_224\"\n",
        "folder_path_waterbird_patch = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbirds_patch_224\"\n",
        "folder_path_waterbird_nopatch = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbirds_nopatch_224\"\n",
        "\n",
        "\n",
        "files_patch= os.listdir(folder_path_waterbird_patch)\n",
        "files_nopatch= os.listdir(folder_path_waterbird_nopatch)\n",
        "\n",
        "\n",
        "num_waterbird_patch_test = len(files_patch)\n",
        "num_waterbird_nopatch_test = len(files_nopatch)\n",
        "\n",
        "\n",
        "patch_no_patch = np.hstack([np.zeros((1,num_waterbird_nopatch_test)),np.ones((1,num_waterbird_patch_test))])\n",
        "\n",
        "wp = np.load('/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbird_test_wp_activations.npy')\n",
        "wo = np.load('/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/waterbird_test_wo_activations.npy')\n",
        "wop_activations = np.vstack([wo,wp])"
      ],
      "metadata": {
        "id": "uSqTQo6_beiR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wop_activations.shape"
      ],
      "metadata": {
        "id": "gTQWCrw2buj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a5292e-ce24-49ad-c66d-66538b68c8a3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2663, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_arrays = np.concatenate((patch_no_patch.T, wop_activations), axis=1) # 900x568\n",
        "corr = np.corrcoef(two_arrays.T)"
      ],
      "metadata": {
        "id": "yjCTgPunbvW4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_no_patch.shape"
      ],
      "metadata": {
        "id": "PvlwHJ5cbw8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40634627-aec7-440e-bb1f-5491bbed4894"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2663)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "activations_corr = np.abs(corr[0][1:])\n",
        "_ = plt.hist(activations_corr, bins='auto')"
      ],
      "metadata": {
        "id": "h-ECE7K_bxmg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "940853cb-a0cd-47a4-ba43-b01ca5f30aa5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activations_corr.shape"
      ],
      "metadata": {
        "id": "atnRZSIdbzGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b40b0ce-c43e-4a52-a5d8-6241972eca56"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512,)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(activations_corr)"
      ],
      "metadata": {
        "id": "fIKcSBQtb0aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e340d9e7-afad-4ecd-d41c-686f977b5fea"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.50414434e-01 2.67762531e-02 3.65096280e-03 2.49865890e-02\n",
            " 1.94161301e-02 5.44366801e-02 1.57929364e-01 3.67966857e-01\n",
            " 3.15196743e-02 1.38524133e-01 2.47027294e-02 2.03471564e-02\n",
            " 5.36477979e-03 2.30132617e-01 1.22259659e-01 2.95760465e-02\n",
            " 1.13219963e-01 2.86004484e-01 3.38477637e-02 1.95606996e-01\n",
            " 2.20955797e-01 1.82812540e-01 4.28592591e-02 2.48647236e-01\n",
            " 6.35567081e-02 2.97793838e-02 7.06459974e-02 1.41372176e-02\n",
            " 9.21527288e-02 2.77732901e-02 5.86217259e-02 5.88206798e-02\n",
            " 1.18945926e-01 2.24960853e-01 2.21526450e-02 5.52531319e-02\n",
            " 1.12797555e-01 1.44727900e-01 2.96160045e-01 2.61356107e-01\n",
            " 1.88205734e-02 5.99452221e-03 1.28079329e-01 4.37811040e-02\n",
            " 2.39710787e-01 2.15612203e-02 4.62798348e-02 3.19759555e-02\n",
            " 6.48964955e-02 1.16949313e-01 1.70949240e-01 1.12038455e-01\n",
            " 9.06539226e-03 2.03847772e-01 4.31944640e-02 3.64324999e-02\n",
            " 5.99061455e-01 6.45052050e-02 2.93514011e-01 9.42015389e-02\n",
            " 7.87797642e-02 1.11444923e-01 7.54950178e-03 2.27069636e-02\n",
            " 1.56111171e-01 6.47438455e-02 1.10162202e-01 1.98053305e-02\n",
            " 3.59800534e-02 6.68838571e-02 6.86435454e-02 1.62691202e-02\n",
            " 3.29426497e-02 3.32293590e-02 5.00271871e-02 5.19727852e-02\n",
            " 9.22284932e-02 2.55931932e-02 3.20287285e-02 7.75812509e-02\n",
            " 7.99911839e-02 2.00920385e-01 3.59752778e-02 3.09657927e-01\n",
            " 5.25693579e-03 3.50863572e-01 4.45805715e-02 1.41707625e-02\n",
            " 4.68063701e-02 7.17567794e-02 3.40801376e-02 9.65921765e-02\n",
            " 5.46946017e-02 1.66470919e-01 3.65240433e-01 9.54716454e-02\n",
            " 2.75392374e-02 1.01286788e-01 1.81669515e-01 6.66671036e-03\n",
            " 2.44126728e-01 4.20267197e-01 3.13587680e-02 8.60106276e-02\n",
            " 3.70464948e-01 1.36317791e-01 1.21632685e-01 9.07024744e-02\n",
            " 6.60319720e-02 3.22392669e-02 9.27408892e-03 2.53236694e-02\n",
            " 8.58501428e-02 7.91625053e-02 8.18255811e-02 3.72364860e-02\n",
            " 2.43592939e-01 3.00259451e-01 1.97855075e-02 1.06696685e-01\n",
            " 2.79952390e-02 1.57272323e-02 1.84203803e-01 7.02670140e-03\n",
            " 3.90471105e-02 8.16887471e-02 1.38444533e-01 1.83433474e-01\n",
            " 4.70906942e-01 1.40802750e-02 4.59836746e-02 7.14990802e-02\n",
            " 1.09750630e-01 3.70299951e-01 8.39908552e-03 1.13449813e-01\n",
            " 1.05037910e-01 1.17586343e-01 2.16684839e-02 7.19912500e-02\n",
            " 1.28372412e-01 5.59565079e-02 2.75689208e-01 4.76174407e-02\n",
            " 5.53381395e-02 1.56782651e-03 4.34794030e-02 1.07696049e-01\n",
            " 2.02079923e-02 3.60960793e-01 1.27495825e-01 2.01897193e-02\n",
            " 1.22459661e-02 5.63341343e-02 9.51738784e-02 2.31305815e-02\n",
            " 7.99737792e-02 8.62268940e-02 7.41684626e-02 1.22752773e-01\n",
            " 3.53908409e-01 8.83164898e-02 1.04688783e-02 2.73353215e-01\n",
            " 3.51057592e-02 3.34442632e-02 1.27494756e-01 1.04576764e-02\n",
            " 1.14583845e-01 5.85392432e-02 3.12673825e-02 3.65143636e-03\n",
            " 4.64195641e-02 8.54452259e-02 5.61148785e-02 5.62135217e-02\n",
            " 8.08974786e-02 9.82686251e-02 3.74304499e-01 6.42662308e-02\n",
            " 3.04726850e-02 5.67172680e-02 3.04643861e-01 8.03907430e-02\n",
            " 4.71952459e-01 5.57668081e-02 5.89213616e-02 1.20170635e-01\n",
            " 1.86129260e-01 3.07651927e-02 2.91700989e-02 4.02859955e-02\n",
            " 1.62589310e-01 4.63598726e-01 6.26061652e-02 2.22572510e-01\n",
            " 4.10612543e-02 2.49224915e-02 1.95435669e-01 1.57738137e-01\n",
            " 7.69833215e-02 8.12178832e-02 1.28916431e-01 2.38301447e-01\n",
            " 4.22444194e-02 8.08900426e-02 8.09624596e-02 9.64111630e-02\n",
            " 6.50739174e-02 2.11225159e-01 3.83788196e-02 1.90377451e-01\n",
            " 5.80982166e-02 6.49629804e-02 4.19695831e-03 5.34754203e-02\n",
            " 4.23706503e-01 1.15563903e-01 1.11205970e-01 1.58973845e-01\n",
            " 1.18651208e-01 1.97342685e-01 1.05056067e-01 7.62151156e-02\n",
            " 1.13372034e-01 8.73688609e-02 1.84323469e-01 5.26042566e-02\n",
            " 2.06449424e-01 1.64422119e-01 1.76697783e-02 1.67713137e-02\n",
            " 1.72765114e-01 1.10402352e-01 4.73283409e-02 2.02608074e-02\n",
            " 3.47223818e-01 2.79327959e-02 2.18550187e-01 1.25679341e-03\n",
            " 2.26811699e-02 7.60452221e-02 1.37657597e-01 1.14850153e-01\n",
            " 2.81175837e-02 1.57662173e-01 3.24201173e-02 7.60657406e-02\n",
            " 8.28936120e-02 1.10975506e-01 3.67286625e-01 1.61431531e-02\n",
            " 2.63326644e-01 4.28653905e-02 3.79065738e-02 2.33668458e-01\n",
            " 6.21536889e-02 2.52676127e-01 4.65554354e-02 7.38913173e-03\n",
            " 9.19233523e-02 9.76360763e-02 1.56640924e-01 2.03712965e-01\n",
            " 8.52236481e-02 4.91009868e-02 1.12433413e-01 9.00977233e-02\n",
            " 1.68118412e-02 4.20748608e-02 1.76837348e-02 2.43868836e-02\n",
            " 6.88717883e-02 1.58919407e-01 7.40852239e-02 6.15975228e-02\n",
            " 2.22114797e-01 2.22121491e-01 2.06503335e-02 1.85982314e-01\n",
            " 8.03277260e-02 3.72850048e-02 7.56024329e-02 5.65511828e-02\n",
            " 1.44422401e-01 1.89112910e-01 4.23307356e-04 9.59455590e-02\n",
            " 5.45495278e-02 1.67639925e-01 2.19259302e-01 4.91223932e-01\n",
            " 3.72863739e-02 9.59542974e-02 5.30085611e-02 4.72133236e-02\n",
            " 5.84283163e-02 6.21768231e-01 1.13167449e-01 1.21757959e-01\n",
            " 1.87178351e-02 1.16647112e-01 9.78616763e-02 2.39107179e-01\n",
            " 2.56898995e-01 6.84682085e-02 1.11630958e-01 3.81105411e-01\n",
            " 1.72191824e-02 4.59204335e-03 3.84386381e-02 8.51127488e-02\n",
            " 1.31880716e-02 7.77116008e-02 1.00528501e-01 3.92390056e-02\n",
            " 2.93024176e-02 2.40451854e-02 3.14071948e-01 3.32236507e-02\n",
            " 5.83054611e-02 6.36091810e-02 2.06048315e-02 1.09410414e-01\n",
            " 3.07452075e-02 3.97966708e-01 7.82068362e-02 4.72438454e-02\n",
            " 5.29056893e-02 9.95937199e-02 6.99455100e-02 1.99627410e-01\n",
            " 2.42459919e-01 7.86401999e-02 1.00420396e-02 1.29874610e-01\n",
            " 3.78145657e-03 2.05623817e-01 2.29579835e-01 1.03832078e-01\n",
            " 1.19002166e-01 7.99639885e-02 4.75966288e-02 7.05254022e-02\n",
            " 1.83318535e-01 3.89614429e-02 1.68842678e-02 1.04048159e-01\n",
            " 7.62430309e-02 1.87106885e-01 4.50001215e-02 2.62363707e-01\n",
            " 1.33350263e-01 1.31030708e-01 2.04319597e-01 5.74184641e-02\n",
            " 7.75140751e-02 1.35216856e-01 2.44110756e-02 1.76681897e-02\n",
            " 3.52487390e-02 1.46180308e-01 2.06222555e-02 1.63354699e-01\n",
            " 1.28649053e-01 1.05285242e-01 2.94666871e-02 1.42135140e-01\n",
            " 3.76885164e-02 4.76096456e-03 1.78011336e-01 5.85242298e-02\n",
            " 3.59489102e-02 4.95306289e-02 2.52365038e-01 6.02576436e-02\n",
            " 2.18385548e-01 8.70011441e-02 7.67403360e-02 6.11042513e-02\n",
            " 8.98920116e-02 1.18119804e-02 3.00154490e-01 1.17172045e-01\n",
            " 1.38573879e-01 2.84641423e-01 1.44587603e-01 1.09974873e-02\n",
            " 3.33050189e-01 2.38624796e-01 1.23506121e-01 2.23401140e-01\n",
            " 7.54531401e-05 4.11560294e-01 9.90091486e-02 3.25710485e-02\n",
            " 1.31624328e-01 1.17516512e-01 6.38005622e-02 1.12057519e-01\n",
            " 1.39343161e-01 2.24827669e-01 5.61450574e-02 1.99398704e-01\n",
            " 7.08630743e-02 3.59872184e-03 1.05031011e-02 7.72633415e-02\n",
            " 1.76226769e-01 2.17584028e-01 1.26356772e-01 6.55204864e-02\n",
            " 1.88498143e-02 2.03507716e-01 1.42566538e-01 1.02654102e-02\n",
            " 1.90157370e-02 3.54522073e-02 1.73134638e-01 1.00692731e-01\n",
            " 3.24984360e-02 2.72282552e-02 2.69994452e-01 3.17294550e-01\n",
            " 2.14287437e-01 6.75798501e-03 4.53597383e-01 1.18739938e-01\n",
            " 1.47700513e-01 8.97407016e-02 1.01872572e-02 4.98447622e-02\n",
            " 1.23255781e-02 1.87974366e-01 3.22885644e-02 3.59538539e-01\n",
            " 3.25717014e-02 1.87358769e-01 3.37953405e-01 1.55664915e-01\n",
            " 8.21402588e-02 1.98865646e-02 1.80351236e-02 4.06880003e-01\n",
            " 4.36086568e-01 6.04266323e-02 1.73170890e-01 5.54028030e-03\n",
            " 1.26977672e-01 9.80791417e-02 2.24224738e-02 1.46779147e-02\n",
            " 1.36835126e-01 5.53336732e-03 2.11970587e-02 1.00549015e-01\n",
            " 8.78381917e-02 2.68011478e-02 5.58770572e-02 9.13678233e-02\n",
            " 1.02019207e-01 2.54958426e-02 1.03662333e-02 4.63634396e-02\n",
            " 1.53596848e-02 2.61993702e-02 2.23156227e-02 1.58771371e-02\n",
            " 9.23424169e-02 1.12650328e-01 3.48999100e-03 1.56177885e-01\n",
            " 1.88018672e-01 1.74704353e-02 1.11955334e-01 4.71930723e-02\n",
            " 5.92772876e-02 1.18617623e-01 2.02511982e-02 1.21983758e-01\n",
            " 3.35682789e-01 4.29439525e-01 1.70698528e-01 1.05142129e-01\n",
            " 1.76881668e-02 9.12082380e-03 9.61130157e-02 4.50859833e-02\n",
            " 9.18761547e-02 2.78451794e-02 9.19336742e-02 3.84185134e-02\n",
            " 1.22854007e-01 3.47796448e-02 6.77958661e-02 4.00503964e-03\n",
            " 3.49200229e-02 4.26584106e-02 7.78939219e-02 6.84094523e-02\n",
            " 3.58787459e-02 5.40391973e-03 6.19326063e-02 2.99849777e-02\n",
            " 5.77215837e-02 3.08047364e-02 7.18616995e-02 4.85017019e-02\n",
            " 3.24580482e-02 5.87802796e-02 5.33045588e-01 3.06896287e-03]\n"
          ]
        }
      ]
    }
  ]
}