{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7OfeLhEdFs_",
        "outputId": "46c0e4b8-3f1f-4ff2-a57e-3900b69e1f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-8HTugQdEpH",
        "outputId": "a4ef6e64-af23-486c-8d46-ce3ad95e4fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchextractor\n",
            "  Downloading torchextractor-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchextractor) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchextractor) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->torchextractor) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->torchextractor) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->torchextractor) (3.0.2)\n",
            "Downloading torchextractor-0.3.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: torchextractor\n",
            "Successfully installed torchextractor-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchextractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_cjXRL5dDFn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from os.path import join as oj\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import TensorDataset, ConcatDataset\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from numpy.random import randint\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import copy\n",
        "import gc\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from scipy.stats import ttest_1samp\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbanKT1Sml1i"
      },
      "source": [
        "### Loading fine tuned alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7eIdrXCYf-G"
      },
      "outputs": [],
      "source": [
        "class MnistDataset(Dataset):\n",
        "    def __init__(self, path: str = None, is_two: int = None, data_files=None, labels=None, transform=None):\n",
        "        self.resize_shape = (64, 64)  # Target shape for resizing images\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize(self.resize_shape),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for RGB images\n",
        "        ])\n",
        "\n",
        "        if path:\n",
        "            self.path = path\n",
        "            self.data_files = [f for f in os.listdir(self.path) if f.endswith(('.jpg', '.png'))]\n",
        "            if len(self.data_files) == 0:\n",
        "                raise ValueError(f\"No valid image files found in the provided path: {self.path}\")\n",
        "\n",
        "            self.is_two = is_two\n",
        "            self.labels = [is_two] * len(self.data_files) if is_two is not None else labels\n",
        "        else:\n",
        "            self.path = ''\n",
        "            if data_files is None or len(data_files) == 0:\n",
        "                raise ValueError(\"data_files must be a non-empty list of file paths.\")\n",
        "\n",
        "            self.data_files = data_files\n",
        "            self.labels = labels\n",
        "            self.is_two = is_two\n",
        "\n",
        "        if self.labels is not None and len(self.labels) != len(self.data_files):\n",
        "            raise ValueError(\"Mismatch between the number of labels and data files.\")\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        try:\n",
        "            img_path = os.path.join(self.path, self.data_files[i]) if self.path else self.data_files[i]\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            is_two = self.is_two if self.is_two is not None else self.labels[i]\n",
        "            return img, is_two  # Exclude group_label\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {i}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0tP9JsQYc_xx",
        "outputId": "c85e7496-6535-4ec0-e7fa-564e791380a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Load and test the model for each seed\\nseeds = [1111, 11111, 111111]\\nfor seed in seeds:\\n    model_path = f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_{seed}.pt\"\\n\\n    print(f\"\\nLoading model with seed {seed}\")\\n    model = load_model(model_path, device)\\n\\n    # Test on wb oatch dataset\\n    #accuracy_fg = test_model(model, test_loader_fg, device)\\n    #print(f\"Accuracy on two with patch test dataset (class_2): {accuracy_fg:.2f}%\")\\n\\n    # Test on original dataset\\n    #accuracy_org = test_model(model, test_loader_org, device)\\n    #print(f\"Accuracy on two without patch test dataset (class_2): {accuracy_org:.2f}%\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "mean = np.asarray([0.485, 0.456, 0.406])\n",
        "std = np.asarray([0.229, 0.224, 0.225])\n",
        "\n",
        "'''\n",
        "def load_model(model_path, device):\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    model = models.alexnet(pretrained=False)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully\")\n",
        "    return model\n",
        "'''\n",
        "\n",
        "\n",
        "# Function to load the trained model\n",
        "def load_model(model_path, device):\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    model = models.alexnet(pretrained=False)\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)\n",
        "\n",
        "    #model = AlexNet().to(device)\n",
        "    #model.fc3 = nn.Linear(4096, 2)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully\")\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Function to test the model on a specific dataset\n",
        "def test_model(model, dataloader, device):\n",
        "    # Ensure the model is in evaluation mode. This disables dropout and batch norm updates.\n",
        "    model.eval()\n",
        "\n",
        "    # Variables to keep track of the total number of samples and correct predictions\n",
        "    correct = 0  # Count of correctly classified samples\n",
        "    total = 0    # Total number of samples processed\n",
        "\n",
        "    # Disable gradient computation since we're only testing, not training\n",
        "    with torch.no_grad():\n",
        "        # Loop through the data in the dataloader\n",
        "        for inputs, labels in dataloader:  # Assume dataloader returns (inputs, labels, additional_metadata)\n",
        "            # Move the input images and labels to the specified device (CPU or GPU)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Perform a forward pass through the model to get outputs (logits for each class)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Use torch.max to get the predicted class with the highest logit (1st dimension: classes)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Increment total by the number of samples in the current batch\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Count the number of correct predictions by comparing with true labels\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "\n",
        "    # Return the calculated accuracy\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "# Define paths to the test datasets\n",
        "test_two_fg_path = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/test/class_2'\n",
        "test_two_org_path = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_2'\n",
        "\n",
        "# Create test datasets\n",
        "dataset_test_two_fg = MnistDataset(path=test_two_fg_path, is_two=1)\n",
        "dataset_test_two_org = MnistDataset(path=test_two_org_path, is_two=1)\n",
        "\n",
        "# Create dataloaders for the test datasets\n",
        "batch_size = 128\n",
        "test_loader_fg = DataLoader(dataset_test_two_fg, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader_org = DataLoader(dataset_test_two_org, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "'''\n",
        "# Load and test the model for each seed\n",
        "seeds = [1111, 11111, 111111]\n",
        "for seed in seeds:\n",
        "    model_path = f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_{seed}.pt\"\n",
        "\n",
        "    print(f\"\\nLoading model with seed {seed}\")\n",
        "    model = load_model(model_path, device)\n",
        "\n",
        "    # Test on wb oatch dataset\n",
        "    #accuracy_fg = test_model(model, test_loader_fg, device)\n",
        "    #print(f\"Accuracy on two with patch test dataset (class_2): {accuracy_fg:.2f}%\")\n",
        "\n",
        "    # Test on original dataset\n",
        "    #accuracy_org = test_model(model, test_loader_org, device)\n",
        "    #print(f\"Accuracy on two without patch test dataset (class_2): {accuracy_org:.2f}%\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwtywcNYmp_r"
      },
      "source": [
        "### Extract Alexnet training fc2 activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opam1xkUmtUk"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None, resize_shape=(64, 64)):\n",
        "        print(f\"Initializing dataset with {len(image_paths)} images\")\n",
        "        self.image_paths = image_paths\n",
        "        self.resize_shape = resize_shape  # Set the resize shape\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize(self.resize_shape),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for RGB images\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        print(f\"Loading image: {image_path}\")\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "# Preprocessing function\n",
        "preprocess = transforms.Compose([\n",
        "    #transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((64, 64)),  # Match the resize shape in MnistDataset\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Match the normalization values in MnistDataset\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEV6eZuI3e0h"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path, freeze_layers=True, pretrained=False):\n",
        "    \"\"\"\n",
        "    Loads an AlexNet model, updates it for binary classification, and optionally freezes layers.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the saved model weights.\n",
        "        freeze_layers (bool): Whether to freeze all layers except the classifier.\n",
        "        pretrained (bool): Whether to use pretrained weights (e.g., from ImageNet) for initialization.\n",
        "\n",
        "    Returns:\n",
        "        model: The loaded and configured AlexNet model.\n",
        "    \"\"\"\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load AlexNet with or without pretrained weights\n",
        "    model = models.alexnet(pretrained=pretrained)\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)  # Update the final layer for binary classification\n",
        "\n",
        "    # Load saved weights\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    print(\"Model loaded successfully\")\n",
        "\n",
        "    # Optionally freeze all layers\n",
        "    if freeze_layers:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        print(\"All layers frozen successfully\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def attach_fc2_hook(model):\n",
        "    \"\"\"\n",
        "    Attaches a forward hook to capture activations from fc2.\n",
        "\n",
        "    Args:\n",
        "        model: The model to attach the hook to.\n",
        "\n",
        "    Returns:\n",
        "        activations (dict): A dictionary to store captured activations.\n",
        "    \"\"\"\n",
        "    activations = {\"fc2\": []}  # Use a list to accumulate activations\n",
        "\n",
        "    def hook(module, input, output):\n",
        "        activations[\"fc2\"].append(output.cpu().numpy())  # Append activations\n",
        "\n",
        "    model.classifier[4].register_forward_hook(hook)\n",
        "    print(\"Hook attached to fc2 successfully\")\n",
        "    return activations\n",
        "\n",
        "\n",
        "    return activations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz6R3SRirCLB"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def load_model(model_path):\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    model = models.alexnet(pretrained=False)\n",
        "    #model = AlexNet().to(device)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    #model.fc3 = nn.Linear(4096, 2)\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully\")\n",
        "\n",
        "    # Freeze all layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print(\"Model loaded and layers frozen successfully\")\n",
        "\n",
        "    # Add a forward hook to capture fc2 activations\n",
        "    activations = {}\n",
        "\n",
        "    def hook(module, input, output):\n",
        "        activations[\"fc2\"] = output\n",
        "\n",
        "    # Attach the hook to the second last layer (fc2)\n",
        "    #model.fc2[1].register_forward_hook(hook)\n",
        "    model.classifier[4].register_forward_hook(hook)\n",
        "\n",
        "    return model, activations\n",
        "\n",
        "# Code 2\n",
        "\n",
        "'''\n",
        "\n",
        "def preprocess_and_extract_activations(model, dataloader, layer):\n",
        "\n",
        "    activations = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            image_tensor = batch[0]  # Extract the image tensor (ignore labels)\n",
        "            image_tensor = image_tensor.to(device)\n",
        "\n",
        "            if layer < 13:  # Layer in model.features\n",
        "                tensor = image_tensor\n",
        "                for idx, layer_module in enumerate(model.features[:layer + 1]):\n",
        "                    tensor = layer_module(tensor)\n",
        "            else:  # Layer in model.classifier\n",
        "                tensor = model.features(image_tensor)\n",
        "                tensor = model.avgpool(tensor)\n",
        "                tensor = torch.flatten(tensor, 1)\n",
        "                for idx, layer_module in enumerate(model.classifier[:layer - 12]):\n",
        "                    tensor = layer_module(tensor)\n",
        "                    if idx == 4:\n",
        "                      print(f\"Extracting from FC2 (classifier[4]): {layer_module}\")\n",
        "                      print(f\"Activation shape at FC2: {tensor.shape}\")\n",
        "\n",
        "\n",
        "            activation = tensor.cpu().numpy()\n",
        "            activations.append(activation)\n",
        "\n",
        "    print(f\"Extracted activations for {len(activations)} images\")\n",
        "    return activations\n",
        "\n",
        "\n",
        "def process_images_in_folder(model, folder_path, layer, is_two, batch_size=1):\n",
        "    all_layer_activations = []\n",
        "\n",
        "    # Ensure folder_path is a string\n",
        "    if not isinstance(folder_path, str):\n",
        "        raise ValueError(f\"Expected folder_path to be a string, but got {type(folder_path)}\")\n",
        "\n",
        "    # Get all image file paths\n",
        "    image_paths = [os.path.join(root, file)\n",
        "                   for root, dirs, files in os.walk(folder_path)\n",
        "                   for file in files if file.endswith(('.jpg', '.png'))]\n",
        "\n",
        "    if len(image_paths) == 0:\n",
        "        raise ValueError(f\"No image files found in folder: {folder_path}\")\n",
        "\n",
        "    print(f\"Initializing dataset with {len(image_paths)} images and is_two={is_two}\")\n",
        "    # Create the dataset and DataLoader\n",
        "    dataset = ImageDataset(image_paths=image_paths, transform=preprocess)\n",
        "    print(f\"Dataset initialized with {len(dataset)} items.\")\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Prepare dictionary for activations\n",
        "    activations_dict = {}\n",
        "\n",
        "    # Define the hook for the specified layer\n",
        "    def hook(module, input, output):\n",
        "        activations_dict[layer] = output\n",
        "\n",
        "    # Register hook for the specified layer\n",
        "    if layer == 'fc2':\n",
        "        model.classifier[4].register_forward_hook(hook)  # Attach to fc2's Linear layer\n",
        "\n",
        "    # Iterate over the dataloader to extract activations\n",
        "    for images in dataloader:  # Only images are returned by the dataset\n",
        "        if images is None:\n",
        "            print(\"Skipping invalid batch.\")\n",
        "            continue\n",
        "\n",
        "        images = images.to(next(model.parameters()).device)  # Move images to the same device as the model\n",
        "        _ = model(images)  # Forward pass to trigger hooks\n",
        "\n",
        "        # Collect activations from the specified layer\n",
        "        if layer in activations_dict:\n",
        "            all_layer_activations.append(activations_dict[layer].cpu().numpy())\n",
        "\n",
        "    if len(all_layer_activations) == 0:\n",
        "        raise ValueError(\"No activations were collected. Check dataset or model.\")\n",
        "\n",
        "    # Concatenate activations if batched\n",
        "    all_layer_activations = np.concatenate(all_layer_activations, axis=0)\n",
        "\n",
        "    # Free resources\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return all_layer_activations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3yFGpq9sgdh"
      },
      "outputs": [],
      "source": [
        "def flatten_and_align_activations(activations_list):\n",
        "    print(\"Flattening and aligning activations\")\n",
        "    flat_activations = [act.flatten() for act in activations_list]\n",
        "    max_length = max(len(act) for act in flat_activations)\n",
        "\n",
        "    aligned_activations = []\n",
        "    for activation in flat_activations:\n",
        "        if len(activation) < max_length:\n",
        "            padded_activation = np.pad(activation, (0, max_length - len(activation)), 'constant')\n",
        "        else:\n",
        "            padded_activation = activation[:max_length]\n",
        "        aligned_activations.append(padded_activation)\n",
        "    print(f\"Aligned activations to shape: {np.vstack(aligned_activations).shape}\")\n",
        "    return np.vstack(aligned_activations)\n",
        "\n",
        "\n",
        "def save_activations(activations, folder_name, filename): #?????\n",
        "    try:\n",
        "        drive_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/{folder_name}/foreground/{filename}.npy'\n",
        "        os.makedirs(os.path.dirname(drive_path), exist_ok=True)\n",
        "        print(f\"Saving activations to {drive_path}\")\n",
        "        np.save(drive_path, activations)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving activations to {drive_path}: {e}\")\n",
        "\n",
        "def load_activations(folder_name, filename):\n",
        "    try:\n",
        "        drive_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/{folder_name}/foreground/{filename}.npy'\n",
        "        print(f\"Loading activations from {drive_path}\")\n",
        "        return np.load(drive_path, allow_pickle=True)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Activations not found at {drive_path}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju51lXuYZyT3"
      },
      "outputs": [],
      "source": [
        "#############TEMP#################\n",
        "def load_model(model_path, freeze_layers=True, pretrained=False):\n",
        "    \"\"\"\n",
        "    Loads an AlexNet model, updates it for binary classification, and optionally freezes layers.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the saved model weights.\n",
        "        freeze_layers (bool): Whether to freeze all layers except the classifier.\n",
        "        pretrained (bool): Whether to use pretrained weights (e.g., from ImageNet) for initialization.\n",
        "\n",
        "    Returns:\n",
        "        model: The loaded and configured AlexNet model.\n",
        "    \"\"\"\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load AlexNet with or without pretrained weights\n",
        "    model = models.alexnet(pretrained=pretrained)\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)  # Update the final layer for binary classification\n",
        "\n",
        "    # Load the saved weights\n",
        "    state_dict = torch.load(model_path, map_location=device)\n",
        "\n",
        "    # Handle mismatched keys\n",
        "    try:\n",
        "        model.load_state_dict(state_dict)\n",
        "    except RuntimeError as e:\n",
        "        print(\"State_dict mismatch detected. Attempting to adjust keys...\")\n",
        "        # Check if keys can be remapped to match AlexNet\n",
        "        adjusted_state_dict = {}\n",
        "        for key, value in state_dict.items():\n",
        "            if key in model.state_dict():\n",
        "                adjusted_state_dict[key] = value\n",
        "            else:\n",
        "                print(f\"Skipping unexpected key in state_dict: {key}\")\n",
        "\n",
        "        # Load the adjusted state_dict\n",
        "        model.load_state_dict(adjusted_state_dict, strict=False)\n",
        "        print(\"Adjusted state_dict loaded successfully.\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    print(\"Model loaded successfully\")\n",
        "\n",
        "    # Optionally freeze all layers\n",
        "    if freeze_layers:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        print(\"All layers frozen successfully\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def attach_fc2_hook(model):\n",
        "    \"\"\"\n",
        "    Attaches a forward hook to capture activations from fc2.\n",
        "\n",
        "    Args:\n",
        "        model: The model to attach the hook to.\n",
        "\n",
        "    Returns:\n",
        "        activations (dict): A dictionary to store captured activations.\n",
        "    \"\"\"\n",
        "    activations = {\"fc2\": []}  # Use a list to accumulate activations\n",
        "\n",
        "    def hook(module, input, output):\n",
        "        activations[\"fc2\"].append(output.cpu().numpy())  # Append activations\n",
        "\n",
        "    model.classifier[4].register_forward_hook(hook)\n",
        "    print(\"Hook attached to fc2 successfully\")\n",
        "    return activations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1LM8UFosmAh"
      },
      "outputs": [],
      "source": [
        "# adjusted\n",
        "def compute_activations_for_layers(model_paths, folder_paths, layers, activations_file_prefix):\n",
        "    # Initialize the dictionary with all keys in folder_paths\n",
        "    all_layer_activations = {layer: {key: [] for key in folder_paths.keys()} for layer in layers}\n",
        "\n",
        "    for folder_name, folder_path in folder_paths.items():\n",
        "        print(f\"Processing folder {folder_name}\")\n",
        "\n",
        "        # Get the is_two value from the mapping\n",
        "        is_two = is_two_mapping.get(folder_name)\n",
        "        if is_two is None:\n",
        "            raise ValueError(f\"Unknown folder name: {folder_name}. Please update is_two_mapping.\")\n",
        "\n",
        "        for layer in layers:\n",
        "            for model_idx, model_path in enumerate(model_paths):\n",
        "                print(f\"Processing model {model_idx + 1}/{len(model_paths)}\")\n",
        "\n",
        "                # Define the specific activation file path\n",
        "                model_specific_file_prefix = f'{activations_file_prefix}_model{model_idx + 1}_{folder_name}'\n",
        "                activation_file_path = f'layer_{layer}_{model_specific_file_prefix}.npy'\n",
        "\n",
        "                # Check if the activation file already exists\n",
        "                if os.path.exists(activation_file_path):\n",
        "                    print(f\"Activation file {activation_file_path} already exists. Skipping computation.\")\n",
        "                    # Load existing activations to the dictionary\n",
        "                    existing_activations = np.load(activation_file_path, allow_pickle=True)\n",
        "                    all_layer_activations[layer][folder_name].append(existing_activations)\n",
        "                    continue\n",
        "\n",
        "                # Load the model\n",
        "                model = load_model(model_path, freeze_layers=True, pretrained=False)\n",
        "\n",
        "                # Attach hook to capture activations\n",
        "                activations = attach_fc2_hook(model)\n",
        "\n",
        "                # Compute activations\n",
        "                activations_result = process_images_in_folder(model, folder_path, layer, is_two=is_two, batch_size=1)\n",
        "\n",
        "                # Flatten and align activations\n",
        "                activations_result = flatten_and_align_activations(activations_result)\n",
        "\n",
        "                # Save activations for this model and folder\n",
        "                save_activations(activations_result, f'layer_{layer}', model_specific_file_prefix)\n",
        "\n",
        "                # Add activations to the dictionary\n",
        "                all_layer_activations[layer][folder_name].append(activations_result)\n",
        "\n",
        "                # Cleanup to free memory\n",
        "                del model\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "    return all_layer_activations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Extract Training Activations\n",
        "\n",
        "model_paths = [\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_11.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_111.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1111.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_11111.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_111111.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1111111.pt\"\n",
        "]\n",
        "\n",
        "layers_of_interest = ['fc2']\n",
        "\n",
        "is_two_mapping = {\n",
        "    'two_no_patch': 1,\n",
        "    'zero_no_patch': 0,\n",
        "    'zero_patch': 0\n",
        "}\n",
        "\n",
        "\n",
        "# Paths to training data\n",
        "train_folder_paths = {\n",
        "    'two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_2',\n",
        "    'zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_0',\n",
        "    'zero_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/train/class_0'\n",
        "}\n",
        "\n",
        "\n",
        "val_folder_paths = {\n",
        "    'two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_2_200',\n",
        "    'zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_200',\n",
        "    'zero_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0_200'\n",
        "}\n",
        "\n",
        "\n",
        "# Extract and save averaged training activations across three models\n",
        "#train_activations = compute_activations_for_layers(model_paths, train_folder_paths, layers_of_interest, 'train')\n",
        "#val_activations = compute_activations_for_layers(model_paths, val_folder_paths, layers_of_interest, 'val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I1fCyvQ2cBS"
      },
      "source": [
        "### Load saved activations of the fc2 alexnet training to later train the SAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a59xOvVP2DWC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_saved_activations(subset, activations_file_prefix, model_idx=None, dataset_type=\"train\"):\n",
        "    \"\"\"\n",
        "    Load saved activations from files with the format: {dataset_type}_model{idx}_{subset}.npy.\n",
        "\n",
        "    Parameters:\n",
        "        subset (str): The data subset (e.g., \"two_no_patch\", \"zero_no_patch\", \"zero_patch\").\n",
        "        activations_file_prefix (str): File prefix for the activations.\n",
        "        model_idx (int or None): Specific model index to load (e.g., 1, 2, 3). If None, load all models.\n",
        "        dataset_type (str): The dataset type (\"train\" or \"val\").\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray or List[np.ndarray]: Loaded activations for a specific model (if model_idx is provided)\n",
        "                                        or a list of activations for all models.\n",
        "    \"\"\"\n",
        "    activations = []\n",
        "\n",
        "    if model_idx is not None:\n",
        "        # Load activations for a specific model\n",
        "        drive_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/{dataset_type}_model{model_idx}_{subset}.npy'\n",
        "        print(f\"Loading activations from {drive_path}\")\n",
        "\n",
        "        if os.path.exists(drive_path):\n",
        "            model_activations = np.load(drive_path, allow_pickle=True)\n",
        "            print(f\"Loaded activations for subset {subset}, dataset {dataset_type}, model {model_idx}. Shape: {model_activations.shape}\")\n",
        "            return model_activations\n",
        "        else:\n",
        "            print(f\"Activations file {drive_path} does not exist.\")\n",
        "            return None\n",
        "    else:\n",
        "        # Load activations for all models\n",
        "        for idx in range(1, 6):  # Adjust the range based on the number of models !!!\n",
        "            drive_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/{dataset_type}_model{idx}_{subset}.npy'\n",
        "            print(f\"Loading activations from {drive_path}\")\n",
        "\n",
        "            if os.path.exists(drive_path):\n",
        "                model_activations = np.load(drive_path, allow_pickle=True)\n",
        "                print(f\"Loaded activations for subset {subset}, dataset {dataset_type}, model {idx}. Shape: {model_activations.shape}\")\n",
        "                activations.append(model_activations)\n",
        "            else:\n",
        "                print(f\"Activations file {drive_path} does not exist.\")\n",
        "\n",
        "        if len(activations) > 0:\n",
        "            print(f\"Loaded activations for {len(activations)} model(s).\")\n",
        "            return activations  # List of numpy arrays, one for each model\n",
        "        else:\n",
        "            print(\"No activations files found.\")\n",
        "            return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ikq6cjxO23WR"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define Sparse Autoencoder with KL-divergence\n",
        "class SparseAutoencoder(nn.Module):\n",
        "    def __init__(self, in_dims, h_dims, sparsity_lambda=1.5, sparsity_target=0.20, xavier_norm_init=True):\n",
        "        super(SparseAutoencoder, self).__init__()\n",
        "        self.in_dims = in_dims  # Input dimension (number of neurons in the input layer)\n",
        "        self.h_dims = h_dims  # Hidden dimension (number of neurons in the hidden layer)\n",
        "        self.sparsity_lambda = sparsity_lambda  # Weight for the sparsity penalty term\n",
        "        self.sparsity_target = sparsity_target  # Target sparsity (desired average activation)\n",
        "\n",
        "        # Encoder: Projects input to the hidden (sparse) space\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.in_dims, self.h_dims),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        if xavier_norm_init:\n",
        "            nn.init.xavier_uniform_(self.encoder[0].weight)  # Xavier initialization\n",
        "\n",
        "        # Decoder: Reconstructs the input from the hidden (sparse) representation\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.h_dims, self.in_dims),\n",
        "            #nn.ReLU()\n",
        "        )\n",
        "        if xavier_norm_init:\n",
        "            nn.init.xavier_uniform_(self.decoder[0].weight)\n",
        "\n",
        "    # Forward pass through the encoder and decoder\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)  # Pass input through encoder\n",
        "        decoded = self.decoder(encoded)  # Pass encoded (sparse) representation through decoder\n",
        "        return encoded, decoded\n",
        "\n",
        "\n",
        "    def kl_sparsity_penalty(self, encoded):\n",
        "        # Penalize the average absolute activation\n",
        "        rho_hat = torch.mean(torch.abs(encoded), dim=0)  # Average absolute activation per hidden unit\n",
        "        rho = torch.ones_like(rho_hat) * self.sparsity_target  # Target sparsity value\n",
        "        epsilon = 1e-8  # Small value to avoid log(0)\n",
        "\n",
        "        # KL-divergence computation for sparsity\n",
        "        kl_divergence = rho * torch.log(rho / (rho_hat + epsilon)) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat + epsilon))\n",
        "        kl_divergence = torch.sum(kl_divergence)  # Sum over all hidden units\n",
        "\n",
        "        return self.sparsity_lambda * kl_divergence\n",
        "\n",
        "\n",
        "\n",
        "    # L1-norm sparsity penalty calculation\n",
        "    def l1_sparsity_penalty(self, encoded):\n",
        "        # Compute the mean of absolute values of activations\n",
        "        sparsity_loss = torch.mean(torch.abs(encoded))  # Average absolute activation across all units\n",
        "        return self.sparsity_lambda * sparsity_loss  # Scale by the sparsity weight\n",
        "\n",
        "\n",
        "    # KL-divergence sparsity penalty calculation\n",
        "    def old_kl_sparsity_penalty(self, encoded):\n",
        "        rho_hat = torch.mean(encoded, dim=0)  # Compute the average activation for each hidden neuron\n",
        "        rho = torch.ones_like(rho_hat) * self.sparsity_target  # Target sparsity value\n",
        "        epsilon = 1e-8  # Small value to avoid log(0)\n",
        "        kl_divergence = F.kl_div((rho_hat + epsilon).log(), rho + epsilon, reduction='batchmean')  # KL-divergence\n",
        "        return self.sparsity_lambda * kl_divergence  # Return the sparsity penalty, weighted by lambda\n",
        "\n",
        "    # Loss function combining MSE (reconstruction error) and sparsity penalty\n",
        "    def loss_function(self, decoded, original, encoded):\n",
        "        mse_loss = F.mse_loss(decoded, original)  # Mean Squared Error for reconstruction\n",
        "        sparsity_loss = self.l1_sparsity_penalty(encoded)  # Sparsity penalty for hidden layer activations\n",
        "        return mse_loss + sparsity_loss  # Total loss is MSE + sparsity penalty\n",
        "\n",
        "\n",
        "# Early stopping mechanism to prevent overfitting\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=30, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta  # Minimum change to qualify as an improvement\n",
        "        self.best_loss = None  # Best validation loss observed so far\n",
        "        self.counter = 0  # Counter to keep track of how many epochs since the last improvement\n",
        "\n",
        "    # Check if training should be stopped based on validation loss\n",
        "    def check(self, loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = loss  # Set the initial best loss\n",
        "            return False\n",
        "\n",
        "        # If the loss has improved significantly\n",
        "        if loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = loss  # Update best loss\n",
        "            self.counter = 0  # Reset counter\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1  # Increment counter if no improvement\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"Early stopping triggered.\")  # Stop training if patience is exceeded\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "\n",
        "# Training Function with Loss Tracking and Plotting\n",
        "def train_autoencoder(autoencoder, train_data, val_data, num_epochs=400, batch_size=128, learning_rate=1e-4, validation_split=0.2, clip_gradients=True, max_grad_norm=0.5):\n",
        "    #print(f\"Training autoencoder with input dim {data.shape[1]} and encoding dim {autoencoder.h_dims}\")\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    #num_train = int((1 - validation_split) * len(train_data))  # Compute the number of training samples\n",
        "    #train_data = train_data[:num_train]  # Training data\n",
        "    #val_data = train_data[num_train:]  # Validation data\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_tensor = torch.from_numpy(train_data).float()\n",
        "    val_tensor = torch.from_numpy(val_data).float()\n",
        "    # Create PyTorch datasets and dataloaders for training and validation\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_data).float())\n",
        "    val_dataset = torch.utils.data.TensorDataset(torch.from_numpy(val_data).float())\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Adam optimizer with learning rate and weight decay for regularization\n",
        "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate, weight_decay=1e-2)\n",
        "\n",
        "    # Initialize early stopping\n",
        "    early_stopping = EarlyStopping(patience=30, min_delta=0.001)\n",
        "\n",
        "    # Lists to store training and validation loss values\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # Start training loop\n",
        "    autoencoder.train()  # Set the autoencoder in training mode\n",
        "    for epoch in range(num_epochs):\n",
        "        total_train_loss = 0  # Initialize training loss for the current epoch\n",
        "\n",
        "        # Iterate over batches in the training set\n",
        "        for x_batch, in train_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "            encoded, decoded = autoencoder(x_batch)  # Forward pass through autoencoder\n",
        "            loss = autoencoder.loss_function(decoded, x_batch, encoded)  # Compute the loss\n",
        "            loss.backward()  # Backpropagate the error\n",
        "\n",
        "            # Apply gradient clipping if enabled\n",
        "            if clip_gradients:\n",
        "                torch.nn.utils.clip_grad_norm_(autoencoder.parameters(), max_grad_norm)\n",
        "\n",
        "            optimizer.step()  # Update the weights using the optimizer\n",
        "            total_train_loss += loss.item()  # Accumulate training loss for this batch\n",
        "\n",
        "        # Validation step after each epoch\n",
        "        total_val_loss = 0  # Initialize validation loss\n",
        "        autoencoder.eval()  # Set the autoencoder in evaluation mode\n",
        "        with torch.no_grad():  # No gradient calculation in validation mode\n",
        "            for x_batch, in val_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                encoded, decoded = autoencoder(x_batch)\n",
        "                loss = autoencoder.loss_function(decoded, x_batch, encoded)\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "        # Compute the average training and validation loss for this epoch\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        # Store the loss values for plotting later\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Print progress for the current epoch\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}')\n",
        "\n",
        "        # Check early stopping condition based on validation loss\n",
        "        if early_stopping.check(avg_val_loss):\n",
        "            break\n",
        "\n",
        "    print(\"Autoencoder training completed\")\n",
        "\n",
        "    # Plot the training and validation loss over epochs\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHcW0D47E2K4",
        "outputId": "81757d8b-bb49-4000-bc0b-188f9d31eee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Define the directory to save autoencoders trained on normalized activations\\nsave_sae_dir = \\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground\\'  # Directory to save the trained autoencoder\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\nos.makedirs(save_sae_dir, exist_ok=True)\\nlayers_of_interest = [\\'fc2\\']\\n\\n# Iterate through layers of interest\\nfor layer in layers_of_interest:\\n    print(f\\'\\nTraining autoencoders for layer {layer}\\')\\n\\n    # Iterate through seeds (corresponding to models)\\n    for seed_idx, seed in enumerate([1, 11, 111, 1111, 11111, 111111, 1111111], start=1):\\n        print(f\"\\nProcessing activations for layer {layer}, seed {seed} (Model {seed_idx})\")\\n\\n        # Get training activations for the current seed and layer\\n        train_activations_list = []\\n        print(f\"\\nTrain files associated with seed {seed}:\")\\n        idx = seed_idx #!!!!!!!!!!!!!!\\n        for subset in [\\'two_no_patch\\', \\'zero_no_patch\\', \\'zero_patch\\'] :\\n                #train_file_path = f\\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/alexnet_mnist_finetune_fg/train_model{idx}_{subset}.npy\\'\\n            train_file_path = f\\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/foreground/train_model{idx}_{subset}.npy\\'\\n            if os.path.exists(train_file_path):\\n                subset_activations = np.load(train_file_path)  # Load the .npy file\\n                train_activations_list.append(subset_activations)\\n                print(f\"  - Subset: {subset}, File: {train_file_path}\")\\n            else:\\n                print(f\"Warning: File not found - {train_file_path}\")\\n\\n        if len(train_activations_list) == 0:\\n            print(f\"No train activations found for layer {layer}, seed {seed}. Skipping...\")\\n            continue\\n\\n        # Combine train activations\\n        combined_train_activations = np.vstack(train_activations_list)\\n        print(f\"Combined train activations shape for layer {layer}, seed {seed}: {combined_train_activations.shape}\")\\n\\n        # Get validation activations for the current seed and layer\\n        val_activations_list = []\\n        print(f\"\\nValidation files associated with seed {seed}:\")\\n        idx = seed_idx #!!!!!!!!!\\n        for subset in [\\'two_no_patch\\', \\'zero_no_patch\\', \\'zero_patch\\']:\\n            val_file_path = f\\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/foreground/val_model{idx}_{subset}.npy\\'\\n            if os.path.exists(val_file_path):\\n                subset_activations = np.load(val_file_path)  # Load the .npy file\\n                val_activations_list.append(subset_activations)\\n                print(f\"  - Subset: {subset}, File: {val_file_path}\")\\n            else:\\n                print(f\"Warning: File not found - {val_file_path}\")\\n\\n        if len(val_activations_list) == 0:\\n            print(f\"No val activations found for layer {layer}, seed {seed}. Skipping...\")\\n            continue\\n\\n        # Combine val activations\\n        combined_val_activations = np.vstack(val_activations_list)\\n        print(f\"Combined val activations shape for layer {layer}, seed {seed}: {combined_val_activations.shape}\")\\n\\n        # Set the random seed for reproducibility\\n        torch.manual_seed(seed)\\n        np.random.seed(seed)\\n\\n        # Define encoding dimension\\n        encoding_dim = 16000\\n\\n        # Train autoencoder on unnormalized activations\\n        autoencoder = SparseAutoencoder(combined_train_activations.shape[1], encoding_dim).to(device)\\n        print(f\"Training autoencoder for layer {layer} (unnormalized, seed {seed})\")\\n        autoencoder = train_autoencoder(autoencoder, combined_train_activations, combined_val_activations,\\n                                        num_epochs=400, learning_rate=1e-4)\\n        # Print losses for inspection\\n        #print(f\"Training Losses for layer {layer}, seed {seed}: {train_losses}\")\\n\\n        #print(f\"Validation Losses for layer {layer}, seed {seed}: {val_losses}\")\\n        # Save the trained autoencoder\\n        save_path_unnormalized = os.path.join(\\n            save_sae_dir, f\\'l1_fg_autoencoder_layer_{layer}_seed_{seed}.pth\\'\\n        )\\n        torch.save(autoencoder.state_dict(), save_path_unnormalized)\\n        print(f\"Saved autoencoder at {save_path_unnormalized}\")\\n\\n        # Clear memory\\n        del autoencoder\\n        torch.cuda.empty_cache()\\n        gc.collect()\\n\\nprint(\"\\nAll autoencoders trained and saved successfully.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import gc\n",
        "'''\n",
        "# Define the directory to save autoencoders trained on normalized activations\n",
        "save_sae_dir = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground'  # Directory to save the trained autoencoder\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "os.makedirs(save_sae_dir, exist_ok=True)\n",
        "layers_of_interest = ['fc2']\n",
        "\n",
        "# Iterate through layers of interest\n",
        "for layer in layers_of_interest:\n",
        "    print(f'\\nTraining autoencoders for layer {layer}')\n",
        "\n",
        "    # Iterate through seeds (corresponding to models)\n",
        "    for seed_idx, seed in enumerate([1, 11, 111, 1111, 11111, 111111, 1111111], start=1):\n",
        "        print(f\"\\nProcessing activations for layer {layer}, seed {seed} (Model {seed_idx})\")\n",
        "\n",
        "        # Get training activations for the current seed and layer\n",
        "        train_activations_list = []\n",
        "        print(f\"\\nTrain files associated with seed {seed}:\")\n",
        "        idx = seed_idx #!!!!!!!!!!!!!!\n",
        "        for subset in ['two_no_patch', 'zero_no_patch', 'zero_patch'] :\n",
        "                #train_file_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/alexnet_mnist_finetune_fg/train_model{idx}_{subset}.npy'\n",
        "            train_file_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/foreground/train_model{idx}_{subset}.npy'\n",
        "            if os.path.exists(train_file_path):\n",
        "                subset_activations = np.load(train_file_path)  # Load the .npy file\n",
        "                train_activations_list.append(subset_activations)\n",
        "                print(f\"  - Subset: {subset}, File: {train_file_path}\")\n",
        "            else:\n",
        "                print(f\"Warning: File not found - {train_file_path}\")\n",
        "\n",
        "        if len(train_activations_list) == 0:\n",
        "            print(f\"No train activations found for layer {layer}, seed {seed}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Combine train activations\n",
        "        combined_train_activations = np.vstack(train_activations_list)\n",
        "        print(f\"Combined train activations shape for layer {layer}, seed {seed}: {combined_train_activations.shape}\")\n",
        "\n",
        "        # Get validation activations for the current seed and layer\n",
        "        val_activations_list = []\n",
        "        print(f\"\\nValidation files associated with seed {seed}:\")\n",
        "        idx = seed_idx #!!!!!!!!!\n",
        "        for subset in ['two_no_patch', 'zero_no_patch', 'zero_patch']:\n",
        "            val_file_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/foreground/val_model{idx}_{subset}.npy'\n",
        "            if os.path.exists(val_file_path):\n",
        "                subset_activations = np.load(val_file_path)  # Load the .npy file\n",
        "                val_activations_list.append(subset_activations)\n",
        "                print(f\"  - Subset: {subset}, File: {val_file_path}\")\n",
        "            else:\n",
        "                print(f\"Warning: File not found - {val_file_path}\")\n",
        "\n",
        "        if len(val_activations_list) == 0:\n",
        "            print(f\"No val activations found for layer {layer}, seed {seed}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Combine val activations\n",
        "        combined_val_activations = np.vstack(val_activations_list)\n",
        "        print(f\"Combined val activations shape for layer {layer}, seed {seed}: {combined_val_activations.shape}\")\n",
        "\n",
        "        # Set the random seed for reproducibility\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # Define encoding dimension\n",
        "        encoding_dim = 16000\n",
        "\n",
        "        # Train autoencoder on unnormalized activations\n",
        "        autoencoder = SparseAutoencoder(combined_train_activations.shape[1], encoding_dim).to(device)\n",
        "        print(f\"Training autoencoder for layer {layer} (unnormalized, seed {seed})\")\n",
        "        autoencoder = train_autoencoder(autoencoder, combined_train_activations, combined_val_activations,\n",
        "                                        num_epochs=400, learning_rate=1e-4)\n",
        "        # Print losses for inspection\n",
        "        #print(f\"Training Losses for layer {layer}, seed {seed}: {train_losses}\")\n",
        "\n",
        "        #print(f\"Validation Losses for layer {layer}, seed {seed}: {val_losses}\")\n",
        "        # Save the trained autoencoder\n",
        "        save_path_unnormalized = os.path.join(\n",
        "            save_sae_dir, f'l1_fg_autoencoder_layer_{layer}_seed_{seed}.pth'\n",
        "        )\n",
        "        torch.save(autoencoder.state_dict(), save_path_unnormalized)\n",
        "        print(f\"Saved autoencoder at {save_path_unnormalized}\")\n",
        "\n",
        "        # Clear memory\n",
        "        del autoencoder\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "print(\"\\nAll autoencoders trained and saved successfully.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBqV-qTGG69r"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained autoencoder for layer 6 (fc2) (from snippet 4)\n",
        "def load_autoencoder(device, save_sae_dir):\n",
        "    \"\"\"\n",
        "    Load a pre-trained sparse autoencoder and freeze its parameters.\n",
        "    \"\"\"\n",
        "    input_dims = 4096\n",
        "    encoding_dim = 16000\n",
        "\n",
        "    # Initialize the autoencoder\n",
        "    autoencoder = SparseAutoencoder(input_dims, encoding_dim)\n",
        "    autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n",
        "    autoencoder = autoencoder.to(device)  # Move model to device\n",
        "\n",
        "    # Freeze all parameters of the autoencoder\n",
        "    for param in autoencoder.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Set the autoencoder to evaluation mode\n",
        "    autoencoder.eval()\n",
        "    print(f\"Autoencoder loaded from {save_sae_dir} and frozen successfully.\")\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "\n",
        "####################\n",
        "\n",
        "def load_model(saved_weights_path, device):\n",
        "    \"\"\"\n",
        "    Loads a trained PyTorch AlexNet model, freezes all layers up to fc2,\n",
        "    and prepares it for passing activations through classifier[5] and classifier[6].\n",
        "\n",
        "    Args:\n",
        "        saved_weights_path (str): Path to the saved weights of the trained AlexNet model.\n",
        "        device (torch.device): The device to load the model onto (e.g., torch.device('cuda') or torch.device('cpu')).\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: The loaded and partially frozen PyTorch AlexNet model.\n",
        "    \"\"\"\n",
        "    # Load the PyTorch AlexNet model\n",
        "    print(f\"Loading model from {saved_weights_path}\")\n",
        "    model = models.alexnet(pretrained=False)  # Load AlexNet without pretrained weights\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)  # Update the last layer for binary classification\n",
        "\n",
        "    # Load the saved weights\n",
        "    model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n",
        "    model.to(device)\n",
        "\n",
        "    # Freeze all layers except `classifier[5]` (ReLU) and `classifier[6]` (fc3)\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"classifier.6\"):  # classifier[6] corresponds to fc3\n",
        "            param.requires_grad = True\n",
        "        elif name.startswith(\"classifier.5\"):  # ReLU does not have trainable params\n",
        "            param.requires_grad = True\n",
        "        else:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    print(\"Model loaded and all layers up to fc2 are frozen\")\n",
        "    return model\n",
        "\n",
        "# Code 1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45Rf_hs5HQkr"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist\"\n",
        "activation_dir = os.path.join(base_dir, \"activations\")\n",
        "output_base_dir = os.path.join(base_dir, \"outputs\")\n",
        "Path(output_base_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# Define paths for pre-saved activations\n",
        "def get_activation_path(folder_name, filename):\n",
        "    return os.path.join(activation_dir, folder_name, f\"{filename}.npy\")\n",
        "\n",
        "\n",
        "def extract_fc2_activations(model, dataloader, activations_dict):\n",
        "\n",
        "    print(\"Extracting AlexNet activations for layer fc2 using hooks...\")\n",
        "\n",
        "    # Ensure the model is in evaluation mode\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device  # Get the model's device\n",
        "    activations_dict[\"fc2\"] = []  # Reset to store activations for this extraction\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch_idx, (image_tensor, _) in enumerate(dataloader):\n",
        "            # Move image tensor to the device\n",
        "            image_tensor = image_tensor.to(device)\n",
        "\n",
        "            # Forward pass through the model (hook captures fc2 activations)\n",
        "            _ = model(image_tensor)\n",
        "\n",
        "            # Log progress\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"Processed {batch_idx + 1}/{len(dataloader)} batches ({len(activations_dict['fc2'])} samples captured)\")\n",
        "\n",
        "            # Clear resources\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    # Stack all activations into a single array\n",
        "    activations = np.vstack(activations_dict[\"fc2\"])  # Stack the activations\n",
        "    print(f\"Extraction complete. Collected activations for {len(activations)} samples.\")\n",
        "    return activations\n",
        "\n",
        "\n",
        "\n",
        "# adjusted\n",
        "\n",
        "def load_or_extract_fc2_activations(model, dataloader, folder_name, filename):\n",
        "    \"\"\"\n",
        "    Load pre-saved activations if available, otherwise extract and save them.\n",
        "\n",
        "    Args:\n",
        "        model: The AlexNet model with hooks attached.\n",
        "        dataloader: DataLoader for the dataset.\n",
        "        folder_name: Directory where activations are stored.\n",
        "        filename: Name of the file to load or save activations.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The activations (loaded or extracted).\n",
        "    \"\"\"\n",
        "    # Generate activation file path\n",
        "    activation_path = get_activation_path(folder_name, filename)\n",
        "\n",
        "    # Check if the activation file exists\n",
        "    if os.path.exists(activation_path):\n",
        "        print(f\"Loading pre-saved AlexNet activations for {filename} from {activation_path}...\")\n",
        "        activations = np.load(activation_path, allow_pickle=True)\n",
        "    else:\n",
        "        print(f\"No pre-saved AlexNet activations found for {filename}. Extracting and saving...\")\n",
        "\n",
        "        # Attach hook if not already done externally\n",
        "        activations_dict = attach_fc2_hook(model)\n",
        "\n",
        "        # Perform activation extraction and store the returned activations\n",
        "        activations = extract_fc2_activations(model, dataloader, activations_dict)\n",
        "\n",
        "        # Ensure the directory exists and save activations\n",
        "        os.makedirs(os.path.dirname(activation_path), exist_ok=True)\n",
        "        np.save(activation_path, activations)\n",
        "        print(f\"Activations for layer fc2 saved to {activation_path}\")\n",
        "\n",
        "    return activations\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "SGZlu8uVxynF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gas8yiO8jsEC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def main():\n",
        "    # Paths and initialization\n",
        "    model_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_11.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_111.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1111.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_11111.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_111111.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1111111.pt\"\n",
        "    ]\n",
        "\n",
        "    # Define dataset paths\n",
        "    dataset_paths = {\n",
        "        \"test_two_fg_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/test/class_2_100',\n",
        "        \"test_two_org_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_2_100',\n",
        "        \"test_zero_fg_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/test/class_0_100',\n",
        "        \"test_zero_org_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_0_100',\n",
        "        \"val_zero_org_200\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_200',\n",
        "        \"val_zero_org_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_100',\n",
        "        \"val_zero_org_50\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_50',\n",
        "        \"val_zero_org_25\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_25',\n",
        "        \"val_zero_fg_200\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0_200',\n",
        "        \"val_zero_fg_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0_100',\n",
        "        \"val_zero_fg_50\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0_50',\n",
        "        \"val_zero_fg_25\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0_25',\n",
        "\n",
        "\n",
        "        #\"val_zero_fg\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0'\n",
        "    }\n",
        "    # Prepare dataloaders\n",
        "    dataloaders = {}\n",
        "    for key, folder in dataset_paths.items():\n",
        "        image_paths = [\n",
        "            os.path.join(root, file)\n",
        "            for root, dirs, files in os.walk(folder)\n",
        "            for file in files if file.endswith(('.jpg', '.png'))\n",
        "        ]\n",
        "        # Use is_two = 1 if \"two\" is in the key, else 0\n",
        "        dataset = MnistDataset(data_files=image_paths, is_two=1 if \"two\" in key else 0)\n",
        "        dataloaders[key] = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Directory for saving results\n",
        "    sparse_output_dir = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground\"\n",
        "    os.makedirs(sparse_output_dir, exist_ok=True)\n",
        "\n",
        "    # Loop over models\n",
        "    for model_path in model_paths:\n",
        "        print(f\"Processing model: {model_path}\")\n",
        "\n",
        "        # Load the model\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        activations_dict = attach_fc2_hook(model)  # Attach the hook for fc2 activations\n",
        "\n",
        "\n",
        "        # Process each dataset\n",
        "        for key, loader in dataloaders.items():\n",
        "            print(f\"Processing dataset: {key}\")\n",
        "\n",
        "            # Reinitialize activations_dict[\"fc2\"] for each dataset\n",
        "            activations_dict[\"fc2\"] = []  # Reset fc2 activations\n",
        "            # Extract activations\n",
        "            activations = load_or_extract_fc2_activations(\n",
        "                model, loader, f'{key}_{Path(model_path).stem}', f'fg_fc2_activations_{key}_{Path(model_path).stem}'\n",
        "            )\n",
        "\n",
        "            # Save activations\n",
        "            activation_path = os.path.join(sparse_output_dir, f\"fc2_activations_{key}_{Path(model_path).stem}.npy\")\n",
        "            np.save(activation_path, activations)\n",
        "            print(f\"Activations for {key} saved to: {activation_path}\")\n",
        "            # Clear activations for the next dataset\n",
        "            activations_dict[\"fc2\"] = None\n",
        "#main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXaqY0YfH8dQ"
      },
      "source": [
        "continue starting from here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 200"
      ],
      "metadata": {
        "id": "LoDHYLVs1iel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IiugMo8c4yv",
        "outputId": "0f8e3a0b-4adb-44bc-b43d-5b36f3ae411d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Seed 1\n",
            "Loading model from /content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-15-ee25108bcc59>:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and all layers up to fc2 are frozen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ee25108bcc59>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder loaded from /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_1.pth and frozen successfully.\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Testing with 0% muting...\n",
            "Reconstruction Error (Val Patch): 530.8309\n",
            "Reconstruction Error (Val No Patch): 448.9767\n",
            "Reconstruction Error (Test Two Patch): 494.3627\n",
            "Reconstruction Error (Test Two No Patch): 363.1244\n",
            "Reconstruction Error (Test Zero Patch): 524.8580\n",
            "Reconstruction Error (Test Zero No Patch): 424.9435\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 0% neurons (0 neurons) for muting.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1dea879bfb76>:455: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with 1% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 1% neurons (160 neurons) for muting.\n",
            "Testing with 2% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 2% neurons (320 neurons) for muting.\n",
            "Testing with 3% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 3% neurons (480 neurons) for muting.\n",
            "Testing with 4% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 4% neurons (640 neurons) for muting.\n",
            "Testing with 5% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 5% neurons (800 neurons) for muting.\n",
            "Testing with 6% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 6% neurons (960 neurons) for muting.\n",
            "Testing with 7% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 7% neurons (1120 neurons) for muting.\n",
            "Testing with 8% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 8% neurons (1280 neurons) for muting.\n",
            "Testing with 9% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 9% neurons (1440 neurons) for muting.\n",
            "Testing with 10% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 10% neurons (1600 neurons) for muting.\n",
            "Testing with 11% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 11% neurons (1760 neurons) for muting.\n",
            "Testing with 12% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 12% neurons (1920 neurons) for muting.\n",
            "Testing with 13% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 13% neurons (2080 neurons) for muting.\n",
            "Testing with 14% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 14% neurons (2240 neurons) for muting.\n",
            "Testing with 15% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 15% neurons (2400 neurons) for muting.\n",
            "Testing with 16% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 16% neurons (2560 neurons) for muting.\n",
            "Testing with 17% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 17% neurons (2720 neurons) for muting.\n",
            "Testing with 18% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 18% neurons (2880 neurons) for muting.\n",
            "Testing with 19% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 19% neurons (3040 neurons) for muting.\n",
            "Testing with 20% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 20% neurons (3200 neurons) for muting.\n",
            "Testing with 21% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 21% neurons (3360 neurons) for muting.\n",
            "Testing with 22% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 22% neurons (3520 neurons) for muting.\n",
            "Testing with 23% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 23% neurons (3680 neurons) for muting.\n",
            "Testing with 24% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 24% neurons (3840 neurons) for muting.\n",
            "Testing with 25% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 25% neurons (4000 neurons) for muting.\n",
            "Testing with 26% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 26% neurons (4160 neurons) for muting.\n",
            "Testing with 27% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 27% neurons (4320 neurons) for muting.\n",
            "Testing with 28% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 28% neurons (4480 neurons) for muting.\n",
            "Testing with 29% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 29% neurons (4640 neurons) for muting.\n",
            "Testing with 30% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 30% neurons (4800 neurons) for muting.\n",
            "Testing with 31% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 31% neurons (4960 neurons) for muting.\n",
            "Testing with 32% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 32% neurons (5120 neurons) for muting.\n",
            "Testing with 33% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 33% neurons (5280 neurons) for muting.\n",
            "Testing with 34% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 34% neurons (5440 neurons) for muting.\n",
            "Testing with 35% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 35% neurons (5600 neurons) for muting.\n",
            "Testing with 36% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 36% neurons (5760 neurons) for muting.\n",
            "Testing with 37% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 37% neurons (5920 neurons) for muting.\n",
            "Testing with 38% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 38% neurons (6080 neurons) for muting.\n",
            "Testing with 39% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 39% neurons (6240 neurons) for muting.\n",
            "Testing with 40% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 40% neurons (6400 neurons) for muting.\n",
            "Testing with 41% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 41% neurons (6560 neurons) for muting.\n",
            "Testing with 42% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 42% neurons (6720 neurons) for muting.\n",
            "Testing with 43% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 43% neurons (6880 neurons) for muting.\n",
            "Testing with 44% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 44% neurons (7040 neurons) for muting.\n",
            "Testing with 45% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 45% neurons (7200 neurons) for muting.\n",
            "Testing with 46% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 46% neurons (7360 neurons) for muting.\n",
            "Testing with 47% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 47% neurons (7520 neurons) for muting.\n",
            "Testing with 48% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 48% neurons (7680 neurons) for muting.\n",
            "Testing with 49% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 49% neurons (7840 neurons) for muting.\n",
            "Testing with 50% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1_200.csv\n",
            "Loaded top 50% neurons (8000 neurons) for muting.\n",
            "\n",
            "Processing Seed 11\n",
            "Loading model from /content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_11.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-15-ee25108bcc59>:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and all layers up to fc2 are frozen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ee25108bcc59>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder loaded from /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_11.pth and frozen successfully.\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Testing with 0% muting...\n",
            "Reconstruction Error (Val Patch): 545.6232\n",
            "Reconstruction Error (Val No Patch): 467.3105\n",
            "Reconstruction Error (Test Two Patch): 506.2455\n",
            "Reconstruction Error (Test Two No Patch): 375.6068\n",
            "Reconstruction Error (Test Zero Patch): 539.6216\n",
            "Reconstruction Error (Test Zero No Patch): 441.9962\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 0% neurons (0 neurons) for muting.\n",
            "Testing with 1% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 1% neurons (160 neurons) for muting.\n",
            "Testing with 2% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 2% neurons (320 neurons) for muting.\n",
            "Testing with 3% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 3% neurons (480 neurons) for muting.\n",
            "Testing with 4% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 4% neurons (640 neurons) for muting.\n",
            "Testing with 5% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 5% neurons (800 neurons) for muting.\n",
            "Testing with 6% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 6% neurons (960 neurons) for muting.\n",
            "Testing with 7% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 7% neurons (1120 neurons) for muting.\n",
            "Testing with 8% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 8% neurons (1280 neurons) for muting.\n",
            "Testing with 9% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 9% neurons (1440 neurons) for muting.\n",
            "Testing with 10% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 10% neurons (1600 neurons) for muting.\n",
            "Testing with 11% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 11% neurons (1760 neurons) for muting.\n",
            "Testing with 12% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 12% neurons (1920 neurons) for muting.\n",
            "Testing with 13% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 13% neurons (2080 neurons) for muting.\n",
            "Testing with 14% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 14% neurons (2240 neurons) for muting.\n",
            "Testing with 15% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 15% neurons (2400 neurons) for muting.\n",
            "Testing with 16% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 16% neurons (2560 neurons) for muting.\n",
            "Testing with 17% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 17% neurons (2720 neurons) for muting.\n",
            "Testing with 18% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 18% neurons (2880 neurons) for muting.\n",
            "Testing with 19% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 19% neurons (3040 neurons) for muting.\n",
            "Testing with 20% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 20% neurons (3200 neurons) for muting.\n",
            "Testing with 21% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 21% neurons (3360 neurons) for muting.\n",
            "Testing with 22% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 22% neurons (3520 neurons) for muting.\n",
            "Testing with 23% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 23% neurons (3680 neurons) for muting.\n",
            "Testing with 24% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 24% neurons (3840 neurons) for muting.\n",
            "Testing with 25% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 25% neurons (4000 neurons) for muting.\n",
            "Testing with 26% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 26% neurons (4160 neurons) for muting.\n",
            "Testing with 27% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 27% neurons (4320 neurons) for muting.\n",
            "Testing with 28% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 28% neurons (4480 neurons) for muting.\n",
            "Testing with 29% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 29% neurons (4640 neurons) for muting.\n",
            "Testing with 30% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 30% neurons (4800 neurons) for muting.\n",
            "Testing with 31% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 31% neurons (4960 neurons) for muting.\n",
            "Testing with 32% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 32% neurons (5120 neurons) for muting.\n",
            "Testing with 33% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 33% neurons (5280 neurons) for muting.\n",
            "Testing with 34% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 34% neurons (5440 neurons) for muting.\n",
            "Testing with 35% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 35% neurons (5600 neurons) for muting.\n",
            "Testing with 36% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 36% neurons (5760 neurons) for muting.\n",
            "Testing with 37% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 37% neurons (5920 neurons) for muting.\n",
            "Testing with 38% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 38% neurons (6080 neurons) for muting.\n",
            "Testing with 39% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 39% neurons (6240 neurons) for muting.\n",
            "Testing with 40% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 40% neurons (6400 neurons) for muting.\n",
            "Testing with 41% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 41% neurons (6560 neurons) for muting.\n",
            "Testing with 42% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 42% neurons (6720 neurons) for muting.\n",
            "Testing with 43% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 43% neurons (6880 neurons) for muting.\n",
            "Testing with 44% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 44% neurons (7040 neurons) for muting.\n",
            "Testing with 45% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 45% neurons (7200 neurons) for muting.\n",
            "Testing with 46% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 46% neurons (7360 neurons) for muting.\n",
            "Testing with 47% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 47% neurons (7520 neurons) for muting.\n",
            "Testing with 48% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 48% neurons (7680 neurons) for muting.\n",
            "Testing with 49% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 49% neurons (7840 neurons) for muting.\n",
            "Testing with 50% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11_200.csv\n",
            "Loaded top 50% neurons (8000 neurons) for muting.\n",
            "\n",
            "Processing Seed 111\n",
            "Loading model from /content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_111.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-15-ee25108bcc59>:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and all layers up to fc2 are frozen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ee25108bcc59>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder loaded from /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_111.pth and frozen successfully.\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Testing with 0% muting...\n",
            "Reconstruction Error (Val Patch): 546.2208\n",
            "Reconstruction Error (Val No Patch): 467.9427\n",
            "Reconstruction Error (Test Two Patch): 508.9437\n",
            "Reconstruction Error (Test Two No Patch): 379.2056\n",
            "Reconstruction Error (Test Zero Patch): 539.8831\n",
            "Reconstruction Error (Test Zero No Patch): 442.6440\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 0% neurons (0 neurons) for muting.\n",
            "Testing with 1% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 1% neurons (160 neurons) for muting.\n",
            "Testing with 2% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 2% neurons (320 neurons) for muting.\n",
            "Testing with 3% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 3% neurons (480 neurons) for muting.\n",
            "Testing with 4% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 4% neurons (640 neurons) for muting.\n",
            "Testing with 5% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 5% neurons (800 neurons) for muting.\n",
            "Testing with 6% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 6% neurons (960 neurons) for muting.\n",
            "Testing with 7% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 7% neurons (1120 neurons) for muting.\n",
            "Testing with 8% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 8% neurons (1280 neurons) for muting.\n",
            "Testing with 9% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 9% neurons (1440 neurons) for muting.\n",
            "Testing with 10% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 10% neurons (1600 neurons) for muting.\n",
            "Testing with 11% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 11% neurons (1760 neurons) for muting.\n",
            "Testing with 12% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 12% neurons (1920 neurons) for muting.\n",
            "Testing with 13% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 13% neurons (2080 neurons) for muting.\n",
            "Testing with 14% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 14% neurons (2240 neurons) for muting.\n",
            "Testing with 15% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 15% neurons (2400 neurons) for muting.\n",
            "Testing with 16% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 16% neurons (2560 neurons) for muting.\n",
            "Testing with 17% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 17% neurons (2720 neurons) for muting.\n",
            "Testing with 18% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 18% neurons (2880 neurons) for muting.\n",
            "Testing with 19% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 19% neurons (3040 neurons) for muting.\n",
            "Testing with 20% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 20% neurons (3200 neurons) for muting.\n",
            "Testing with 21% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 21% neurons (3360 neurons) for muting.\n",
            "Testing with 22% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 22% neurons (3520 neurons) for muting.\n",
            "Testing with 23% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 23% neurons (3680 neurons) for muting.\n",
            "Testing with 24% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 24% neurons (3840 neurons) for muting.\n",
            "Testing with 25% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 25% neurons (4000 neurons) for muting.\n",
            "Testing with 26% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 26% neurons (4160 neurons) for muting.\n",
            "Testing with 27% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 27% neurons (4320 neurons) for muting.\n",
            "Testing with 28% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 28% neurons (4480 neurons) for muting.\n",
            "Testing with 29% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 29% neurons (4640 neurons) for muting.\n",
            "Testing with 30% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 30% neurons (4800 neurons) for muting.\n",
            "Testing with 31% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 31% neurons (4960 neurons) for muting.\n",
            "Testing with 32% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 32% neurons (5120 neurons) for muting.\n",
            "Testing with 33% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 33% neurons (5280 neurons) for muting.\n",
            "Testing with 34% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 34% neurons (5440 neurons) for muting.\n",
            "Testing with 35% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 35% neurons (5600 neurons) for muting.\n",
            "Testing with 36% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 36% neurons (5760 neurons) for muting.\n",
            "Testing with 37% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 37% neurons (5920 neurons) for muting.\n",
            "Testing with 38% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 38% neurons (6080 neurons) for muting.\n",
            "Testing with 39% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 39% neurons (6240 neurons) for muting.\n",
            "Testing with 40% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 40% neurons (6400 neurons) for muting.\n",
            "Testing with 41% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 41% neurons (6560 neurons) for muting.\n",
            "Testing with 42% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 42% neurons (6720 neurons) for muting.\n",
            "Testing with 43% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 43% neurons (6880 neurons) for muting.\n",
            "Testing with 44% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 44% neurons (7040 neurons) for muting.\n",
            "Testing with 45% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 45% neurons (7200 neurons) for muting.\n",
            "Testing with 46% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 46% neurons (7360 neurons) for muting.\n",
            "Testing with 47% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 47% neurons (7520 neurons) for muting.\n",
            "Testing with 48% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 48% neurons (7680 neurons) for muting.\n",
            "Testing with 49% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 49% neurons (7840 neurons) for muting.\n",
            "Testing with 50% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111_200.csv\n",
            "Loaded top 50% neurons (8000 neurons) for muting.\n",
            "\n",
            "Processing Seed 1111\n",
            "Loading model from /content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1111.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-15-ee25108bcc59>:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and all layers up to fc2 are frozen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ee25108bcc59>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder loaded from /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_1111.pth and frozen successfully.\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Testing with 0% muting...\n",
            "Reconstruction Error (Val Patch): 567.3940\n",
            "Reconstruction Error (Val No Patch): 515.0310\n",
            "Reconstruction Error (Test Two Patch): 528.1042\n",
            "Reconstruction Error (Test Two No Patch): 418.3323\n",
            "Reconstruction Error (Test Zero Patch): 560.7633\n",
            "Reconstruction Error (Test Zero No Patch): 485.2011\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 0% neurons (0 neurons) for muting.\n",
            "Testing with 1% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 1% neurons (160 neurons) for muting.\n",
            "Testing with 2% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 2% neurons (320 neurons) for muting.\n",
            "Testing with 3% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 3% neurons (480 neurons) for muting.\n",
            "Testing with 4% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 4% neurons (640 neurons) for muting.\n",
            "Testing with 5% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 5% neurons (800 neurons) for muting.\n",
            "Testing with 6% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 6% neurons (960 neurons) for muting.\n",
            "Testing with 7% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 7% neurons (1120 neurons) for muting.\n",
            "Testing with 8% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 8% neurons (1280 neurons) for muting.\n",
            "Testing with 9% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 9% neurons (1440 neurons) for muting.\n",
            "Testing with 10% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 10% neurons (1600 neurons) for muting.\n",
            "Testing with 11% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 11% neurons (1760 neurons) for muting.\n",
            "Testing with 12% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 12% neurons (1920 neurons) for muting.\n",
            "Testing with 13% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 13% neurons (2080 neurons) for muting.\n",
            "Testing with 14% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 14% neurons (2240 neurons) for muting.\n",
            "Testing with 15% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 15% neurons (2400 neurons) for muting.\n",
            "Testing with 16% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 16% neurons (2560 neurons) for muting.\n",
            "Testing with 17% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 17% neurons (2720 neurons) for muting.\n",
            "Testing with 18% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 18% neurons (2880 neurons) for muting.\n",
            "Testing with 19% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 19% neurons (3040 neurons) for muting.\n",
            "Testing with 20% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 20% neurons (3200 neurons) for muting.\n",
            "Testing with 21% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 21% neurons (3360 neurons) for muting.\n",
            "Testing with 22% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 22% neurons (3520 neurons) for muting.\n",
            "Testing with 23% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 23% neurons (3680 neurons) for muting.\n",
            "Testing with 24% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 24% neurons (3840 neurons) for muting.\n",
            "Testing with 25% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 25% neurons (4000 neurons) for muting.\n",
            "Testing with 26% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 26% neurons (4160 neurons) for muting.\n",
            "Testing with 27% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 27% neurons (4320 neurons) for muting.\n",
            "Testing with 28% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 28% neurons (4480 neurons) for muting.\n",
            "Testing with 29% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 29% neurons (4640 neurons) for muting.\n",
            "Testing with 30% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 30% neurons (4800 neurons) for muting.\n",
            "Testing with 31% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 31% neurons (4960 neurons) for muting.\n",
            "Testing with 32% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 32% neurons (5120 neurons) for muting.\n",
            "Testing with 33% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 33% neurons (5280 neurons) for muting.\n",
            "Testing with 34% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 34% neurons (5440 neurons) for muting.\n",
            "Testing with 35% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 35% neurons (5600 neurons) for muting.\n",
            "Testing with 36% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 36% neurons (5760 neurons) for muting.\n",
            "Testing with 37% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 37% neurons (5920 neurons) for muting.\n",
            "Testing with 38% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 38% neurons (6080 neurons) for muting.\n",
            "Testing with 39% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 39% neurons (6240 neurons) for muting.\n",
            "Testing with 40% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 40% neurons (6400 neurons) for muting.\n",
            "Testing with 41% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 41% neurons (6560 neurons) for muting.\n",
            "Testing with 42% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 42% neurons (6720 neurons) for muting.\n",
            "Testing with 43% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 43% neurons (6880 neurons) for muting.\n",
            "Testing with 44% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 44% neurons (7040 neurons) for muting.\n",
            "Testing with 45% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 45% neurons (7200 neurons) for muting.\n",
            "Testing with 46% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 46% neurons (7360 neurons) for muting.\n",
            "Testing with 47% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 47% neurons (7520 neurons) for muting.\n",
            "Testing with 48% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 48% neurons (7680 neurons) for muting.\n",
            "Testing with 49% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 49% neurons (7840 neurons) for muting.\n",
            "Testing with 50% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111_200.csv\n",
            "Loaded top 50% neurons (8000 neurons) for muting.\n",
            "\n",
            "Processing Seed 11111\n",
            "Loading model from /content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_11111.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-15-ee25108bcc59>:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and all layers up to fc2 are frozen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ee25108bcc59>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder loaded from /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_11111.pth and frozen successfully.\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Testing with 0% muting...\n",
            "Reconstruction Error (Val Patch): 549.3031\n",
            "Reconstruction Error (Val No Patch): 476.8838\n",
            "Reconstruction Error (Test Two Patch): 509.2920\n",
            "Reconstruction Error (Test Two No Patch): 381.9119\n",
            "Reconstruction Error (Test Zero Patch): 543.3553\n",
            "Reconstruction Error (Test Zero No Patch): 450.7477\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 0% neurons (0 neurons) for muting.\n",
            "Testing with 1% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 1% neurons (160 neurons) for muting.\n",
            "Testing with 2% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 2% neurons (320 neurons) for muting.\n",
            "Testing with 3% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 3% neurons (480 neurons) for muting.\n",
            "Testing with 4% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 4% neurons (640 neurons) for muting.\n",
            "Testing with 5% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 5% neurons (800 neurons) for muting.\n",
            "Testing with 6% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 6% neurons (960 neurons) for muting.\n",
            "Testing with 7% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 7% neurons (1120 neurons) for muting.\n",
            "Testing with 8% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 8% neurons (1280 neurons) for muting.\n",
            "Testing with 9% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 9% neurons (1440 neurons) for muting.\n",
            "Testing with 10% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 10% neurons (1600 neurons) for muting.\n",
            "Testing with 11% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 11% neurons (1760 neurons) for muting.\n",
            "Testing with 12% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 12% neurons (1920 neurons) for muting.\n",
            "Testing with 13% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 13% neurons (2080 neurons) for muting.\n",
            "Testing with 14% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 14% neurons (2240 neurons) for muting.\n",
            "Testing with 15% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 15% neurons (2400 neurons) for muting.\n",
            "Testing with 16% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 16% neurons (2560 neurons) for muting.\n",
            "Testing with 17% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 17% neurons (2720 neurons) for muting.\n",
            "Testing with 18% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 18% neurons (2880 neurons) for muting.\n",
            "Testing with 19% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 19% neurons (3040 neurons) for muting.\n",
            "Testing with 20% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 20% neurons (3200 neurons) for muting.\n",
            "Testing with 21% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 21% neurons (3360 neurons) for muting.\n",
            "Testing with 22% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 22% neurons (3520 neurons) for muting.\n",
            "Testing with 23% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 23% neurons (3680 neurons) for muting.\n",
            "Testing with 24% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 24% neurons (3840 neurons) for muting.\n",
            "Testing with 25% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 25% neurons (4000 neurons) for muting.\n",
            "Testing with 26% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 26% neurons (4160 neurons) for muting.\n",
            "Testing with 27% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 27% neurons (4320 neurons) for muting.\n",
            "Testing with 28% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 28% neurons (4480 neurons) for muting.\n",
            "Testing with 29% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 29% neurons (4640 neurons) for muting.\n",
            "Testing with 30% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 30% neurons (4800 neurons) for muting.\n",
            "Testing with 31% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 31% neurons (4960 neurons) for muting.\n",
            "Testing with 32% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 32% neurons (5120 neurons) for muting.\n",
            "Testing with 33% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 33% neurons (5280 neurons) for muting.\n",
            "Testing with 34% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 34% neurons (5440 neurons) for muting.\n",
            "Testing with 35% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 35% neurons (5600 neurons) for muting.\n",
            "Testing with 36% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 36% neurons (5760 neurons) for muting.\n",
            "Testing with 37% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 37% neurons (5920 neurons) for muting.\n",
            "Testing with 38% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 38% neurons (6080 neurons) for muting.\n",
            "Testing with 39% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 39% neurons (6240 neurons) for muting.\n",
            "Testing with 40% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 40% neurons (6400 neurons) for muting.\n",
            "Testing with 41% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 41% neurons (6560 neurons) for muting.\n",
            "Testing with 42% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 42% neurons (6720 neurons) for muting.\n",
            "Testing with 43% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 43% neurons (6880 neurons) for muting.\n",
            "Testing with 44% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 44% neurons (7040 neurons) for muting.\n",
            "Testing with 45% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 45% neurons (7200 neurons) for muting.\n",
            "Testing with 46% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 46% neurons (7360 neurons) for muting.\n",
            "Testing with 47% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 47% neurons (7520 neurons) for muting.\n",
            "Testing with 48% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 48% neurons (7680 neurons) for muting.\n",
            "Testing with 49% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 49% neurons (7840 neurons) for muting.\n",
            "Testing with 50% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_11111_200.csv\n",
            "Loaded top 50% neurons (8000 neurons) for muting.\n",
            "\n",
            "Processing Seed 111111\n",
            "Loading model from /content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_111111.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-15-ee25108bcc59>:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and all layers up to fc2 are frozen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ee25108bcc59>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder loaded from /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_111111.pth and frozen successfully.\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Testing with 0% muting...\n",
            "Reconstruction Error (Val Patch): 532.2167\n",
            "Reconstruction Error (Val No Patch): 446.9419\n",
            "Reconstruction Error (Test Two Patch): 493.0913\n",
            "Reconstruction Error (Test Two No Patch): 359.1201\n",
            "Reconstruction Error (Test Zero Patch): 526.5109\n",
            "Reconstruction Error (Test Zero No Patch): 423.1266\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 0% neurons (0 neurons) for muting.\n",
            "Testing with 1% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 1% neurons (160 neurons) for muting.\n",
            "Testing with 2% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 2% neurons (320 neurons) for muting.\n",
            "Testing with 3% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 3% neurons (480 neurons) for muting.\n",
            "Testing with 4% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 4% neurons (640 neurons) for muting.\n",
            "Testing with 5% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 5% neurons (800 neurons) for muting.\n",
            "Testing with 6% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 6% neurons (960 neurons) for muting.\n",
            "Testing with 7% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 7% neurons (1120 neurons) for muting.\n",
            "Testing with 8% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 8% neurons (1280 neurons) for muting.\n",
            "Testing with 9% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 9% neurons (1440 neurons) for muting.\n",
            "Testing with 10% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 10% neurons (1600 neurons) for muting.\n",
            "Testing with 11% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 11% neurons (1760 neurons) for muting.\n",
            "Testing with 12% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 12% neurons (1920 neurons) for muting.\n",
            "Testing with 13% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 13% neurons (2080 neurons) for muting.\n",
            "Testing with 14% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 14% neurons (2240 neurons) for muting.\n",
            "Testing with 15% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 15% neurons (2400 neurons) for muting.\n",
            "Testing with 16% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 16% neurons (2560 neurons) for muting.\n",
            "Testing with 17% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 17% neurons (2720 neurons) for muting.\n",
            "Testing with 18% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 18% neurons (2880 neurons) for muting.\n",
            "Testing with 19% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 19% neurons (3040 neurons) for muting.\n",
            "Testing with 20% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 20% neurons (3200 neurons) for muting.\n",
            "Testing with 21% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 21% neurons (3360 neurons) for muting.\n",
            "Testing with 22% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 22% neurons (3520 neurons) for muting.\n",
            "Testing with 23% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 23% neurons (3680 neurons) for muting.\n",
            "Testing with 24% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 24% neurons (3840 neurons) for muting.\n",
            "Testing with 25% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 25% neurons (4000 neurons) for muting.\n",
            "Testing with 26% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 26% neurons (4160 neurons) for muting.\n",
            "Testing with 27% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 27% neurons (4320 neurons) for muting.\n",
            "Testing with 28% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 28% neurons (4480 neurons) for muting.\n",
            "Testing with 29% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 29% neurons (4640 neurons) for muting.\n",
            "Testing with 30% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 30% neurons (4800 neurons) for muting.\n",
            "Testing with 31% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 31% neurons (4960 neurons) for muting.\n",
            "Testing with 32% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 32% neurons (5120 neurons) for muting.\n",
            "Testing with 33% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 33% neurons (5280 neurons) for muting.\n",
            "Testing with 34% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 34% neurons (5440 neurons) for muting.\n",
            "Testing with 35% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 35% neurons (5600 neurons) for muting.\n",
            "Testing with 36% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 36% neurons (5760 neurons) for muting.\n",
            "Testing with 37% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 37% neurons (5920 neurons) for muting.\n",
            "Testing with 38% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 38% neurons (6080 neurons) for muting.\n",
            "Testing with 39% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 39% neurons (6240 neurons) for muting.\n",
            "Testing with 40% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 40% neurons (6400 neurons) for muting.\n",
            "Testing with 41% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 41% neurons (6560 neurons) for muting.\n",
            "Testing with 42% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 42% neurons (6720 neurons) for muting.\n",
            "Testing with 43% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 43% neurons (6880 neurons) for muting.\n",
            "Testing with 44% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 44% neurons (7040 neurons) for muting.\n",
            "Testing with 45% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 45% neurons (7200 neurons) for muting.\n",
            "Testing with 46% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 46% neurons (7360 neurons) for muting.\n",
            "Testing with 47% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 47% neurons (7520 neurons) for muting.\n",
            "Testing with 48% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 48% neurons (7680 neurons) for muting.\n",
            "Testing with 49% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 49% neurons (7840 neurons) for muting.\n",
            "Testing with 50% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_111111_200.csv\n",
            "Loaded top 50% neurons (8000 neurons) for muting.\n",
            "\n",
            "Processing Seed 1111111\n",
            "Loading model from /content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_1111111.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-15-ee25108bcc59>:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and all layers up to fc2 are frozen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ee25108bcc59>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder loaded from /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_1111111.pth and frozen successfully.\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Projecting Alexnet activations into SAE sparse space...\n",
            "Testing with 0% muting...\n",
            "Reconstruction Error (Val Patch): 525.4078\n",
            "Reconstruction Error (Val No Patch): 431.4221\n",
            "Reconstruction Error (Test Two Patch): 486.2897\n",
            "Reconstruction Error (Test Two No Patch): 347.0998\n",
            "Reconstruction Error (Test Zero Patch): 520.2115\n",
            "Reconstruction Error (Test Zero No Patch): 409.0144\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 0% neurons (0 neurons) for muting.\n",
            "Testing with 1% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 1% neurons (160 neurons) for muting.\n",
            "Testing with 2% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 2% neurons (320 neurons) for muting.\n",
            "Testing with 3% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 3% neurons (480 neurons) for muting.\n",
            "Testing with 4% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 4% neurons (640 neurons) for muting.\n",
            "Testing with 5% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 5% neurons (800 neurons) for muting.\n",
            "Testing with 6% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 6% neurons (960 neurons) for muting.\n",
            "Testing with 7% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 7% neurons (1120 neurons) for muting.\n",
            "Testing with 8% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 8% neurons (1280 neurons) for muting.\n",
            "Testing with 9% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 9% neurons (1440 neurons) for muting.\n",
            "Testing with 10% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 10% neurons (1600 neurons) for muting.\n",
            "Testing with 11% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 11% neurons (1760 neurons) for muting.\n",
            "Testing with 12% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 12% neurons (1920 neurons) for muting.\n",
            "Testing with 13% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 13% neurons (2080 neurons) for muting.\n",
            "Testing with 14% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 14% neurons (2240 neurons) for muting.\n",
            "Testing with 15% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 15% neurons (2400 neurons) for muting.\n",
            "Testing with 16% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 16% neurons (2560 neurons) for muting.\n",
            "Testing with 17% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 17% neurons (2720 neurons) for muting.\n",
            "Testing with 18% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 18% neurons (2880 neurons) for muting.\n",
            "Testing with 19% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 19% neurons (3040 neurons) for muting.\n",
            "Testing with 20% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 20% neurons (3200 neurons) for muting.\n",
            "Testing with 21% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 21% neurons (3360 neurons) for muting.\n",
            "Testing with 22% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 22% neurons (3520 neurons) for muting.\n",
            "Testing with 23% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 23% neurons (3680 neurons) for muting.\n",
            "Testing with 24% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 24% neurons (3840 neurons) for muting.\n",
            "Testing with 25% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 25% neurons (4000 neurons) for muting.\n",
            "Testing with 26% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 26% neurons (4160 neurons) for muting.\n",
            "Testing with 27% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 27% neurons (4320 neurons) for muting.\n",
            "Testing with 28% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 28% neurons (4480 neurons) for muting.\n",
            "Testing with 29% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 29% neurons (4640 neurons) for muting.\n",
            "Testing with 30% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 30% neurons (4800 neurons) for muting.\n",
            "Testing with 31% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 31% neurons (4960 neurons) for muting.\n",
            "Testing with 32% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 32% neurons (5120 neurons) for muting.\n",
            "Testing with 33% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 33% neurons (5280 neurons) for muting.\n",
            "Testing with 34% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 34% neurons (5440 neurons) for muting.\n",
            "Testing with 35% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 35% neurons (5600 neurons) for muting.\n",
            "Testing with 36% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 36% neurons (5760 neurons) for muting.\n",
            "Testing with 37% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 37% neurons (5920 neurons) for muting.\n",
            "Testing with 38% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 38% neurons (6080 neurons) for muting.\n",
            "Testing with 39% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 39% neurons (6240 neurons) for muting.\n",
            "Testing with 40% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 40% neurons (6400 neurons) for muting.\n",
            "Testing with 41% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 41% neurons (6560 neurons) for muting.\n",
            "Testing with 42% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 42% neurons (6720 neurons) for muting.\n",
            "Testing with 43% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 43% neurons (6880 neurons) for muting.\n",
            "Testing with 44% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 44% neurons (7040 neurons) for muting.\n",
            "Testing with 45% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 45% neurons (7200 neurons) for muting.\n",
            "Testing with 46% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 46% neurons (7360 neurons) for muting.\n",
            "Testing with 47% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 47% neurons (7520 neurons) for muting.\n",
            "Testing with 48% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 48% neurons (7680 neurons) for muting.\n",
            "Testing with 49% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 49% neurons (7840 neurons) for muting.\n",
            "Testing with 50% muting...\n",
            "Number of val patch neurons: 16000\n",
            "Number of val patch images: 200\n",
            "Number of pp labels: 400\n",
            "shape of correlations (16000,)\n",
            "Neuron correlations saved at: /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/l1_neurons_by_correlation_seed_1111111_200.csv\n",
            "Loaded top 50% neurons (8000 neurons) for muting.\n",
            "All results saved to /content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground/foreground_200.csv\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "def calculate_reconstruction_error(original_activations, decoded_activations):\n",
        "    \"\"\"\n",
        "    Calculate the reconstruction error as mean squared error (MSE).\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(original_activations, decoded_activations)\n",
        "    return mse\n",
        "\n",
        "\n",
        "\n",
        "def plot_correlation_histogram(original, projected, title):\n",
        "    correlations = [\n",
        "        np.corrcoef(original[:, i], projected[:, i])[0, 1]\n",
        "        if np.std(original[:, i]) > 0 and np.std(projected[:, i]) > 0\n",
        "        else 0  # Handle constant features\n",
        "        for i in range(original.shape[1])\n",
        "    ]\n",
        "    correlations = np.nan_to_num(correlations)  # Replace NaNs with 0\n",
        "    plt.hist(correlations, bins=50, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Correlation\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences_200.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "'''\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"l1_neurons_by_correlation.csv\"):\n",
        "    \"\"\"\n",
        "    Save neurons sorted by their correlation between val_patch_activations and val_no_patch_activations.\n",
        "    \"\"\"\n",
        "    print(f\"Calculating neuron correlations and saving to {filename}\")\n",
        "\n",
        "    # Compute the correlation for each neuron across the two groups\n",
        "    correlations = np.array([\n",
        "        np.corrcoef(val_patch_activations[:, i], val_no_patch_activations[:, i])[0, 1]\n",
        "        if np.std(val_patch_activations[:, i]) > 0 and np.std(val_no_patch_activations[:, i]) > 0\n",
        "        else 0  # Set correlation to 0 if one group has constant values\n",
        "        for i in range(val_patch_activations.shape[1])\n",
        "    ])\n",
        "\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(correlations)),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by absolute correlation in ascending order (low correlation first)\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "'''\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"neurons_by_correlation_200.csv\"):\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Number of neurons should be 16k\n",
        "    num_neurons = val_patch_activations.shape[1]\n",
        "    print(f\"Number of val patch neurons: {num_neurons}\")\n",
        "    num_images = val_patch_activations.shape[0]\n",
        "    print(f\"Number of val patch images: {val_patch_activations.shape[0]}\")\n",
        "\n",
        "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
        "    pp = np.concatenate([np.ones(val_patch_activations.shape[0]), np.zeros(val_no_patch_activations.shape[0])])\n",
        "    print(f\"Number of pp labels: {len(pp)}\")\n",
        "\n",
        "    # array to store correlations\n",
        "    correlations = np.zeros(num_neurons)\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        # Combine activations for neuron i from both datassets p and np\n",
        "        act_i = np.concatenate([val_patch_activations[:, i], val_no_patch_activations[:, i]])\n",
        "\n",
        "        # Compute correlation between pp and act_i\n",
        "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
        "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
        "        else:\n",
        "            corr = 0  # Handle constant vectors\n",
        "\n",
        "        correlations[i] = corr\n",
        "\n",
        "    # As previous code\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "    print('shape of correlations', correlations.shape)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(num_neurons),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by correlation in descending order\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"l1_fg_top_neurons_200.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "\n",
        "    # Debugging for 0% muting\n",
        "    if percentage == 0:\n",
        "        assert len(top_neurons) == 0, \"Top neurons list should be empty for 0% muting.\"\n",
        "\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    model.eval() #TAKE A LOOK HERE!!!!!\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(output).item()\n",
        "        #prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item() #TAKE A LOOK HERE!!!!!\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111, 1111, 11111, 111111, 1111111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_{seed}.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_two_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_two_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_zero_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_zero_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_val_zero_fg_200_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_val_zero_org_200_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Prepare a DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Seed\", \"Percentage\",\n",
        "        \"Val_Patch_Before\", \"Val_NoPatch_Before\",\n",
        "        \"Val_Patch_After\", \"Val_NoPatch_After\",\n",
        "        \"Test_Two_Patch_Before\", \"Test_Two_NoPatch_Before\",\n",
        "        \"Test_Two_Patch_After\", \"Test_Two_NoPatch_After\",\n",
        "        \"Test_Zero_Patch_Before\", \"Test_Zero_NoPatch_Before\",\n",
        "        \"Test_Zero_Patch_After\", \"Test_Zero_NoPatch_After\",\n",
        "        \"Worst_Acc_Before\", \"Worst_Acc_After\",\n",
        "        \"Avg_Acc_Before\", \"Avg_Acc_After\"\n",
        "    ])\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "\n",
        "        # Load paths\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        test_two_patch = np.load(test_two_patch_path, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_two_no_patch_path, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_zero_patch_path, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_zero_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Classify \"before muting\"\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Project activations\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "\n",
        "        # Loop through percentages\n",
        "        for percentage in range(0, 51):  # 1% to 15%\n",
        "            print(f\"Testing with {percentage}% muting...\")\n",
        "\n",
        "            if percentage == 0:\n",
        "                # Decode original activations without muting\n",
        "                decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch).to(device).float()).cpu().numpy()\n",
        "\n",
        "                # Calculate reconstruction errors\n",
        "                recon_error_val_patch = calculate_reconstruction_error(val_activations_patch, decoded_val_patch)\n",
        "                recon_error_val_no_patch = calculate_reconstruction_error(val_activations_no_patch, decoded_val_no_patch)\n",
        "                recon_error_test_two_patch = calculate_reconstruction_error(test_two_patch, decoded_two_test_patch)\n",
        "                recon_error_test_two_no_patch = calculate_reconstruction_error(test_two_no_patch, decoded_two_test_no_patch)\n",
        "                recon_error_test_zero_patch = calculate_reconstruction_error(test_zero_patch, decoded_zero_test_patch)\n",
        "                recon_error_test_zero_no_patch = calculate_reconstruction_error(test_zero_no_patch, decoded_zero_test_no_patch)\n",
        "\n",
        "                # Print reconstruction errors\n",
        "                print(f\"Reconstruction Error (Val Patch): {recon_error_val_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Val No Patch): {recon_error_val_no_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Two Patch): {recon_error_test_two_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Two No Patch): {recon_error_test_two_no_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Zero Patch): {recon_error_test_zero_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Zero No Patch): {recon_error_test_zero_no_patch:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "            # Calculate differences and load top neurons\n",
        "            #abs_diff = np.abs(np.mean(projected_val_patch, axis=0) - np.mean(projected_val_no_patch, axis=0))\n",
        "            #csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\")\n",
        "            #top_neurons = load_top_neurons_from_csv(folder_name, f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\", percentage)\n",
        "\n",
        "            # **Correlation-Based Neurons**\n",
        "            correlation_csv_path = save_neurons_by_correlation(\n",
        "                projected_val_patch, projected_val_no_patch, folder_name, filename=f\"l1_neurons_by_correlation_seed_{seed}_200.csv\"\n",
        "            )\n",
        "            top_neurons_corr = load_top_neurons_from_csv(folder_name, f\"l1_neurons_by_correlation_seed_{seed}_200.csv\", percentage)\n",
        "\n",
        "            top_neurons = top_neurons_corr\n",
        "\n",
        "            # Muting neurons\n",
        "            projected_val_patch_muted = projected_val_patch.copy()\n",
        "            projected_val_no_patch_muted = projected_val_no_patch.copy()\n",
        "            projected_two_test_patch_muted = projected_two_test_patch.copy()\n",
        "            projected_two_test_no_patch_muted = projected_two_test_no_patch.copy()\n",
        "            projected_zero_test_patch_muted = projected_zero_test_patch.copy()\n",
        "            projected_zero_test_no_patch_muted = projected_zero_test_no_patch.copy()\n",
        "\n",
        "            projected_val_patch_muted[:, top_neurons] = 0\n",
        "            projected_val_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_no_patch_muted[:, top_neurons] = 0\n",
        "\n",
        "            # Decode and classify\n",
        "            decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "\n",
        "            predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "            predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "            predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "            predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "            predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "            predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "            accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "            accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "            accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "            accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "            accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0] * len(predictions_test_zero_patch_after))\n",
        "            accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "            # Calculate worst and average group accuracies\n",
        "            worst_acc_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "            worst_acc_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "            avg_acc_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before +\n",
        "                              accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "            avg_acc_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after +\n",
        "                             accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "            # Append results to DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                \"Seed\": seed,\n",
        "                \"Percentage\": percentage,\n",
        "                \"Val_Patch_Before\": accuracy_val_patch_before,\n",
        "                \"Val_NoPatch_Before\": accuracy_val_no_patch_before,\n",
        "                \"Val_Patch_After\": accuracy_val_patch_after,\n",
        "                \"Val_NoPatch_After\": accuracy_val_no_patch_after,\n",
        "                \"Test_Two_Patch_Before\": accuracy_test_two_patch_before,\n",
        "                \"Test_Two_NoPatch_Before\": accuracy_test_two_no_patch_before,\n",
        "                \"Test_Two_Patch_After\": accuracy_test_two_patch_after,\n",
        "                \"Test_Two_NoPatch_After\": accuracy_test_two_no_patch_after,\n",
        "                \"Test_Zero_Patch_Before\": accuracy_test_zero_patch_before,\n",
        "                \"Test_Zero_NoPatch_Before\": accuracy_test_zero_no_patch_before,\n",
        "                \"Test_Zero_Patch_After\": accuracy_test_zero_patch_after,\n",
        "                \"Test_Zero_NoPatch_After\": accuracy_test_zero_no_patch_after,\n",
        "                \"Worst_Acc_Before\": worst_acc_before,\n",
        "                \"Worst_Acc_After\": worst_acc_after,\n",
        "                \"Avg_Acc_Before\": avg_acc_before,\n",
        "                \"Avg_Acc_After\": avg_acc_after\n",
        "            }])\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_csv_path = os.path.join(folder_name, \"foreground_200.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###100"
      ],
      "metadata": {
        "id": "A_UEsQ9b1f7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "def calculate_reconstruction_error(original_activations, decoded_activations):\n",
        "    \"\"\"\n",
        "    Calculate the reconstruction error as mean squared error (MSE).\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(original_activations, decoded_activations)\n",
        "    return mse\n",
        "\n",
        "\n",
        "\n",
        "def plot_correlation_histogram(original, projected, title):\n",
        "    correlations = [\n",
        "        np.corrcoef(original[:, i], projected[:, i])[0, 1]\n",
        "        if np.std(original[:, i]) > 0 and np.std(projected[:, i]) > 0\n",
        "        else 0  # Handle constant features\n",
        "        for i in range(original.shape[1])\n",
        "    ]\n",
        "    correlations = np.nan_to_num(correlations)  # Replace NaNs with 0\n",
        "    plt.hist(correlations, bins=50, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Correlation\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences_100.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "'''\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"l1_neurons_by_correlation.csv\"):\n",
        "    \"\"\"\n",
        "    Save neurons sorted by their correlation between val_patch_activations and val_no_patch_activations.\n",
        "    \"\"\"\n",
        "    print(f\"Calculating neuron correlations and saving to {filename}\")\n",
        "\n",
        "    # Compute the correlation for each neuron across the two groups\n",
        "    correlations = np.array([\n",
        "        np.corrcoef(val_patch_activations[:, i], val_no_patch_activations[:, i])[0, 1]\n",
        "        if np.std(val_patch_activations[:, i]) > 0 and np.std(val_no_patch_activations[:, i]) > 0\n",
        "        else 0  # Set correlation to 0 if one group has constant values\n",
        "        for i in range(val_patch_activations.shape[1])\n",
        "    ])\n",
        "\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(correlations)),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by absolute correlation in ascending order (low correlation first)\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "'''\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"neurons_by_correlation_100.csv\"):\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Number of neurons should be 16k\n",
        "    num_neurons = val_patch_activations.shape[1]\n",
        "    print(f\"Number of val patch neurons: {num_neurons}\")\n",
        "    num_images = val_patch_activations.shape[0]\n",
        "    print(f\"Number of val patch images: {val_patch_activations.shape[0]}\")\n",
        "\n",
        "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
        "    pp = np.concatenate([np.ones(val_patch_activations.shape[0]), np.zeros(val_no_patch_activations.shape[0])])\n",
        "    print(f\"Number of pp labels: {len(pp)}\")\n",
        "\n",
        "    # array to store correlations\n",
        "    correlations = np.zeros(num_neurons)\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        # Combine activations for neuron i from both datassets p and np\n",
        "        act_i = np.concatenate([val_patch_activations[:, i], val_no_patch_activations[:, i]])\n",
        "\n",
        "        # Compute correlation between pp and act_i\n",
        "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
        "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
        "        else:\n",
        "            corr = 0  # Handle constant vectors\n",
        "\n",
        "        correlations[i] = corr\n",
        "\n",
        "    # As previous code\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "    print('shape of correlations', correlations.shape)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(num_neurons),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by correlation in descending order\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"l1_fg_top_neurons_100.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "\n",
        "    # Debugging for 0% muting\n",
        "    if percentage == 0:\n",
        "        assert len(top_neurons) == 0, \"Top neurons list should be empty for 0% muting.\"\n",
        "\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    model.eval() #TAKE A LOOK HERE!!!!!\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(output).item()\n",
        "        #prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item() #TAKE A LOOK HERE!!!!!\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111, 1111, 11111, 111111, 1111111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_{seed}.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_two_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_two_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_zero_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_zero_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_val_zero_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_val_zero_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Prepare a DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Seed\", \"Percentage\",\n",
        "        \"Val_Patch_Before\", \"Val_NoPatch_Before\",\n",
        "        \"Val_Patch_After\", \"Val_NoPatch_After\",\n",
        "        \"Test_Two_Patch_Before\", \"Test_Two_NoPatch_Before\",\n",
        "        \"Test_Two_Patch_After\", \"Test_Two_NoPatch_After\",\n",
        "        \"Test_Zero_Patch_Before\", \"Test_Zero_NoPatch_Before\",\n",
        "        \"Test_Zero_Patch_After\", \"Test_Zero_NoPatch_After\",\n",
        "        \"Worst_Acc_Before\", \"Worst_Acc_After\",\n",
        "        \"Avg_Acc_Before\", \"Avg_Acc_After\"\n",
        "    ])\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "\n",
        "        # Load paths\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        test_two_patch = np.load(test_two_patch_path, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_two_no_patch_path, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_zero_patch_path, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_zero_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Classify \"before muting\"\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Project activations\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "\n",
        "        # Loop through percentages\n",
        "        for percentage in range(0, 51):  # 1% to 15%\n",
        "            print(f\"Testing with {percentage}% muting...\")\n",
        "\n",
        "            if percentage == 0:\n",
        "                # Decode original activations without muting\n",
        "                decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch).to(device).float()).cpu().numpy()\n",
        "\n",
        "                # Calculate reconstruction errors\n",
        "                recon_error_val_patch = calculate_reconstruction_error(val_activations_patch, decoded_val_patch)\n",
        "                recon_error_val_no_patch = calculate_reconstruction_error(val_activations_no_patch, decoded_val_no_patch)\n",
        "                recon_error_test_two_patch = calculate_reconstruction_error(test_two_patch, decoded_two_test_patch)\n",
        "                recon_error_test_two_no_patch = calculate_reconstruction_error(test_two_no_patch, decoded_two_test_no_patch)\n",
        "                recon_error_test_zero_patch = calculate_reconstruction_error(test_zero_patch, decoded_zero_test_patch)\n",
        "                recon_error_test_zero_no_patch = calculate_reconstruction_error(test_zero_no_patch, decoded_zero_test_no_patch)\n",
        "\n",
        "                # Print reconstruction errors\n",
        "                print(f\"Reconstruction Error (Val Patch): {recon_error_val_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Val No Patch): {recon_error_val_no_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Two Patch): {recon_error_test_two_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Two No Patch): {recon_error_test_two_no_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Zero Patch): {recon_error_test_zero_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Zero No Patch): {recon_error_test_zero_no_patch:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "            # Calculate differences and load top neurons\n",
        "            #abs_diff = np.abs(np.mean(projected_val_patch, axis=0) - np.mean(projected_val_no_patch, axis=0))\n",
        "            #csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\")\n",
        "            #top_neurons = load_top_neurons_from_csv(folder_name, f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\", percentage)\n",
        "\n",
        "            # **Correlation-Based Neurons**\n",
        "            correlation_csv_path = save_neurons_by_correlation(\n",
        "                projected_val_patch, projected_val_no_patch, folder_name, filename=f\"l1_neurons_by_correlation_seed_{seed}_100.csv\"\n",
        "            )\n",
        "            top_neurons_corr = load_top_neurons_from_csv(folder_name, f\"l1_neurons_by_correlation_seed_{seed}_100.csv\", percentage)\n",
        "\n",
        "            top_neurons = top_neurons_corr\n",
        "\n",
        "            # Muting neurons\n",
        "            projected_val_patch_muted = projected_val_patch.copy()\n",
        "            projected_val_no_patch_muted = projected_val_no_patch.copy()\n",
        "            projected_two_test_patch_muted = projected_two_test_patch.copy()\n",
        "            projected_two_test_no_patch_muted = projected_two_test_no_patch.copy()\n",
        "            projected_zero_test_patch_muted = projected_zero_test_patch.copy()\n",
        "            projected_zero_test_no_patch_muted = projected_zero_test_no_patch.copy()\n",
        "\n",
        "            projected_val_patch_muted[:, top_neurons] = 0\n",
        "            projected_val_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_no_patch_muted[:, top_neurons] = 0\n",
        "\n",
        "            # Decode and classify\n",
        "            decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "\n",
        "            predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "            predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "            predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "            predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "            predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "            predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "            accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "            accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "            accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "            accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "            accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0] * len(predictions_test_zero_patch_after))\n",
        "            accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "            # Calculate worst and average group accuracies\n",
        "            worst_acc_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "            worst_acc_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "            avg_acc_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before +\n",
        "                              accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "            avg_acc_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after +\n",
        "                             accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "            # Append results to DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                \"Seed\": seed,\n",
        "                \"Percentage\": percentage,\n",
        "                \"Val_Patch_Before\": accuracy_val_patch_before,\n",
        "                \"Val_NoPatch_Before\": accuracy_val_no_patch_before,\n",
        "                \"Val_Patch_After\": accuracy_val_patch_after,\n",
        "                \"Val_NoPatch_After\": accuracy_val_no_patch_after,\n",
        "                \"Test_Two_Patch_Before\": accuracy_test_two_patch_before,\n",
        "                \"Test_Two_NoPatch_Before\": accuracy_test_two_no_patch_before,\n",
        "                \"Test_Two_Patch_After\": accuracy_test_two_patch_after,\n",
        "                \"Test_Two_NoPatch_After\": accuracy_test_two_no_patch_after,\n",
        "                \"Test_Zero_Patch_Before\": accuracy_test_zero_patch_before,\n",
        "                \"Test_Zero_NoPatch_Before\": accuracy_test_zero_no_patch_before,\n",
        "                \"Test_Zero_Patch_After\": accuracy_test_zero_patch_after,\n",
        "                \"Test_Zero_NoPatch_After\": accuracy_test_zero_no_patch_after,\n",
        "                \"Worst_Acc_Before\": worst_acc_before,\n",
        "                \"Worst_Acc_After\": worst_acc_after,\n",
        "                \"Avg_Acc_Before\": avg_acc_before,\n",
        "                \"Avg_Acc_After\": avg_acc_after\n",
        "            }])\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_csv_path = os.path.join(folder_name, \"foreground_100.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "L-RfsDQEmMaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 50"
      ],
      "metadata": {
        "id": "jMm9lHKb1Z2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "def calculate_reconstruction_error(original_activations, decoded_activations):\n",
        "    \"\"\"\n",
        "    Calculate the reconstruction error as mean squared error (MSE).\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(original_activations, decoded_activations)\n",
        "    return mse\n",
        "\n",
        "\n",
        "\n",
        "def plot_correlation_histogram(original, projected, title):\n",
        "    correlations = [\n",
        "        np.corrcoef(original[:, i], projected[:, i])[0, 1]\n",
        "        if np.std(original[:, i]) > 0 and np.std(projected[:, i]) > 0\n",
        "        else 0  # Handle constant features\n",
        "        for i in range(original.shape[1])\n",
        "    ]\n",
        "    correlations = np.nan_to_num(correlations)  # Replace NaNs with 0\n",
        "    plt.hist(correlations, bins=50, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Correlation\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences_50.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "'''\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"l1_neurons_by_correlation.csv\"):\n",
        "    \"\"\"\n",
        "    Save neurons sorted by their correlation between val_patch_activations and val_no_patch_activations.\n",
        "    \"\"\"\n",
        "    print(f\"Calculating neuron correlations and saving to {filename}\")\n",
        "\n",
        "    # Compute the correlation for each neuron across the two groups\n",
        "    correlations = np.array([\n",
        "        np.corrcoef(val_patch_activations[:, i], val_no_patch_activations[:, i])[0, 1]\n",
        "        if np.std(val_patch_activations[:, i]) > 0 and np.std(val_no_patch_activations[:, i]) > 0\n",
        "        else 0  # Set correlation to 0 if one group has constant values\n",
        "        for i in range(val_patch_activations.shape[1])\n",
        "    ])\n",
        "\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(correlations)),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by absolute correlation in ascending order (low correlation first)\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "'''\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"neurons_by_correlation_50.csv\"):\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Number of neurons should be 16k\n",
        "    num_neurons = val_patch_activations.shape[1]\n",
        "    print(f\"Number of val patch neurons: {num_neurons}\")\n",
        "    num_images = val_patch_activations.shape[0]\n",
        "    print(f\"Number of val patch images: {val_patch_activations.shape[0]}\")\n",
        "\n",
        "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
        "    pp = np.concatenate([np.ones(val_patch_activations.shape[0]), np.zeros(val_no_patch_activations.shape[0])])\n",
        "    print(f\"Number of pp labels: {len(pp)}\")\n",
        "\n",
        "    # array to store correlations\n",
        "    correlations = np.zeros(num_neurons)\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        # Combine activations for neuron i from both datassets p and np\n",
        "        act_i = np.concatenate([val_patch_activations[:, i], val_no_patch_activations[:, i]])\n",
        "\n",
        "        # Compute correlation between pp and act_i\n",
        "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
        "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
        "        else:\n",
        "            corr = 0  # Handle constant vectors\n",
        "\n",
        "        correlations[i] = corr\n",
        "\n",
        "    # As previous code\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "    print('shape of correlations', correlations.shape)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(num_neurons),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by correlation in descending order\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"l1_fg_top_neurons_50.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "\n",
        "    # Debugging for 0% muting\n",
        "    if percentage == 0:\n",
        "        assert len(top_neurons) == 0, \"Top neurons list should be empty for 0% muting.\"\n",
        "\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    model.eval() #TAKE A LOOK HERE!!!!!\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(output).item()\n",
        "        #prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item() #TAKE A LOOK HERE!!!!!\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111, 1111, 11111, 111111, 1111111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_{seed}.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_two_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_two_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_zero_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_zero_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_val_zero_fg_50_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_val_zero_org_50_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Prepare a DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Seed\", \"Percentage\",\n",
        "        \"Val_Patch_Before\", \"Val_NoPatch_Before\",\n",
        "        \"Val_Patch_After\", \"Val_NoPatch_After\",\n",
        "        \"Test_Two_Patch_Before\", \"Test_Two_NoPatch_Before\",\n",
        "        \"Test_Two_Patch_After\", \"Test_Two_NoPatch_After\",\n",
        "        \"Test_Zero_Patch_Before\", \"Test_Zero_NoPatch_Before\",\n",
        "        \"Test_Zero_Patch_After\", \"Test_Zero_NoPatch_After\",\n",
        "        \"Worst_Acc_Before\", \"Worst_Acc_After\",\n",
        "        \"Avg_Acc_Before\", \"Avg_Acc_After\"\n",
        "    ])\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "\n",
        "        # Load paths\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        test_two_patch = np.load(test_two_patch_path, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_two_no_patch_path, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_zero_patch_path, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_zero_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Classify \"before muting\"\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Project activations\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "\n",
        "        # Loop through percentages\n",
        "        for percentage in range(0, 51):  # 1% to 15%\n",
        "            print(f\"Testing with {percentage}% muting...\")\n",
        "\n",
        "            if percentage == 0:\n",
        "                # Decode original activations without muting\n",
        "                decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch).to(device).float()).cpu().numpy()\n",
        "\n",
        "                # Calculate reconstruction errors\n",
        "                recon_error_val_patch = calculate_reconstruction_error(val_activations_patch, decoded_val_patch)\n",
        "                recon_error_val_no_patch = calculate_reconstruction_error(val_activations_no_patch, decoded_val_no_patch)\n",
        "                recon_error_test_two_patch = calculate_reconstruction_error(test_two_patch, decoded_two_test_patch)\n",
        "                recon_error_test_two_no_patch = calculate_reconstruction_error(test_two_no_patch, decoded_two_test_no_patch)\n",
        "                recon_error_test_zero_patch = calculate_reconstruction_error(test_zero_patch, decoded_zero_test_patch)\n",
        "                recon_error_test_zero_no_patch = calculate_reconstruction_error(test_zero_no_patch, decoded_zero_test_no_patch)\n",
        "\n",
        "                # Print reconstruction errors\n",
        "                print(f\"Reconstruction Error (Val Patch): {recon_error_val_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Val No Patch): {recon_error_val_no_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Two Patch): {recon_error_test_two_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Two No Patch): {recon_error_test_two_no_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Zero Patch): {recon_error_test_zero_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Zero No Patch): {recon_error_test_zero_no_patch:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "            # Calculate differences and load top neurons\n",
        "            #abs_diff = np.abs(np.mean(projected_val_patch, axis=0) - np.mean(projected_val_no_patch, axis=0))\n",
        "            #csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\")\n",
        "            #top_neurons = load_top_neurons_from_csv(folder_name, f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\", percentage)\n",
        "\n",
        "            # **Correlation-Based Neurons**\n",
        "            correlation_csv_path = save_neurons_by_correlation(\n",
        "                projected_val_patch, projected_val_no_patch, folder_name, filename=f\"l1_neurons_by_correlation_seed_{seed}_50.csv\"\n",
        "            )\n",
        "            top_neurons_corr = load_top_neurons_from_csv(folder_name, f\"l1_neurons_by_correlation_seed_{seed}_50.csv\", percentage)\n",
        "\n",
        "            top_neurons = top_neurons_corr\n",
        "\n",
        "            # Muting neurons\n",
        "            projected_val_patch_muted = projected_val_patch.copy()\n",
        "            projected_val_no_patch_muted = projected_val_no_patch.copy()\n",
        "            projected_two_test_patch_muted = projected_two_test_patch.copy()\n",
        "            projected_two_test_no_patch_muted = projected_two_test_no_patch.copy()\n",
        "            projected_zero_test_patch_muted = projected_zero_test_patch.copy()\n",
        "            projected_zero_test_no_patch_muted = projected_zero_test_no_patch.copy()\n",
        "\n",
        "            projected_val_patch_muted[:, top_neurons] = 0\n",
        "            projected_val_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_no_patch_muted[:, top_neurons] = 0\n",
        "\n",
        "            # Decode and classify\n",
        "            decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "\n",
        "            predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "            predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "            predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "            predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "            predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "            predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "            accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "            accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "            accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "            accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "            accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0] * len(predictions_test_zero_patch_after))\n",
        "            accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "            # Calculate worst and average group accuracies\n",
        "            worst_acc_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "            worst_acc_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "            avg_acc_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before +\n",
        "                              accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "            avg_acc_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after +\n",
        "                             accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "            # Append results to DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                \"Seed\": seed,\n",
        "                \"Percentage\": percentage,\n",
        "                \"Val_Patch_Before\": accuracy_val_patch_before,\n",
        "                \"Val_NoPatch_Before\": accuracy_val_no_patch_before,\n",
        "                \"Val_Patch_After\": accuracy_val_patch_after,\n",
        "                \"Val_NoPatch_After\": accuracy_val_no_patch_after,\n",
        "                \"Test_Two_Patch_Before\": accuracy_test_two_patch_before,\n",
        "                \"Test_Two_NoPatch_Before\": accuracy_test_two_no_patch_before,\n",
        "                \"Test_Two_Patch_After\": accuracy_test_two_patch_after,\n",
        "                \"Test_Two_NoPatch_After\": accuracy_test_two_no_patch_after,\n",
        "                \"Test_Zero_Patch_Before\": accuracy_test_zero_patch_before,\n",
        "                \"Test_Zero_NoPatch_Before\": accuracy_test_zero_no_patch_before,\n",
        "                \"Test_Zero_Patch_After\": accuracy_test_zero_patch_after,\n",
        "                \"Test_Zero_NoPatch_After\": accuracy_test_zero_no_patch_after,\n",
        "                \"Worst_Acc_Before\": worst_acc_before,\n",
        "                \"Worst_Acc_After\": worst_acc_after,\n",
        "                \"Avg_Acc_Before\": avg_acc_before,\n",
        "                \"Avg_Acc_After\": avg_acc_after\n",
        "            }])\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_csv_path = os.path.join(folder_name, \"foreground_50.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "UbjVJLGtmbPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 25"
      ],
      "metadata": {
        "id": "09XYA02o1WPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "def calculate_reconstruction_error(original_activations, decoded_activations):\n",
        "    \"\"\"\n",
        "    Calculate the reconstruction error as mean squared error (MSE).\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(original_activations, decoded_activations)\n",
        "    return mse\n",
        "\n",
        "\n",
        "\n",
        "def plot_correlation_histogram(original, projected, title):\n",
        "    correlations = [\n",
        "        np.corrcoef(original[:, i], projected[:, i])[0, 1]\n",
        "        if np.std(original[:, i]) > 0 and np.std(projected[:, i]) > 0\n",
        "        else 0  # Handle constant features\n",
        "        for i in range(original.shape[1])\n",
        "    ]\n",
        "    correlations = np.nan_to_num(correlations)  # Replace NaNs with 0\n",
        "    plt.hist(correlations, bins=50, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Correlation\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences_25.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "'''\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"l1_neurons_by_correlation.csv\"):\n",
        "    \"\"\"\n",
        "    Save neurons sorted by their correlation between val_patch_activations and val_no_patch_activations.\n",
        "    \"\"\"\n",
        "    print(f\"Calculating neuron correlations and saving to {filename}\")\n",
        "\n",
        "    # Compute the correlation for each neuron across the two groups\n",
        "    correlations = np.array([\n",
        "        np.corrcoef(val_patch_activations[:, i], val_no_patch_activations[:, i])[0, 1]\n",
        "        if np.std(val_patch_activations[:, i]) > 0 and np.std(val_no_patch_activations[:, i]) > 0\n",
        "        else 0  # Set correlation to 0 if one group has constant values\n",
        "        for i in range(val_patch_activations.shape[1])\n",
        "    ])\n",
        "\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(correlations)),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by absolute correlation in ascending order (low correlation first)\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "'''\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"neurons_by_correlation_25.csv\"):\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Number of neurons should be 16k\n",
        "    num_neurons = val_patch_activations.shape[1]\n",
        "    print(f\"Number of val patch neurons: {num_neurons}\")\n",
        "    num_images = val_patch_activations.shape[0]\n",
        "    print(f\"Number of val patch images: {val_patch_activations.shape[0]}\")\n",
        "\n",
        "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
        "    pp = np.concatenate([np.ones(val_patch_activations.shape[0]), np.zeros(val_no_patch_activations.shape[0])])\n",
        "    print(f\"Number of pp labels: {len(pp)}\")\n",
        "\n",
        "    # array to store correlations\n",
        "    correlations = np.zeros(num_neurons)\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        # Combine activations for neuron i from both datassets p and np\n",
        "        act_i = np.concatenate([val_patch_activations[:, i], val_no_patch_activations[:, i]])\n",
        "\n",
        "        # Compute correlation between pp and act_i\n",
        "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
        "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
        "        else:\n",
        "            corr = 0  # Handle constant vectors\n",
        "\n",
        "        correlations[i] = corr\n",
        "\n",
        "    # As previous code\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "    print('shape of correlations', correlations.shape)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(num_neurons),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by correlation in descending order\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"l1_fg_top_neurons_25.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "\n",
        "    # Debugging for 0% muting\n",
        "    if percentage == 0:\n",
        "        assert len(top_neurons) == 0, \"Top neurons list should be empty for 0% muting.\"\n",
        "\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    model.eval() #TAKE A LOOK HERE!!!!!\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(output).item()\n",
        "        #prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item() #TAKE A LOOK HERE!!!!!\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111, 1111, 11111, 111111, 1111111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/foreground/l1_fg_autoencoder_layer_fc2_seed_{seed}.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_two_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_two_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_zero_fg_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_test_zero_org_100_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_val_zero_fg_25_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/foreground/fc2_activations_val_zero_org_25_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/foreground\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Prepare a DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Seed\", \"Percentage\",\n",
        "        \"Val_Patch_Before\", \"Val_NoPatch_Before\",\n",
        "        \"Val_Patch_After\", \"Val_NoPatch_After\",\n",
        "        \"Test_Two_Patch_Before\", \"Test_Two_NoPatch_Before\",\n",
        "        \"Test_Two_Patch_After\", \"Test_Two_NoPatch_After\",\n",
        "        \"Test_Zero_Patch_Before\", \"Test_Zero_NoPatch_Before\",\n",
        "        \"Test_Zero_Patch_After\", \"Test_Zero_NoPatch_After\",\n",
        "        \"Worst_Acc_Before\", \"Worst_Acc_After\",\n",
        "        \"Avg_Acc_Before\", \"Avg_Acc_After\"\n",
        "    ])\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "\n",
        "        # Load paths\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        test_two_patch = np.load(test_two_patch_path, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_two_no_patch_path, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_zero_patch_path, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_zero_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Classify \"before muting\"\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Project activations\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "\n",
        "        # Loop through percentages\n",
        "        for percentage in range(0, 51):  # 1% to 15%\n",
        "            print(f\"Testing with {percentage}% muting...\")\n",
        "\n",
        "            if percentage == 0:\n",
        "                # Decode original activations without muting\n",
        "                decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch).to(device).float()).cpu().numpy()\n",
        "                decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch).to(device).float()).cpu().numpy()\n",
        "\n",
        "                # Calculate reconstruction errors\n",
        "                recon_error_val_patch = calculate_reconstruction_error(val_activations_patch, decoded_val_patch)\n",
        "                recon_error_val_no_patch = calculate_reconstruction_error(val_activations_no_patch, decoded_val_no_patch)\n",
        "                recon_error_test_two_patch = calculate_reconstruction_error(test_two_patch, decoded_two_test_patch)\n",
        "                recon_error_test_two_no_patch = calculate_reconstruction_error(test_two_no_patch, decoded_two_test_no_patch)\n",
        "                recon_error_test_zero_patch = calculate_reconstruction_error(test_zero_patch, decoded_zero_test_patch)\n",
        "                recon_error_test_zero_no_patch = calculate_reconstruction_error(test_zero_no_patch, decoded_zero_test_no_patch)\n",
        "\n",
        "                # Print reconstruction errors\n",
        "                print(f\"Reconstruction Error (Val Patch): {recon_error_val_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Val No Patch): {recon_error_val_no_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Two Patch): {recon_error_test_two_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Two No Patch): {recon_error_test_two_no_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Zero Patch): {recon_error_test_zero_patch:.4f}\")\n",
        "                print(f\"Reconstruction Error (Test Zero No Patch): {recon_error_test_zero_no_patch:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "            # Calculate differences and load top neurons\n",
        "            #abs_diff = np.abs(np.mean(projected_val_patch, axis=0) - np.mean(projected_val_no_patch, axis=0))\n",
        "            #csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\")\n",
        "            #top_neurons = load_top_neurons_from_csv(folder_name, f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\", percentage)\n",
        "\n",
        "            # **Correlation-Based Neurons**\n",
        "            correlation_csv_path = save_neurons_by_correlation(\n",
        "                projected_val_patch, projected_val_no_patch, folder_name, filename=f\"l1_neurons_by_correlation_seed_{seed}_25.csv\"\n",
        "            )\n",
        "            top_neurons_corr = load_top_neurons_from_csv(folder_name, f\"l1_neurons_by_correlation_seed_{seed}_25.csv\", percentage)\n",
        "\n",
        "            top_neurons = top_neurons_corr\n",
        "\n",
        "            # Muting neurons\n",
        "            projected_val_patch_muted = projected_val_patch.copy()\n",
        "            projected_val_no_patch_muted = projected_val_no_patch.copy()\n",
        "            projected_two_test_patch_muted = projected_two_test_patch.copy()\n",
        "            projected_two_test_no_patch_muted = projected_two_test_no_patch.copy()\n",
        "            projected_zero_test_patch_muted = projected_zero_test_patch.copy()\n",
        "            projected_zero_test_no_patch_muted = projected_zero_test_no_patch.copy()\n",
        "\n",
        "            projected_val_patch_muted[:, top_neurons] = 0\n",
        "            projected_val_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_no_patch_muted[:, top_neurons] = 0\n",
        "\n",
        "            # Decode and classify\n",
        "            decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "\n",
        "            predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "            predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "            predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "            predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "            predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "            predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "            accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "            accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "            accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "            accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "            accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0] * len(predictions_test_zero_patch_after))\n",
        "            accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "            # Calculate worst and average group accuracies\n",
        "            worst_acc_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "            worst_acc_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "            avg_acc_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before +\n",
        "                              accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "            avg_acc_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after +\n",
        "                             accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "            # Append results to DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                \"Seed\": seed,\n",
        "                \"Percentage\": percentage,\n",
        "                \"Val_Patch_Before\": accuracy_val_patch_before,\n",
        "                \"Val_NoPatch_Before\": accuracy_val_no_patch_before,\n",
        "                \"Val_Patch_After\": accuracy_val_patch_after,\n",
        "                \"Val_NoPatch_After\": accuracy_val_no_patch_after,\n",
        "                \"Test_Two_Patch_Before\": accuracy_test_two_patch_before,\n",
        "                \"Test_Two_NoPatch_Before\": accuracy_test_two_no_patch_before,\n",
        "                \"Test_Two_Patch_After\": accuracy_test_two_patch_after,\n",
        "                \"Test_Two_NoPatch_After\": accuracy_test_two_no_patch_after,\n",
        "                \"Test_Zero_Patch_Before\": accuracy_test_zero_patch_before,\n",
        "                \"Test_Zero_NoPatch_Before\": accuracy_test_zero_no_patch_before,\n",
        "                \"Test_Zero_Patch_After\": accuracy_test_zero_patch_after,\n",
        "                \"Test_Zero_NoPatch_After\": accuracy_test_zero_no_patch_after,\n",
        "                \"Worst_Acc_Before\": worst_acc_before,\n",
        "                \"Worst_Acc_After\": worst_acc_after,\n",
        "                \"Avg_Acc_Before\": avg_acc_before,\n",
        "                \"Avg_Acc_After\": avg_acc_after\n",
        "            }])\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_csv_path = os.path.join(folder_name, \"foreground_25.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "0SyPPjt5muJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "# Function to load the trained model\n",
        "def load_model(model_path, device):\n",
        "    model = models.alexnet(pretrained=True)\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    params_to_update = model.parameters()\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Function to test the model on a specific dataset\n",
        "def test_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:  # Ignore group_label\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Define paths to the test datasets\n",
        "test_two_bg_path = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/background/test/class_2'\n",
        "test_two_org_path = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_2'\n",
        "test_zero_bg_path = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/background/test/class_0'\n",
        "test_zero_org_path = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_0'\n",
        "\n",
        "# Create test datasets\n",
        "dataset_test_two_bg = MnistDataset(path=test_two_bg_path, is_two=1)\n",
        "dataset_test_two_org = MnistDataset(path=test_two_org_path, is_two=1)\n",
        "dataset_test_zero_bg = MnistDataset(path=test_zero_bg_path, is_two=0)\n",
        "dataset_test_zero_org = MnistDataset(path=test_zero_org_path, is_two=0)\n",
        "\n",
        "# Create dataloaders for the test datasets\n",
        "batch_size = 64\n",
        "test_loader_two_bg = DataLoader(dataset_test_two_bg, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader_two_org = DataLoader(dataset_test_two_org, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader_zero_bg = DataLoader(dataset_test_zero_bg, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader_zero_org = DataLoader(dataset_test_zero_org, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load and test the model for each seed\n",
        "seeds = [1, 11, 111]\n",
        "\n",
        "\n",
        "for seed in seeds:\n",
        "    model_path = f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_bg_seed_{seed}.pt\"\n",
        "\n",
        "    print(f\"\\nLoading model with seed {seed}\")\n",
        "    model = load_model(model_path, device)\n",
        "\n",
        "    # Test on patches_left dataset\n",
        "    accuracy_two_bg = test_model(model, test_loader_two_bg, device)\n",
        "    print(f\"Accuracy on colored background test dataset (class_2): {accuracy_two_bg:.2f}%\")\n",
        "\n",
        "    # Test on original dataset\n",
        "    accuracy_two_org = test_model(model, test_loader_two_org, device)\n",
        "    print(f\"Accuracy on original background test dataset (class_2): {accuracy_two_org:.2f}%\")\n",
        "\n",
        "    accuracy_zero_org = test_model(model, test_loader_zero_org, device)\n",
        "    print(f\"Accuracy on original foreground test dataset (class_0): {accuracy_zero_org:.2f}%\")\n",
        "    accuracy_zero_bg = test_model(model, test_loader_zero_bg, device)\n",
        "    print(f\"Accuracy on colored foreground test dataset (class_0): {accuracy_zero_bg:.2f}%\")\n"
      ],
      "metadata": {
        "id": "SyDg2eU8EoJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits\"\n",
        "\n",
        "# Function to count images in each folder and subfolder\n",
        "def count_images_in_directory(directory):\n",
        "    image_count = {}\n",
        "    for root, _, files in os.walk(directory):\n",
        "        image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        image_count[root] = len(image_files)\n",
        "    return image_count\n",
        "\n",
        "image_counts = count_images_in_directory(base_dir)\n",
        "\n",
        "for folder, count in image_counts.items():\n",
        "    print(f\"Folder: {folder}, Image Count: {count}\")"
      ],
      "metadata": {
        "id": "6OeVdB9ULSRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRzejxlRDEaq"
      },
      "source": [
        "## Archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvcHM6sfDGEX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define all folder paths\n",
        "fg_folder_paths = {\n",
        "    'train_two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_2',\n",
        "    'train_zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_0',\n",
        "    'train_zero_fg': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/train/class_0',\n",
        "    'val_two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_2',\n",
        "    'val_zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0',\n",
        "    'val_zero_fg': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0',\n",
        "    'test_two_fg': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/test/class_2',\n",
        "    'test_two_org': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_2',\n",
        "    'test_zero_fg': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/test/class_0',\n",
        "    'test_zero_org': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_0'\n",
        "}\n",
        "\n",
        "bg_folder_paths = {\n",
        "    'train_two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_2',\n",
        "    'train_zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_0',\n",
        "    'train_zero_bg': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/background/train/class_0',\n",
        "    'val_two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_2',\n",
        "    'val_zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0',\n",
        "    'val_zero_bg': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/background/val/class_0',\n",
        "    'test_two_bg': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/background/test/class_2',\n",
        "    'test_two_org': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_2',\n",
        "    'test_zero_bg': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/background/test/class_0',\n",
        "    'test_zero_org': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_0'\n",
        "}\n",
        "\n",
        "\n",
        "dlp_folder_paths = {\n",
        "    'train_two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_2',\n",
        "    'train_zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_0',\n",
        "    'train_zero_dlp': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/train/class_0',\n",
        "    'val_two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_2',\n",
        "    'val_zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0',\n",
        "    'val_zero_dlp': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/val/class_0',\n",
        "    'test_two_dlp': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/test/class_2',\n",
        "    'test_two_org': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_2',\n",
        "    'test_zero_dlp': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/test/class_0',\n",
        "    'test_zero_org': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_0'\n",
        "}\n",
        "\n",
        "# Function to display a random image and count images in a folder\n",
        "def display_random_image_and_count(folder_name, folder_path):\n",
        "    # Get all image file names in the folder\n",
        "    try:\n",
        "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "        num_images = len(image_files)\n",
        "\n",
        "        print(f\"Folder: {folder_name}\")\n",
        "        print(f\"Total images: {num_images}\")\n",
        "\n",
        "        if num_images > 0:\n",
        "            # Select a random image\n",
        "            random_image = random.choice(image_files)\n",
        "            random_image_path = os.path.join(folder_path, random_image)\n",
        "\n",
        "            # Open and display the image\n",
        "            image = Image.open(random_image_path)\n",
        "            plt.figure(figsize=(4, 4))\n",
        "            plt.title(f\"Folder: {folder_name}\\nRandom Image: {random_image}\")\n",
        "            plt.imshow(image, cmap='gray')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No images found in this folder.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing folder {folder_name}: {e}\")\n",
        "\n",
        "print('Foreground')\n",
        "\n",
        "# Iterate over all folders and display random images\n",
        "for folder_name, folder_path in fg_folder_paths.items():\n",
        "    display_random_image_and_count(folder_name, folder_path)\n",
        "\n",
        "print('Background')\n",
        "\n",
        "# Iterate over all folders and display random images\n",
        "for folder_name, folder_path in bg_folder_paths.items():\n",
        "    display_random_image_and_count(folder_name, folder_path)\n",
        "\n",
        "print('Dynamic left patch')\n",
        "# Iterate over all folders and display random images\n",
        "for folder_name, folder_path in dlp_folder_paths.items():\n",
        "    display_random_image_and_count(folder_name, folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RmIBDI6wUhY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "# Function to load the trained model\n",
        "def load_model(model_path, device):\n",
        "    model = models.alexnet(pretrained=True)\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    params_to_update = model.parameters()\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Function to test the model on a specific dataset\n",
        "def test_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:  # Ignore group_label\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Define paths to the test datasets\n",
        "test_two_fg_path = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0'\n",
        "test_two_org_path = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0'\n",
        "\n",
        "# Create test datasets\n",
        "dataset_test_two_fg = MnistDataset(path=test_two_fg_path, is_two=0)\n",
        "dataset_test_two_org = MnistDataset(path=test_two_org_path, is_two=0)\n",
        "\n",
        "# Create dataloaders for the test datasets\n",
        "batch_size = 64\n",
        "test_loader_fg = DataLoader(dataset_test_two_fg, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader_org = DataLoader(dataset_test_two_org, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load and test the model for each seed\n",
        "seeds = [1, 11, 111]\n",
        "\n",
        "\n",
        "for seed in seeds:\n",
        "    model_path = f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_{seed}.pt\"\n",
        "\n",
        "    print(f\"\\nLoading model with seed {seed}\")\n",
        "    model = load_model(model_path, device)\n",
        "\n",
        "    # Test on patches_left dataset\n",
        "    accuracy_fg = test_model(model, test_loader_fg, device)\n",
        "    print(f\"Accuracy on colored digit val dataset (class_2): {accuracy_fg:.2f}%\")\n",
        "\n",
        "    # Test on original dataset\n",
        "    accuracy_org = test_model(model, test_loader_org, device)\n",
        "    print(f\"Accuracy on original digit val dataset (class_2): {accuracy_org:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDfzrj34MmJ6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "def calculate_reconstruction_error(original_activations, decoded_activations):\n",
        "    \"\"\"\n",
        "    Calculate the reconstruction error as mean squared error (MSE).\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(original_activations, decoded_activations)\n",
        "    return mse\n",
        "\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"fg_all_neuron_differences.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "\n",
        "\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"fg_top_neurons.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_fg_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/mnist_fg/fg_autoencoder_layer_fc2_seed_{seed}_unnormalized.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_fg/fc2_activations_test_two_fg_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_fg/fc2_activations_test_two_org_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_fg/fc2_activations_test_zero_fg_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_fg/fc2_activations_test_zero_org_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_fg/fc2_activations_val_zero_fg_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_fg/fc2_activations_val_zero_org_alexnet_mnist_fg_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/alexnet_mnist_finetune_fg\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        print(f\"Model Path: {model_path}\")\n",
        "        print(f\"Autoencoder Path: {sae_path}\")\n",
        "        print(f\"Validation Patch Path: {val_patch_path}\")\n",
        "        print(f\"Validation No Patch Path: {val_no_patch_path}\")\n",
        "        print(f\"Test Two Patch Path: {test_two_patch_path}\")\n",
        "        print(f\"Test Two No Patch Path: {test_two_no_patch_path}\")\n",
        "        print(f\"Test Zero Patch Path: {test_zero_patch_path}\")\n",
        "        print(f\"Test Zero No Patch Path: {test_zero_no_patch_path}\")\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Direct classification using AlexNet\n",
        "        predictions_val_patch_alexnet = classify_with_alexnet(model, val_activations_patch)\n",
        "        accuracy_val_patch_alexnet = accuracy_score([0] * len(predictions_val_patch_alexnet), predictions_val_patch_alexnet)\n",
        "\n",
        "        predictions_val_no_patch_alexnet = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_no_patch_alexnet = accuracy_score([0] * len(predictions_val_no_patch_alexnet), predictions_val_no_patch_alexnet)\n",
        "\n",
        "        # Classification before muting\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "\n",
        "        # Calculate validation accuracies before muting\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "\n",
        "\n",
        "        # Project validation activations into sparse space\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "\n",
        "        # Calculate differences and save neuron indexes\n",
        "        avg_val_patch = np.mean(projected_val_patch, axis=0)\n",
        "        avg_val_no_patch = np.mean(projected_val_no_patch, axis=0)\n",
        "        abs_diff = np.abs(avg_val_patch - avg_val_no_patch)\n",
        "        csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\")\n",
        "\n",
        "        csv_folder = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/alexnet_mnist_finetune_fg\"\n",
        "        csv_filename = f\"val_neuron_differences_seed_{seed}.csv\"\n",
        "        neurons_to_mute = load_top_neurons_from_csv(csv_folder, filename=f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\", percentage = 10)\n",
        "        #neurons_to_mute = top_neurons[:int(len(top_neurons) * 0.1)]\n",
        "        projected_val_patch[:, neurons_to_mute] = 0\n",
        "        projected_val_no_patch[:, neurons_to_mute] = 0\n",
        "\n",
        "        decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch).to(device).float()).cpu().numpy()\n",
        "        decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch).to(device).float()).cpu().numpy()\n",
        "\n",
        "        predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "        predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "\n",
        "        accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "        accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "\n",
        "        # Print Validation Results\n",
        "        print(f\"Validation Accuracy (Patch, Before Muting): {accuracy_val_patch_before:.4f}\")\n",
        "        print(f\"Validation Accuracy (No Patch, Before Muting): {accuracy_val_no_patch_before:.4f}\")\n",
        "        print(f\"Validation Accuracy (Patch, After Muting): {accuracy_val_patch_after:.4f}\")\n",
        "        print(f\"Validation Accuracy (No Patch, After Muting): {accuracy_val_no_patch_after:.4f}\")\n",
        "\n",
        "############################################################################################################################################\n",
        "        # Test Phase\n",
        "        test_two_patch = np.load(test_activation_two_patch_paths[seed_idx], allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_activation_two_no_patch_paths[seed_idx], allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_activation_zero_patch_paths[seed_idx], allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_activation_zero_no_patch_paths[seed_idx], allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "        # Test classification before muting\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Load top neurons from validation\n",
        "        top_neurons = load_top_neurons_from_csv(csv_folder, filename=f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\", percentage=10)\n",
        "\n",
        "        # Project test activations into sparse space\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "        #top_neuron_count = int(len(abs_diff) * 0.1)\n",
        "        #top_neurons = np.argsort(abs_diff)[-top_neuron_count:]\n",
        "\n",
        "        # Muting neurons in test data\n",
        "        percentage = 10\n",
        "        neurons_to_mute = load_top_neurons_from_csv(csv_folder, filename=f\"mnist_fg_val_neuron_differences_seed_{seed}.csv\", percentage = 10)\n",
        "        projected_two_test_patch[:, neurons_to_mute] = 0\n",
        "        projected_two_test_no_patch[:, neurons_to_mute] = 0\n",
        "        projected_zero_test_patch[:, neurons_to_mute] = 0\n",
        "        projected_zero_test_no_patch[:, neurons_to_mute] = 0\n",
        "\n",
        "\n",
        "        # Decode and classify test data\n",
        "        decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch).to(device).float()).cpu().detach().numpy()\n",
        "\n",
        "        # Classification\n",
        "        predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "        predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "        predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "        predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "        accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "        accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0]* len(predictions_test_zero_patch_after))\n",
        "        accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "        # Calculate Worst and Average Group Accuracies\n",
        "        worst_group_accuracy_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "        worst_group_accuracy_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "\n",
        "        # Calculate the average group accuracy correctly by dividing the sum of accuracies by 4\n",
        "        avg_group_accuracy_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before + accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "        avg_group_accuracy_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after + accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "        # Print Test Results\n",
        "        print(f\"Test Accuracy Two (Patch, Before Muting): {accuracy_test_two_patch_before:.4f}\")\n",
        "        print(f\"Test Accuracy Two (Patch, After Muting): {accuracy_test_two_patch_after:.4f}\")\n",
        "        print(f\"Test Accuracy Two (No Patch, Before Muting): {accuracy_test_two_no_patch_before:.4f}\")\n",
        "        print(f\"Test Accuracy Two (No Patch, After Muting): {accuracy_test_two_no_patch_after:.4f}\")\n",
        "        print(f\"Test Accuracy Zero (No Patch, Before Muting): {accuracy_test_zero_no_patch_before:.4f}\")\n",
        "        print(f\"Test Accuracy Zero (No Patch, After Muting): {accuracy_test_zero_no_patch_after:.4f}\")\n",
        "        print(f\"Test Accuracy Zero (Patch, Before Muting): {accuracy_test_zero_patch_before:.4f}\")\n",
        "        print(f\"Test Accuracy Zero (Patch, After Muting): {accuracy_test_zero_patch_after:.4f}\")\n",
        "        print(f\"Worst Group Accuracy (Before Muting): {worst_group_accuracy_before:.4f}\")\n",
        "        print(f\"Worst Group Accuracy (After Muting): {worst_group_accuracy_after:.4f}\")\n",
        "        print(f\"Average Group Accuracy (Before Muting): {avg_group_accuracy_before:.4f}\")\n",
        "        print(f\"Average Group Accuracy (After Muting): {avg_group_accuracy_after:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JRzejxlRDEaq"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}