{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7OfeLhEdFs_",
        "outputId": "4881c80a-3c1b-4d00-e134-bf0b287b5697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-8HTugQdEpH",
        "outputId": "6f1b31cd-d27c-4a32-b02e-b29a9099fafa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchextractor\n",
            "  Downloading torchextractor-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchextractor) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchextractor) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->torchextractor) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->torchextractor) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->torchextractor) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->torchextractor) (3.0.2)\n",
            "Downloading torchextractor-0.3.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: torchextractor\n",
            "Successfully installed torchextractor-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchextractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_cjXRL5dDFn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from os.path import join as oj\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import TensorDataset, ConcatDataset\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from numpy.random import randint\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import copy\n",
        "import gc\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from scipy.stats import ttest_1samp\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbanKT1Sml1i"
      },
      "source": [
        "### Loading fine tuned alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7eIdrXCYf-G"
      },
      "outputs": [],
      "source": [
        "class MnistDataset(Dataset):\n",
        "    def __init__(self, path: str = None, is_two: int = None, data_files=None, labels=None, transform=None):\n",
        "        self.resize_shape = (64, 64)  # Target shape for resizing images\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize(self.resize_shape),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for RGB images\n",
        "        ])\n",
        "\n",
        "        if path:\n",
        "            self.path = path\n",
        "            self.data_files = [f for f in os.listdir(self.path) if f.endswith(('.jpg', '.png'))]\n",
        "            if len(self.data_files) == 0:\n",
        "                raise ValueError(f\"No valid image files found in the provided path: {self.path}\")\n",
        "\n",
        "            self.is_two = is_two\n",
        "            self.labels = [is_two] * len(self.data_files) if is_two is not None else labels\n",
        "        else:\n",
        "            self.path = ''\n",
        "            if data_files is None or len(data_files) == 0:\n",
        "                raise ValueError(\"data_files must be a non-empty list of file paths.\")\n",
        "\n",
        "            self.data_files = data_files\n",
        "            self.labels = labels\n",
        "            self.is_two = is_two\n",
        "\n",
        "        if self.labels is not None and len(self.labels) != len(self.data_files):\n",
        "            raise ValueError(\"Mismatch between the number of labels and data files.\")\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        try:\n",
        "            img_path = os.path.join(self.path, self.data_files[i]) if self.path else self.data_files[i]\n",
        "            img = Image.open(img_path).convert(\"RGB\") #!!!!!\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            is_two = self.is_two if self.is_two is not None else self.labels[i]\n",
        "            return img, is_two  # Exclude group_label\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {i}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tP9JsQYc_xx"
      },
      "outputs": [],
      "source": [
        "mean = np.asarray([0.485, 0.456, 0.406])\n",
        "std = np.asarray([0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "# Function to load the trained model\n",
        "def load_model(model_path, device):\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    model = models.alexnet(pretrained=False)\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully\")\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwtywcNYmp_r"
      },
      "source": [
        "### Extract Alexnet training fc2 activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opam1xkUmtUk"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None, resize_shape=(64, 64)):\n",
        "        print(f\"Initializing dataset with {len(image_paths)} images\")\n",
        "        self.image_paths = image_paths\n",
        "        self.resize_shape = resize_shape  # Set the resize shape\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize(self.resize_shape),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for RGB images\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        print(f\"Loading image: {image_path}\")\n",
        "        image = Image.open(image_path).convert(\"RGB\") #!!!!!!!!!!!\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "# Preprocessing function\n",
        "preprocess = transforms.Compose([\n",
        "    #transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((64, 64)),  # Match the resize shape in MnistDataset\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Match the normalization values in MnistDataset\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz6R3SRirCLB"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    model = models.alexnet(pretrained=True)\n",
        "    #model = AlexNet().to(device)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    #model.fc3 = nn.Linear(4096, 2)\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully\")\n",
        "\n",
        "    # Freeze all layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print(\"Model loaded and layers frozen successfully\")\n",
        "\n",
        "    # Add a forward hook to capture fc2 activations\n",
        "    activations = {}\n",
        "\n",
        "    def hook(module, input, output):\n",
        "        activations[\"fc2\"] = output\n",
        "\n",
        "    # Attach the hook to the second last layer (fc2)\n",
        "    #model.fc2[1].register_forward_hook(hook)\n",
        "    model.classifier[4].register_forward_hook(hook)\n",
        "\n",
        "    return model, activations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_and_extract_activations(model, dataloader, layer):\n",
        "\n",
        "    activations = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            image_tensor = batch[0]  # Extract the image tensor (ignore labels)\n",
        "            image_tensor = image_tensor.to(device)\n",
        "\n",
        "            if layer < 13:  # Layer in model.features\n",
        "                tensor = image_tensor\n",
        "                for idx, layer_module in enumerate(model.features[:layer + 1]):\n",
        "                    tensor = layer_module(tensor)\n",
        "            else:  # Layer in model.classifier\n",
        "                tensor = model.features(image_tensor)\n",
        "                tensor = model.avgpool(tensor)\n",
        "                tensor = torch.flatten(tensor, 1)\n",
        "                for idx, layer_module in enumerate(model.classifier[:layer - 12]):\n",
        "                    tensor = layer_module(tensor)\n",
        "                    if idx == 4:\n",
        "                      print(f\"Extracting from FC2 (classifier[4]): {layer_module}\")\n",
        "                      print(f\"Activation shape at FC2: {tensor.shape}\")\n",
        "\n",
        "\n",
        "            activation = tensor.cpu().numpy()\n",
        "            activations.append(activation)\n",
        "\n",
        "    print(f\"Extracted activations for {len(activations)} images\")\n",
        "    return activations\n",
        "\n",
        "\n",
        "def process_images_in_folder(model, folder_path, layer, is_two, batch_size=1):\n",
        "    all_layer_activations = []\n",
        "\n",
        "    # Ensure folder_path is a string\n",
        "    if not isinstance(folder_path, str):\n",
        "        raise ValueError(f\"Expected folder_path to be a string, but got {type(folder_path)}\")\n",
        "\n",
        "    # Get all image file paths\n",
        "    image_paths = [os.path.join(root, file)\n",
        "                   for root, dirs, files in os.walk(folder_path)\n",
        "                   for file in files if file.endswith(('.jpg', '.png'))]\n",
        "\n",
        "    if len(image_paths) == 0:\n",
        "        raise ValueError(f\"No image files found in folder: {folder_path}\")\n",
        "\n",
        "    print(f\"Initializing dataset with {len(image_paths)} images and is_two={is_two}\")\n",
        "    # Create the dataset and DataLoader\n",
        "    dataset = ImageDataset(image_paths=image_paths, transform=preprocess)\n",
        "    print(f\"Dataset initialized with {len(dataset)} items.\")\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Prepare dictionary for activations\n",
        "    activations_dict = {}\n",
        "\n",
        "    # Define the hook for the specified layer\n",
        "    def hook(module, input, output):\n",
        "        activations_dict[layer] = output\n",
        "\n",
        "    # Register hook for the specified layer\n",
        "    if layer == 'fc2':\n",
        "        model.classifier[4].register_forward_hook(hook)  # Attach to fc2's Linear layer\n",
        "\n",
        "    # Iterate over the dataloader to extract activations\n",
        "    for images in dataloader:  # Only images are returned by the dataset\n",
        "        if images is None:\n",
        "            print(\"Skipping invalid batch.\")\n",
        "            continue\n",
        "\n",
        "        images = images.to(next(model.parameters()).device)  # Move images to the same device as the model\n",
        "        _ = model(images)  # Forward pass to trigger hooks\n",
        "\n",
        "        # Collect activations from the specified layer\n",
        "        if layer in activations_dict:\n",
        "            all_layer_activations.append(activations_dict[layer].cpu().numpy())\n",
        "\n",
        "    if len(all_layer_activations) == 0:\n",
        "        raise ValueError(\"No activations were collected. Check dataset or model.\")\n",
        "\n",
        "    # Concatenate activations if batched\n",
        "    all_layer_activations = np.concatenate(all_layer_activations, axis=0)\n",
        "\n",
        "    # Free resources\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return all_layer_activations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3yFGpq9sgdh"
      },
      "outputs": [],
      "source": [
        "def flatten_and_align_activations(activations_list):\n",
        "    print(\"Flattening and aligning activations\")\n",
        "    flat_activations = [act.flatten() for act in activations_list]\n",
        "    max_length = max(len(act) for act in flat_activations)\n",
        "\n",
        "    aligned_activations = []\n",
        "    for activation in flat_activations:\n",
        "        if len(activation) < max_length:\n",
        "            padded_activation = np.pad(activation, (0, max_length - len(activation)), 'constant')\n",
        "        else:\n",
        "            padded_activation = activation[:max_length]\n",
        "        aligned_activations.append(padded_activation)\n",
        "    print(f\"Aligned activations to shape: {np.vstack(aligned_activations).shape}\")\n",
        "    return np.vstack(aligned_activations)\n",
        "\n",
        "\n",
        "def save_activations(activations, folder_name, filename): #?????\n",
        "    try:\n",
        "        drive_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/{folder_name}/alexnet_mnist_finetune_dlp/{filename}.npy'\n",
        "        os.makedirs(os.path.dirname(drive_path), exist_ok=True)\n",
        "        print(f\"Saving activations to {drive_path}\")\n",
        "        np.save(drive_path, activations)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving activations to {drive_path}: {e}\")\n",
        "\n",
        "def load_activations(folder_name, filename):\n",
        "    try:\n",
        "        drive_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/{folder_name}/alexnet_mnist_finetune_dlp/{filename}.npy'\n",
        "        print(f\"Loading activations from {drive_path}\")\n",
        "        return np.load(drive_path, allow_pickle=True)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Activations not found at {drive_path}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1LM8UFosmAh"
      },
      "outputs": [],
      "source": [
        "def compute_activations_for_layers(model_paths, folder_paths, layers, activations_file_prefix):\n",
        "    # Initialize the dictionary with all keys in folder_paths\n",
        "    all_layer_activations = {layer: {key: [] for key in folder_paths.keys()} for layer in layers}\n",
        "\n",
        "    for folder_name, folder_path in folder_paths.items():\n",
        "        print(f\"Processing folder {folder_name}\")\n",
        "\n",
        "        # Get the is_two value from the mapping\n",
        "        is_two = is_two_mapping.get(folder_name)\n",
        "        if is_two is None:\n",
        "            raise ValueError(f\"Unknown folder name: {folder_name}. maybe update is_two_mapping.\")\n",
        "\n",
        "        for layer in layers:\n",
        "            for model_idx, model_path in enumerate(model_paths):\n",
        "                print(f\"Processing model {model_idx + 1}/{len(model_paths)}\")\n",
        "                model, activations_dict = load_model(model_path)\n",
        "\n",
        "                def hook(module, input, output):\n",
        "                    activations_dict[layer] = output\n",
        "\n",
        "                model.classifier[4].register_forward_hook(hook)\n",
        "\n",
        "                # Pass is_two when creating the dataset\n",
        "                activations = process_images_in_folder(model, folder_path, layer, is_two=is_two, batch_size=1)\n",
        "                activations = flatten_and_align_activations(activations)\n",
        "\n",
        "                # Save activations for this model and folder\n",
        "                model_specific_file_prefix = f'{activations_file_prefix}_model{model_idx + 1}_{folder_name}'\n",
        "                save_activations(activations, f'layer_{layer}', model_specific_file_prefix)\n",
        "\n",
        "                all_layer_activations[layer][folder_name].append(activations)\n",
        "\n",
        "                del model\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "    return all_layer_activations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Extract Training Activations\n",
        "\n",
        "model_paths = [\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_1.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_11.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_111.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_1111.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_11111.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_111111.pt\",\n",
        "    \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_1111111.pt\"\n",
        "]\n",
        "\n",
        "layers_of_interest = ['fc2']\n",
        "\n",
        "is_two_mapping = {\n",
        "    'two_no_patch': 1,\n",
        "    'zero_no_patch': 0,\n",
        "    'zero_patch': 0\n",
        "}\n",
        "\n",
        "\n",
        "# Paths to training data\n",
        "train_folder_paths = {\n",
        "    'two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_2',\n",
        "    'zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/train/class_0',\n",
        "    'zero_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/train/class_0'\n",
        "}\n",
        "\n",
        "\n",
        "val_folder_paths = {\n",
        "    'two_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_2',\n",
        "    'zero_no_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0',\n",
        "    'zero_patch': '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/val/class_0'\n",
        "}\n",
        "\n",
        "\n",
        "# Extract and save averaged training activations across three models\n",
        "#train_activations = compute_activations_for_layers(model_paths, train_folder_paths, layers_of_interest, 'train')\n",
        "#val_activations = compute_activations_for_layers(model_paths, val_folder_paths, layers_of_interest, 'val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I1fCyvQ2cBS"
      },
      "source": [
        "### Load saved activations of the fc2 alexnet training to later train the SAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a59xOvVP2DWC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_saved_activations(subset, activations_file_prefix, model_idx=None, dataset_type=\"train\"):\n",
        "    \"\"\"\n",
        "    Load saved activations from files with the format: {dataset_type}_model{idx}_{subset}.npy.\n",
        "\n",
        "    Parameters:\n",
        "        subset (str): The data subset (e.g., \"two_no_patch\", \"zero_no_patch\", \"zero_patch\").\n",
        "        activations_file_prefix (str): File prefix for the activations.\n",
        "        model_idx (int or None): Specific model index to load (e.g., 1, 2, 3). If None, load all models.\n",
        "        dataset_type (str): The dataset type (\"train\" or \"val\").\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray or List[np.ndarray]: Loaded activations for a specific model (if model_idx is provided)\n",
        "                                        or a list of activations for all models.\n",
        "    \"\"\"\n",
        "    activations = []\n",
        "\n",
        "    if model_idx is not None:\n",
        "        # Load activations for a specific model\n",
        "        drive_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/alexnet_mnist_finetune_dlp/{dataset_type}_model{model_idx}_{subset}.npy'\n",
        "        print(f\"Loading activations from {drive_path}\")\n",
        "\n",
        "        if os.path.exists(drive_path):\n",
        "            model_activations = np.load(drive_path, allow_pickle=True)\n",
        "            print(f\"Loaded activations for subset {subset}, dataset {dataset_type}, model {model_idx}. Shape: {model_activations.shape}\")\n",
        "            return model_activations\n",
        "        else:\n",
        "            print(f\"Activations file {drive_path} does not exist.\")\n",
        "            return None\n",
        "    else:\n",
        "        # Load activations for all models\n",
        "        for idx in range(1, 8):  # Adjust the range based on the number of models\n",
        "            drive_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/alexnet_mnist_finetune_dlp/{dataset_type}_model{idx}_{subset}.npy'\n",
        "            print(f\"Loading activations from {drive_path}\")\n",
        "\n",
        "            if os.path.exists(drive_path):\n",
        "                model_activations = np.load(drive_path, allow_pickle=True)\n",
        "                print(f\"Loaded activations for subset {subset}, dataset {dataset_type}, model {idx}. Shape: {model_activations.shape}\")\n",
        "                activations.append(model_activations)\n",
        "            else:\n",
        "                print(f\"Activations file {drive_path} does not exist.\")\n",
        "\n",
        "        if len(activations) > 0:\n",
        "            print(f\"Loaded activations for {len(activations)} model(s).\")\n",
        "            return activations  # List of numpy arrays, one for each model\n",
        "        else:\n",
        "            print(\"No activations files found.\")\n",
        "            return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ikq6cjxO23WR"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define Sparse Autoencoder with KL-divergence\n",
        "class SparseAutoencoder(nn.Module):\n",
        "    def __init__(self, in_dims, h_dims, sparsity_lambda=1.5, sparsity_target=0.20, xavier_norm_init=True):\n",
        "        super(SparseAutoencoder, self).__init__()\n",
        "        self.in_dims = in_dims  # Input dimension (number of neurons in the input layer)\n",
        "        self.h_dims = h_dims  # Hidden dimension (number of neurons in the hidden layer)\n",
        "        self.sparsity_lambda = sparsity_lambda  # Weight for the sparsity penalty term\n",
        "        self.sparsity_target = sparsity_target  # Target sparsity (desired average activation)\n",
        "\n",
        "        # Encoder: Projects input to the hidden (sparse) space\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.in_dims, self.h_dims),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        if xavier_norm_init:\n",
        "            nn.init.xavier_uniform_(self.encoder[0].weight)  # Xavier initialization\n",
        "\n",
        "        # Decoder: Reconstructs the input from the hidden (sparse) representation\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.h_dims, self.in_dims),\n",
        "            #nn.ReLU()\n",
        "        )\n",
        "        if xavier_norm_init:\n",
        "            nn.init.xavier_uniform_(self.decoder[0].weight)\n",
        "\n",
        "    # Forward pass through the encoder and decoder\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)  # Pass input through encoder\n",
        "        decoded = self.decoder(encoded)  # Pass encoded (sparse) representation through decoder\n",
        "        return encoded, decoded\n",
        "\n",
        "\n",
        "    def kl_sparsity_penalty(self, encoded):\n",
        "        # Penalize the average absolute activation\n",
        "        rho_hat = torch.mean(torch.abs(encoded), dim=0)  # Average absolute activation per hidden unit\n",
        "        rho = torch.ones_like(rho_hat) * self.sparsity_target  # Target sparsity value\n",
        "        epsilon = 1e-8  # Small value to avoid log(0)\n",
        "\n",
        "        # KL-divergence computation for sparsity\n",
        "        kl_divergence = rho * torch.log(rho / (rho_hat + epsilon)) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat + epsilon))\n",
        "        kl_divergence = torch.sum(kl_divergence)  # Sum over all hidden units\n",
        "\n",
        "        return self.sparsity_lambda * kl_divergence\n",
        "\n",
        "\n",
        "\n",
        "    # L1-norm sparsity penalty calculation\n",
        "    def l1_sparsity_penalty(self, encoded):\n",
        "        # Compute the mean of absolute values of activations\n",
        "        sparsity_loss = torch.mean(torch.abs(encoded))  # Average absolute activation across all units\n",
        "        return self.sparsity_lambda * sparsity_loss  # Scale by the sparsity weight\n",
        "\n",
        "\n",
        "    # KL-divergence sparsity penalty calculation\n",
        "    def old_kl_sparsity_penalty(self, encoded):\n",
        "        rho_hat = torch.mean(encoded, dim=0)  # Compute the average activation for each hidden neuron\n",
        "        rho = torch.ones_like(rho_hat) * self.sparsity_target  # Target sparsity value\n",
        "        epsilon = 1e-8  # Small value to avoid log(0)\n",
        "        kl_divergence = F.kl_div((rho_hat + epsilon).log(), rho + epsilon, reduction='batchmean')  # KL-divergence\n",
        "        return self.sparsity_lambda * kl_divergence  # Return the sparsity penalty, weighted by lambda\n",
        "\n",
        "    # Loss function combining MSE (reconstruction error) and sparsity penalty\n",
        "    def loss_function(self, decoded, original, encoded):\n",
        "        mse_loss = F.mse_loss(decoded, original)  # Mean Squared Error for reconstruction\n",
        "        sparsity_loss = self.l1_sparsity_penalty(encoded)  # Sparsity penalty for hidden layer activations\n",
        "        return mse_loss + sparsity_loss  # Total loss is MSE + sparsity penalty\n",
        "\n",
        "\n",
        "# Early stopping mechanism to prevent overfitting\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=20, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta  # Minimum change to qualify as an improvement\n",
        "        self.best_loss = None  # Best validation loss observed so far\n",
        "        self.counter = 0  # Counter to keep track of how many epochs since the last improvement\n",
        "\n",
        "    # Check if training should be stopped based on validation loss\n",
        "    def check(self, loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = loss  # Set the initial best loss\n",
        "            return False\n",
        "\n",
        "        # If the loss has improved significantly\n",
        "        if loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = loss  # Update best loss\n",
        "            self.counter = 0  # Reset counter\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1  # Increment counter if no improvement\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"Early stopping triggered.\")  # Stop training if patience is exceeded\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "\n",
        "# Training Function with Loss Tracking and Plotting\n",
        "def train_autoencoder(autoencoder, train_data, val_data, num_epochs=500, batch_size=128, learning_rate=1e-4, validation_split=0.2, clip_gradients=True, max_grad_norm=0.5):\n",
        "    #print(f\"Training autoencoder with input dim {data.shape[1]} and encoding dim {autoencoder.h_dims}\")\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    #num_train = int((1 - validation_split) * len(data))  # Compute the number of training samples\n",
        "    #train_data = data[:num_train]  # Training data\n",
        "    #val_data = data[num_train:]  # Validation data\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_tensor = torch.from_numpy(train_data).float()\n",
        "    val_tensor = torch.from_numpy(val_data).float()\n",
        "    # Create PyTorch datasets and dataloaders for training and validation\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_data).float())\n",
        "    val_dataset = torch.utils.data.TensorDataset(torch.from_numpy(val_data).float())\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Adam optimizer with learning rate and weight decay for regularization\n",
        "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate, weight_decay=1e-2)\n",
        "\n",
        "    # Initialize early stopping\n",
        "    early_stopping = EarlyStopping(patience=30, min_delta=0.001)\n",
        "\n",
        "    # Lists to store training and validation loss values\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # Start training loop\n",
        "    autoencoder.train()  # Set the autoencoder in training mode\n",
        "    for epoch in range(num_epochs):\n",
        "        total_train_loss = 0  # Initialize training loss for the current epoch\n",
        "\n",
        "        # Iterate over batches in the training set\n",
        "        for x_batch, in train_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "            encoded, decoded = autoencoder(x_batch)  # Forward pass through autoencoder\n",
        "            loss = autoencoder.loss_function(decoded, x_batch, encoded)  # Compute the loss\n",
        "            loss.backward()  # Backpropagate the error\n",
        "\n",
        "            # Apply gradient clipping if enabled\n",
        "            if clip_gradients:\n",
        "                torch.nn.utils.clip_grad_norm_(autoencoder.parameters(), max_grad_norm)\n",
        "\n",
        "            optimizer.step()  # Update the weights using the optimizer\n",
        "            total_train_loss += loss.item()  # Accumulate training loss for this batch\n",
        "\n",
        "        # Validation step after each epoch\n",
        "        total_val_loss = 0  # Initialize validation loss\n",
        "        autoencoder.eval()  # Set the autoencoder in evaluation mode\n",
        "        with torch.no_grad():  # No gradient calculation in validation mode\n",
        "            for x_batch, in val_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                encoded, decoded = autoencoder(x_batch)\n",
        "                loss = autoencoder.loss_function(decoded, x_batch, encoded)\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "        # Compute the average training and validation loss for this epoch\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        # Store the loss values for plotting later\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Print progress for the current epoch\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}')\n",
        "\n",
        "        # Check early stopping condition based on validation loss\n",
        "        if early_stopping.check(avg_val_loss):\n",
        "            break\n",
        "\n",
        "    print(\"Autoencoder training completed\")\n",
        "\n",
        "    # Plot the training and validation loss over epochs\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Li6LJndh25th",
        "outputId": "fc52e954-d5e5-4915-fefb-36a8fc9b1ece"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Define the directory to save autoencoders trained on normalized activations\\nsave_sae_dir = \\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/dynamic_left_patch\\'  # Directory to save the trained autoencoder\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\nos.makedirs(save_sae_dir, exist_ok=True)\\nlayers_of_interest = [\\'fc2\\']\\n\\n# Iterate through layers of interest\\nfor layer in layers_of_interest:\\n    print(f\\'\\nTraining autoencoders for layer {layer}\\')\\n\\n    # Iterate through seeds (corresponding to models)\\n    for seed_idx, seed in enumerate([1, 11, 111, 1111, 11111, 111111, 1111111], start=1):\\n        print(f\"\\nProcessing activations for layer {layer}, seed {seed} (Model {seed_idx})\")\\n\\n        # Get training activations for the current seed and layer\\n        train_activations_list = []\\n        print(f\"\\nTrain files associated with seed {seed}:\")\\n        for idx in range(1, 8): #!!!!!!!!!!!!!!\\n            for subset in [\\'two_no_patch\\', \\'zero_no_patch\\', \\'zero_patch\\'] :\\n                #train_file_path = f\\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/alexnet_mnist_finetune_fg/train_model{idx}_{subset}.npy\\'\\n                train_file_path = f\\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/dynamic_left_patch/train_model{idx}_{subset}.npy\\'\\n                if os.path.exists(train_file_path):\\n                    subset_activations = np.load(train_file_path)  # Load the .npy file\\n                    train_activations_list.append(subset_activations)\\n                    print(f\"  - Subset: {subset}, File: {train_file_path}\")\\n                else:\\n                    print(f\"Warning: File not found - {train_file_path}\")\\n\\n        if len(train_activations_list) == 0:\\n            print(f\"No train activations found for layer {layer}, seed {seed}. Skipping...\")\\n            continue\\n\\n        # Combine train activations\\n        combined_train_activations = np.vstack(train_activations_list)\\n        print(f\"Combined train activations shape for layer {layer}, seed {seed}: {combined_train_activations.shape}\")\\n\\n        # Get validation activations for the current seed and layer\\n        val_activations_list = []\\n        print(f\"\\nValidation files associated with seed {seed}:\")\\n        for idx in range(1, 8): #!!!!!!!!!\\n            for subset in [\\'two_no_patch\\', \\'zero_no_patch\\', \\'zero_patch\\']:\\n                val_file_path = f\\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/dynamic_left_patch/val_model{idx}_{subset}.npy\\'\\n                if os.path.exists(val_file_path):\\n                    subset_activations = np.load(val_file_path)  # Load the .npy file\\n                    val_activations_list.append(subset_activations)\\n                    print(f\"  - Subset: {subset}, File: {val_file_path}\")\\n                else:\\n                    print(f\"Warning: File not found - {val_file_path}\")\\n\\n        if len(val_activations_list) == 0:\\n            print(f\"No val activations found for layer {layer}, seed {seed}. Skipping...\")\\n            continue\\n\\n        # Combine val activations\\n        combined_val_activations = np.vstack(val_activations_list)\\n        print(f\"Combined val activations shape for layer {layer}, seed {seed}: {combined_val_activations.shape}\")\\n\\n        # Set the random seed for reproducibility\\n        torch.manual_seed(seed)\\n        np.random.seed(seed)\\n\\n        # Define encoding dimension\\n        encoding_dim = 16000\\n\\n        # Train autoencoder on unnormalized activations\\n        autoencoder = SparseAutoencoder(combined_train_activations.shape[1], encoding_dim).to(device)\\n        print(f\"Training autoencoder for layer {layer} (unnormalized, seed {seed})\")\\n        autoencoder = train_autoencoder(autoencoder, combined_train_activations, combined_val_activations,\\n                                        num_epochs=400, learning_rate=1e-5)\\n        # Print losses for inspection\\n        #print(f\"Training Losses for layer {layer}, seed {seed}: {train_losses}\")\\n\\n        #print(f\"Validation Losses for layer {layer}, seed {seed}: {val_losses}\")\\n        # Save the trained autoencoder\\n        save_path_unnormalized = os.path.join(\\n            save_sae_dir, f\\'l1_dlp_autoencoder_layer_{layer}_seed_{seed}.pth\\'\\n        )\\n        torch.save(autoencoder.state_dict(), save_path_unnormalized)\\n        print(f\"Saved autoencoder at {save_path_unnormalized}\")\\n\\n        # Clear memory\\n        del autoencoder\\n        torch.cuda.empty_cache()\\n        gc.collect()\\n\\nprint(\"\\nAll autoencoders trained and saved successfully.\")\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import gc\n",
        "'''\n",
        "# Define the directory to save autoencoders trained on normalized activations\n",
        "save_sae_dir = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/dynamic_left_patch'  # Directory to save the trained autoencoder\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "os.makedirs(save_sae_dir, exist_ok=True)\n",
        "layers_of_interest = ['fc2']\n",
        "\n",
        "# Iterate through layers of interest\n",
        "for layer in layers_of_interest:\n",
        "    print(f'\\nTraining autoencoders for layer {layer}')\n",
        "\n",
        "    # Iterate through seeds (corresponding to models)\n",
        "    for seed_idx, seed in enumerate([1, 11, 111, 1111, 11111, 111111, 1111111], start=1):\n",
        "        print(f\"\\nProcessing activations for layer {layer}, seed {seed} (Model {seed_idx})\")\n",
        "\n",
        "        # Get training activations for the current seed and layer\n",
        "        train_activations_list = []\n",
        "        print(f\"\\nTrain files associated with seed {seed}:\")\n",
        "        for idx in range(1, 8): #!!!!!!!!!!!!!!\n",
        "            for subset in ['two_no_patch', 'zero_no_patch', 'zero_patch'] :\n",
        "                #train_file_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/alexnet_mnist_finetune_fg/train_model{idx}_{subset}.npy'\n",
        "                train_file_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/dynamic_left_patch/train_model{idx}_{subset}.npy'\n",
        "                if os.path.exists(train_file_path):\n",
        "                    subset_activations = np.load(train_file_path)  # Load the .npy file\n",
        "                    train_activations_list.append(subset_activations)\n",
        "                    print(f\"  - Subset: {subset}, File: {train_file_path}\")\n",
        "                else:\n",
        "                    print(f\"Warning: File not found - {train_file_path}\")\n",
        "\n",
        "        if len(train_activations_list) == 0:\n",
        "            print(f\"No train activations found for layer {layer}, seed {seed}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Combine train activations\n",
        "        combined_train_activations = np.vstack(train_activations_list)\n",
        "        print(f\"Combined train activations shape for layer {layer}, seed {seed}: {combined_train_activations.shape}\")\n",
        "\n",
        "        # Get validation activations for the current seed and layer\n",
        "        val_activations_list = []\n",
        "        print(f\"\\nValidation files associated with seed {seed}:\")\n",
        "        for idx in range(1, 8): #!!!!!!!!!\n",
        "            for subset in ['two_no_patch', 'zero_no_patch', 'zero_patch']:\n",
        "                val_file_path = f'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/individual/layer_fc2/dynamic_left_patch/val_model{idx}_{subset}.npy'\n",
        "                if os.path.exists(val_file_path):\n",
        "                    subset_activations = np.load(val_file_path)  # Load the .npy file\n",
        "                    val_activations_list.append(subset_activations)\n",
        "                    print(f\"  - Subset: {subset}, File: {val_file_path}\")\n",
        "                else:\n",
        "                    print(f\"Warning: File not found - {val_file_path}\")\n",
        "\n",
        "        if len(val_activations_list) == 0:\n",
        "            print(f\"No val activations found for layer {layer}, seed {seed}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Combine val activations\n",
        "        combined_val_activations = np.vstack(val_activations_list)\n",
        "        print(f\"Combined val activations shape for layer {layer}, seed {seed}: {combined_val_activations.shape}\")\n",
        "\n",
        "        # Set the random seed for reproducibility\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # Define encoding dimension\n",
        "        encoding_dim = 16000\n",
        "\n",
        "        # Train autoencoder on unnormalized activations\n",
        "        autoencoder = SparseAutoencoder(combined_train_activations.shape[1], encoding_dim).to(device)\n",
        "        print(f\"Training autoencoder for layer {layer} (unnormalized, seed {seed})\")\n",
        "        autoencoder = train_autoencoder(autoencoder, combined_train_activations, combined_val_activations,\n",
        "                                        num_epochs=400, learning_rate=1e-5)\n",
        "        # Print losses for inspection\n",
        "        #print(f\"Training Losses for layer {layer}, seed {seed}: {train_losses}\")\n",
        "\n",
        "        #print(f\"Validation Losses for layer {layer}, seed {seed}: {val_losses}\")\n",
        "        # Save the trained autoencoder\n",
        "        save_path_unnormalized = os.path.join(\n",
        "            save_sae_dir, f'l1_dlp_autoencoder_layer_{layer}_seed_{seed}.pth'\n",
        "        )\n",
        "        torch.save(autoencoder.state_dict(), save_path_unnormalized)\n",
        "        print(f\"Saved autoencoder at {save_path_unnormalized}\")\n",
        "\n",
        "        # Clear memory\n",
        "        del autoencoder\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "print(\"\\nAll autoencoders trained and saved successfully.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "fd52sNKG_b97",
        "outputId": "c81d4570-0830-42f8-90c3-c7d2092cb60b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndevice = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n# Define the directory to save autoencoders trained on normalized activations\\nsave_sae_dir = \\'/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/dynamic_left_patch\\'  # Directory to save the trained autoencoder\\nos.makedirs(save_sae_dir, exist_ok=True)\\n\\n# Iterate through layers of interest\\nfor layer in layers_of_interest:\\n    print(f\\'\\nTraining autoencoders for layer {layer}\\')\\n\\n    # Iterate through seeds (corresponding to models)\\n    for seed_idx, seed in enumerate([1, 11, 111, 1111, 11111, 111111, 1111111], start=1):\\n        print(f\"\\nProcessing activations for layer {layer}, seed {seed} (Model {seed_idx})\")\\n\\n        # Get training activations for the current seed and layer\\n        train_activations_list = []\\n        print(f\"\\nTrain files associated with seed {seed}:\")\\n        for subset in [\\'two_no_patch\\', \\'zero_no_patch\\', \\'zero_patch\\']:\\n            if subset in train_activations[layer]:\\n                subset_activations = train_activations[layer][subset][seed_idx - 1]  # Seed index starts from 1, Python lists are 0-based\\n                train_activations_list.append(subset_activations)\\n                print(f\"  - Subset: {subset}, File: train_model{seed_idx}_{subset}.npy\")\\n            else:\\n                print(f\"Warning: No train activations found for subset {subset}, layer {layer}, seed {seed}.\")\\n\\n        if len(train_activations_list) == 0:\\n            print(f\"No train activations found for layer {layer}, seed {seed}. Skipping...\")\\n            continue\\n\\n        # Combine train activations\\n        combined_train_activations = np.vstack(train_activations_list)\\n        print(f\"Combined train activations shape for layer {layer}, seed {seed}: {combined_train_activations.shape}\")\\n\\n        # Get validation activations for the current seed and layer\\n        val_activations_list = []\\n        print(f\"\\nValidation files associated with seed {seed}:\")\\n        for subset in [\\'two_no_patch\\', \\'zero_no_patch\\', \\'zero_patch\\']:\\n            if subset in val_activations[layer]:\\n                subset_activations = val_activations[layer][subset][seed_idx - 1]\\n                val_activations_list.append(subset_activations)\\n                print(f\"  - Subset: {subset}, File: val_model{seed_idx}_{subset}.npy\")\\n            else:\\n                print(f\"Warning: No val activations found for subset {subset}, layer {layer}, seed {seed}.\")\\n\\n        if len(val_activations_list) == 0:\\n            print(f\"No val activations found for layer {layer}, seed {seed}. Skipping...\")\\n            continue\\n\\n        # Combine val activations\\n        combined_val_activations = np.vstack(val_activations_list)\\n        print(f\"Combined val activations shape for layer {layer}, seed {seed}: {combined_val_activations.shape}\")\\n\\n        # Set the random seed for reproducibility\\n        torch.manual_seed(seed)\\n        np.random.seed(seed)\\n\\n        # Define encoding dimension\\n        encoding_dim = 8000\\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n        # Train autoencoder on unnormalized activations\\n        autoencoder = SparseAutoencoder(combined_train_activations.shape[1], encoding_dim).to(device)\\n        print(f\"Training autoencoder for layer {layer} (unnormalized, seed {seed})\")\\n        autoencoder = train_autoencoder(autoencoder, combined_train_activations, combined_val_activations,\\n                                        num_epochs=500, learning_rate=1e-4)\\n\\n        # Save the trained autoencoder\\n        save_path_unnormalized = os.path.join(\\n            save_sae_dir, f\\'dlp_autoencoder_layer_{layer}_seed_{seed}.pth\\'\\n        )\\n        torch.save(autoencoder.state_dict(), save_path_unnormalized)\\n        print(f\"Saved unnormalized autoencoder at {save_path_unnormalized}\")\\n\\n        # Clear memory\\n        del autoencoder\\n        torch.cuda.empty_cache()\\n        gc.collect()\\n\\nprint(\"\\nAll autoencoders trained and saved successfully.\")\\n'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Define the directory to save autoencoders trained on normalized activations\n",
        "save_sae_dir = '/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/dynamic_left_patch'  # Directory to save the trained autoencoder\n",
        "os.makedirs(save_sae_dir, exist_ok=True)\n",
        "\n",
        "# Iterate through layers of interest\n",
        "for layer in layers_of_interest:\n",
        "    print(f'\\nTraining autoencoders for layer {layer}')\n",
        "\n",
        "    # Iterate through seeds (corresponding to models)\n",
        "    for seed_idx, seed in enumerate([1, 11, 111, 1111, 11111, 111111, 1111111], start=1):\n",
        "        print(f\"\\nProcessing activations for layer {layer}, seed {seed} (Model {seed_idx})\")\n",
        "\n",
        "        # Get training activations for the current seed and layer\n",
        "        train_activations_list = []\n",
        "        print(f\"\\nTrain files associated with seed {seed}:\")\n",
        "        for subset in ['two_no_patch', 'zero_no_patch', 'zero_patch']:\n",
        "            if subset in train_activations[layer]:\n",
        "                subset_activations = train_activations[layer][subset][seed_idx - 1]  # Seed index starts from 1, Python lists are 0-based\n",
        "                train_activations_list.append(subset_activations)\n",
        "                print(f\"  - Subset: {subset}, File: train_model{seed_idx}_{subset}.npy\")\n",
        "            else:\n",
        "                print(f\"Warning: No train activations found for subset {subset}, layer {layer}, seed {seed}.\")\n",
        "\n",
        "        if len(train_activations_list) == 0:\n",
        "            print(f\"No train activations found for layer {layer}, seed {seed}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Combine train activations\n",
        "        combined_train_activations = np.vstack(train_activations_list)\n",
        "        print(f\"Combined train activations shape for layer {layer}, seed {seed}: {combined_train_activations.shape}\")\n",
        "\n",
        "        # Get validation activations for the current seed and layer\n",
        "        val_activations_list = []\n",
        "        print(f\"\\nValidation files associated with seed {seed}:\")\n",
        "        for subset in ['two_no_patch', 'zero_no_patch', 'zero_patch']:\n",
        "            if subset in val_activations[layer]:\n",
        "                subset_activations = val_activations[layer][subset][seed_idx - 1]\n",
        "                val_activations_list.append(subset_activations)\n",
        "                print(f\"  - Subset: {subset}, File: val_model{seed_idx}_{subset}.npy\")\n",
        "            else:\n",
        "                print(f\"Warning: No val activations found for subset {subset}, layer {layer}, seed {seed}.\")\n",
        "\n",
        "        if len(val_activations_list) == 0:\n",
        "            print(f\"No val activations found for layer {layer}, seed {seed}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Combine val activations\n",
        "        combined_val_activations = np.vstack(val_activations_list)\n",
        "        print(f\"Combined val activations shape for layer {layer}, seed {seed}: {combined_val_activations.shape}\")\n",
        "\n",
        "        # Set the random seed for reproducibility\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # Define encoding dimension\n",
        "        encoding_dim = 8000\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # Train autoencoder on unnormalized activations\n",
        "        autoencoder = SparseAutoencoder(combined_train_activations.shape[1], encoding_dim).to(device)\n",
        "        print(f\"Training autoencoder for layer {layer} (unnormalized, seed {seed})\")\n",
        "        autoencoder = train_autoencoder(autoencoder, combined_train_activations, combined_val_activations,\n",
        "                                        num_epochs=500, learning_rate=1e-4)\n",
        "\n",
        "        # Save the trained autoencoder\n",
        "        save_path_unnormalized = os.path.join(\n",
        "            save_sae_dir, f'dlp_autoencoder_layer_{layer}_seed_{seed}.pth'\n",
        "        )\n",
        "        torch.save(autoencoder.state_dict(), save_path_unnormalized)\n",
        "        print(f\"Saved unnormalized autoencoder at {save_path_unnormalized}\")\n",
        "\n",
        "        # Clear memory\n",
        "        del autoencoder\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "print(\"\\nAll autoencoders trained and saved successfully.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgT8Ap_JG4FM"
      },
      "source": [
        "### Load the saved SAE and project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBqV-qTGG69r"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained autoencoder for layer 6 (fc2) (from snippet 4)\n",
        "def load_autoencoder(device, save_sae_dir):\n",
        "\n",
        "    input_dims = 4096\n",
        "    encoding_dim = 8000\n",
        "\n",
        "    # Initialize the autoencoder\n",
        "    autoencoder = SparseAutoencoder(input_dims, encoding_dim)\n",
        "    autoencoder.load_state_dict(torch.load(save_sae_dir))  # Load weights\n",
        "    autoencoder = autoencoder.to(device)  # Move model to device\n",
        "\n",
        "    # Freeze all parameters of the autoencoder\n",
        "    for param in autoencoder.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Set the autoencoder to evaluation mode\n",
        "    autoencoder.eval()\n",
        "    print(f\"Autoencoder loaded from {save_sae_dir} and frozen successfully.\")\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_model(saved_weights_path, device):\n",
        "\n",
        "    # Load the PyTorch AlexNet model\n",
        "    print(f\"Loading model from {saved_weights_path}\")\n",
        "    model = models.alexnet(pretrained=False)  # Load AlexNet without pretrained weights\n",
        "    model.classifier[-1] = nn.Linear(4096, 2)  # Update the last layer for binary classification\n",
        "\n",
        "    # Load the saved weights\n",
        "    model.load_state_dict(torch.load(saved_weights_path, map_location=device))\n",
        "    model.to(device)\n",
        "\n",
        "    # Freeze all layers except `classifier[5]` (ReLU) and `classifier[6]` (fc3)\n",
        "    for name, param in model.named_parameters():\n",
        "        if name.startswith(\"classifier.6\"):  # classifier[6] corresponds to fc3\n",
        "            param.requires_grad = True\n",
        "        elif name.startswith(\"classifier.5\"):  # ReLU does not have trainable params\n",
        "            param.requires_grad = True\n",
        "        else:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    print(\"Model loaded and all layers up to fc2 are frozen\")\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45Rf_hs5HQkr"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist\"\n",
        "activation_dir = os.path.join(base_dir, \"activations\")\n",
        "output_base_dir = os.path.join(base_dir, \"outputs\")\n",
        "Path(output_base_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# Define paths for pre-saved activations\n",
        "def get_activation_path(folder_name, filename):\n",
        "    return os.path.join(activation_dir, folder_name, f\"{filename}.npy\")\n",
        "\n",
        "\n",
        "def extract_fc2_activations(model, dataloader):\n",
        "    \"\"\"\n",
        "    Extract activations from the fc2 layer (classifier[4]) of the PyTorch AlexNet.\n",
        "    Args:\n",
        "        model: Pretrained or fine-tuned PyTorch AlexNet model.\n",
        "        dataloader: DataLoader for the test set.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Activations from fc2 for all images in the dataloader.\n",
        "    \"\"\"\n",
        "    print(\"Extracting AlexNet activations for layer fc2...\")\n",
        "    activations = []\n",
        "\n",
        "    # Ensure the model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch_idx, (image_tensor, _) in enumerate(dataloader):  # Expect only 2 elements: (img, is_two)\n",
        "            # Move image tensor to the device (CPU or GPU)\n",
        "            image_tensor = image_tensor.to(device)\n",
        "\n",
        "            # Pass through the feature extractor\n",
        "            features = model.features(image_tensor)\n",
        "            features = model.avgpool(features)  # Apply average pooling\n",
        "            features = torch.flatten(features, 1)  # Flatten for classifier input\n",
        "\n",
        "            # Pass through classifier layers up to fc2\n",
        "            for idx, layer in enumerate(model.classifier):\n",
        "                features = layer(features)\n",
        "                if idx == 4:  # Stop after fc2 (classifier[4])\n",
        "                    activations.append(features.cpu().numpy())\n",
        "                    break\n",
        "\n",
        "            # Log progress\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"Processed {batch_idx + 1}/{len(dataloader)} batches\")\n",
        "\n",
        "            # Clear resources\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    # Stack activations into a single array\n",
        "    return np.vstack(activations)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_or_extract_fc2_activations(model, dataloader, folder_name, filename):\n",
        "    # Generate activation file path\n",
        "    activation_path = get_activation_path(folder_name, filename)\n",
        "\n",
        "    # Check if the activation file exists\n",
        "    if os.path.exists(activation_path):\n",
        "        print(f\"Loading pre-saved AlexNet activations for {filename} from {activation_path}...\")\n",
        "        activations = np.load(activation_path, allow_pickle=True)\n",
        "    else:\n",
        "        print(f\"No pre-saved AlexNet activations found for {filename}. Extracting and saving...\")\n",
        "        activations = extract_fc2_activations(model, dataloader)  # Extract activations\n",
        "        os.makedirs(os.path.dirname(activation_path), exist_ok=True)  # Ensure directory exists\n",
        "        np.save(activation_path, activations)  # Save activations\n",
        "        print(f\"Activations for layer fc2 saved to {activation_path}\")\n",
        "\n",
        "    return activations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5MdH9w478Ag"
      },
      "source": [
        "till here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5JSPwt4xu60"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gas8yiO8jsEC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def main():\n",
        "    # Paths and initialization\n",
        "    model_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_1.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_11.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_111.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_1111.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_11111.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_111111.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_1111111.pt\"\n",
        "\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Define dataset paths\n",
        "    dataset_paths = {\n",
        "        \"test_two_dlp_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/test/class_2_100',\n",
        "        \"test_two_org_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_2_100',\n",
        "        \"test_zero_dlp_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/test/class_0_100',\n",
        "        \"test_zero_org_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/test/class_0_100',\n",
        "        \"val_zero_org_200\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_200',\n",
        "        \"val_zero_org_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_100',\n",
        "        \"val_zero_org_50\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_50',\n",
        "        \"val_zero_org_25\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val/class_0_25',\n",
        "        \"val_zero_dlp_200\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/val/class_0_200',\n",
        "        \"val_zero_dlp_100\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/val/class_0_100',\n",
        "        \"val_zero_dlp_50\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/val/class_0_50',\n",
        "        \"val_zero_dlp_25\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/dynamic_patches_left/val/class_0_25',\n",
        "\n",
        "\n",
        "        #\"val_zero_fg\": '/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/foreground/val/class_0'\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    for key, folder in dataset_paths.items():\n",
        "        if not os.path.exists(folder):\n",
        "            print(f\"Path does not exist: {folder}\")\n",
        "        else:\n",
        "            files = [\n",
        "                os.path.join(root, file)\n",
        "                for root, dirs, files in os.walk(folder)\n",
        "                for file in files if file.endswith(('.jpg', '.png'))\n",
        "            ]\n",
        "            if not files:\n",
        "                print(f\"No valid image files found in: {folder}\")\n",
        "            else:\n",
        "                print(f\"Found {len(files)} files in {folder}\")\n",
        "\n",
        "\n",
        "    base_path = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/dataset_splits/original/val\"\n",
        "    print(\"Contents of the directory:\")\n",
        "    for item in os.listdir(base_path):\n",
        "        print(item)\n",
        "\n",
        "\n",
        "\n",
        "    # Prepare dataloaders\n",
        "    dataloaders = {}\n",
        "    for key, folder in dataset_paths.items():\n",
        "        image_paths = [\n",
        "            os.path.join(root, file)\n",
        "            for root, dirs, files in os.walk(folder)\n",
        "            for file in files if file.endswith(('.jpg', '.png'))\n",
        "        ]\n",
        "        # Use is_two = 1 if \"two\" is in the key, else 0\n",
        "        dataset = MnistDataset(data_files=image_paths, is_two=1 if \"two\" in key else 0)\n",
        "        dataloaders[key] = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Directory for saving results\n",
        "    sparse_output_dir = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch\"\n",
        "    os.makedirs(sparse_output_dir, exist_ok=True)\n",
        "\n",
        "    # Loop over models\n",
        "    for model_path in model_paths:\n",
        "        print(f\"Processing model: {model_path}\")\n",
        "\n",
        "        # Load the model\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "\n",
        "        # Process each dataset\n",
        "        for key, loader in dataloaders.items():\n",
        "            print(f\"Processing dataset: {key}\")\n",
        "\n",
        "            # Extract activations\n",
        "            activations = load_or_extract_fc2_activations(\n",
        "                model, loader, f'{key}_{Path(model_path).stem}', f'dlp_fc2_activations_{key}_{Path(model_path).stem}'\n",
        "            )\n",
        "\n",
        "            # Save activations\n",
        "            activation_path = os.path.join(sparse_output_dir, f\"fc2_activations_{key}_{Path(model_path).stem}.npy\")\n",
        "            np.save(activation_path, activations)\n",
        "            print(f\"Activations for {key} saved to: {activation_path}\")\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFpVCEMm1lv4"
      },
      "source": [
        "### 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tuf5LkXUEC5o"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"neurons_by_correlation_200.csv\"):\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Number of neurons should be 16k\n",
        "    num_neurons = val_patch_activations.shape[1]\n",
        "    print(f\"Number of val patch neurons: {num_neurons}\")\n",
        "    num_images = val_patch_activations.shape[0]\n",
        "    print(f\"Number of val patch images: {val_patch_activations.shape[0]}\")\n",
        "\n",
        "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
        "    pp = np.concatenate([np.ones(val_patch_activations.shape[0]), np.zeros(val_no_patch_activations.shape[0])])\n",
        "    print(f\"Number of pp labels: {len(pp)}\")\n",
        "\n",
        "    # array to store correlations\n",
        "    correlations = np.zeros(num_neurons)\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        # Combine activations for neuron i from both datassets p and np\n",
        "        act_i = np.concatenate([val_patch_activations[:, i], val_no_patch_activations[:, i]])\n",
        "\n",
        "        # Compute correlation between pp and act_i\n",
        "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
        "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
        "        else:\n",
        "            corr = 0  # Handle constant vectors\n",
        "\n",
        "        correlations[i] = corr\n",
        "\n",
        "    # As previous code\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "    print('shape of correlations', correlations.shape)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(num_neurons),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by correlation in descending order\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "def plot_correlation_histogram(original, projected, title):\n",
        "    correlations = [\n",
        "        np.corrcoef(original[:, i], projected[:, i])[0, 1]\n",
        "        if np.std(original[:, i]) > 0 and np.std(projected[:, i]) > 0\n",
        "        else 0  # Handle constant features\n",
        "        for i in range(original.shape[1])\n",
        "    ]\n",
        "    correlations = np.nan_to_num(correlations)  # Replace NaNs with 0\n",
        "    plt.hist(correlations, bins=50, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Correlation\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences_200.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "\n",
        "\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"dlp_top_neurons_200.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111, 1111, 11111, 111111, 1111111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/dynamic_left_patch/dlp_autoencoder_layer_fc2_seed_{seed}.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_two_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_two_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_zero_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_zero_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_val_zero_dlp_200_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_val_zero_org_200_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/dynamic_left_patch\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Prepare a DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Seed\", \"Percentage\",\n",
        "        \"Val_Patch_Before\", \"Val_NoPatch_Before\",\n",
        "        \"Val_Patch_After\", \"Val_NoPatch_After\",\n",
        "        \"Test_Two_Patch_Before\", \"Test_Two_NoPatch_Before\",\n",
        "        \"Test_Two_Patch_After\", \"Test_Two_NoPatch_After\",\n",
        "        \"Test_Zero_Patch_Before\", \"Test_Zero_NoPatch_Before\",\n",
        "        \"Test_Zero_Patch_After\", \"Test_Zero_NoPatch_After\",\n",
        "        \"Worst_Acc_Before\", \"Worst_Acc_After\",\n",
        "        \"Avg_Acc_Before\", \"Avg_Acc_After\"\n",
        "    ])\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "\n",
        "        # Load paths\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        test_two_patch = np.load(test_two_patch_path, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_two_no_patch_path, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_zero_patch_path, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_zero_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Classify \"before muting\"\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Project activations\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "        # Loop through percentages\n",
        "        for percentage in range(0, 51):  # 1% to 15%\n",
        "            print(f\"Testing with {percentage}% muting...\")\n",
        "\n",
        "            # Calculate differences and load top neurons\n",
        "            #abs_diff = np.abs(np.mean(projected_val_patch, axis=0) - np.mean(projected_val_no_patch, axis=0))\n",
        "            #csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\")\n",
        "            #top_neurons = load_top_neurons_from_csv(folder_name, f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\", percentage)\n",
        "\n",
        "            # **Correlation-Based Neurons**\n",
        "            correlation_csv_path = save_neurons_by_correlation(\n",
        "                projected_val_patch, projected_val_no_patch, folder_name, filename=f\"neurons_by_correlation_seed_{seed}_200.csv\"\n",
        "            )\n",
        "            top_neurons_corr = load_top_neurons_from_csv(folder_name, f\"neurons_by_correlation_seed_{seed}_200.csv\", percentage)\n",
        "\n",
        "            top_neurons = top_neurons_corr\n",
        "            # Muting neurons\n",
        "            projected_val_patch_muted = projected_val_patch.copy()\n",
        "            projected_val_no_patch_muted = projected_val_no_patch.copy()\n",
        "            projected_two_test_patch_muted = projected_two_test_patch.copy()\n",
        "            projected_two_test_no_patch_muted = projected_two_test_no_patch.copy()\n",
        "            projected_zero_test_patch_muted = projected_zero_test_patch.copy()\n",
        "            projected_zero_test_no_patch_muted = projected_zero_test_no_patch.copy()\n",
        "\n",
        "            projected_val_patch_muted[:, top_neurons] = 0\n",
        "            projected_val_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_no_patch_muted[:, top_neurons] = 0\n",
        "\n",
        "            # Decode and classify\n",
        "            decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "\n",
        "            predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "            predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "            predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "            predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "            predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "            predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "            accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "            accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "            accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "            accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "            accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0] * len(predictions_test_zero_patch_after))\n",
        "            accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "            # Calculate worst and average group accuracies\n",
        "            worst_acc_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "            worst_acc_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "            avg_acc_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before +\n",
        "                              accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "            avg_acc_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after +\n",
        "                             accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "            # Append results to DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                \"Seed\": seed,\n",
        "                \"Percentage\": percentage,\n",
        "                \"Val_Patch_Before\": accuracy_val_patch_before,\n",
        "                \"Val_NoPatch_Before\": accuracy_val_no_patch_before,\n",
        "                \"Val_Patch_After\": accuracy_val_patch_after,\n",
        "                \"Val_NoPatch_After\": accuracy_val_no_patch_after,\n",
        "                \"Test_Two_Patch_Before\": accuracy_test_two_patch_before,\n",
        "                \"Test_Two_NoPatch_Before\": accuracy_test_two_no_patch_before,\n",
        "                \"Test_Two_Patch_After\": accuracy_test_two_patch_after,\n",
        "                \"Test_Two_NoPatch_After\": accuracy_test_two_no_patch_after,\n",
        "                \"Test_Zero_Patch_Before\": accuracy_test_zero_patch_before,\n",
        "                \"Test_Zero_NoPatch_Before\": accuracy_test_zero_no_patch_before,\n",
        "                \"Test_Zero_Patch_After\": accuracy_test_zero_patch_after,\n",
        "                \"Test_Zero_NoPatch_After\": accuracy_test_zero_no_patch_after,\n",
        "                \"Worst_Acc_Before\": worst_acc_before,\n",
        "                \"Worst_Acc_After\": worst_acc_after,\n",
        "                \"Avg_Acc_Before\": avg_acc_before,\n",
        "                \"Avg_Acc_After\": avg_acc_after\n",
        "            }])\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_csv_path = os.path.join(folder_name, \"dynamic_left_patch_200.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYS5GUKX1jOw"
      },
      "source": [
        "### 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwN-2abAp4JG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"neurons_by_correlation_100.csv\"):\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Number of neurons should be 16k\n",
        "    num_neurons = val_patch_activations.shape[1]\n",
        "    print(f\"Number of val patch neurons: {num_neurons}\")\n",
        "    num_images = val_patch_activations.shape[0]\n",
        "    print(f\"Number of val patch images: {val_patch_activations.shape[0]}\")\n",
        "\n",
        "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
        "    pp = np.concatenate([np.ones(val_patch_activations.shape[0]), np.zeros(val_no_patch_activations.shape[0])])\n",
        "    print(f\"Number of pp labels: {len(pp)}\")\n",
        "\n",
        "    # array to store correlations\n",
        "    correlations = np.zeros(num_neurons)\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        # Combine activations for neuron i from both datassets p and np\n",
        "        act_i = np.concatenate([val_patch_activations[:, i], val_no_patch_activations[:, i]])\n",
        "\n",
        "        # Compute correlation between pp and act_i\n",
        "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
        "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
        "        else:\n",
        "            corr = 0  # Handle constant vectors\n",
        "\n",
        "        correlations[i] = corr\n",
        "\n",
        "    # As previous code\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "    print('shape of correlations', correlations.shape)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(num_neurons),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by correlation in descending order\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "def plot_correlation_histogram(original, projected, title):\n",
        "    correlations = [\n",
        "        np.corrcoef(original[:, i], projected[:, i])[0, 1]\n",
        "        if np.std(original[:, i]) > 0 and np.std(projected[:, i]) > 0\n",
        "        else 0  # Handle constant features\n",
        "        for i in range(original.shape[1])\n",
        "    ]\n",
        "    correlations = np.nan_to_num(correlations)  # Replace NaNs with 0\n",
        "    plt.hist(correlations, bins=50, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Correlation\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences_100.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "\n",
        "\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"dlp_top_neurons_100.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111, 1111, 11111, 111111, 1111111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/dynamic_left_patch/dlp_autoencoder_layer_fc2_seed_{seed}.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_two_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_two_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_zero_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_zero_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_val_zero_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_val_zero_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/dynamic_left_patch\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Prepare a DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Seed\", \"Percentage\",\n",
        "        \"Val_Patch_Before\", \"Val_NoPatch_Before\",\n",
        "        \"Val_Patch_After\", \"Val_NoPatch_After\",\n",
        "        \"Test_Two_Patch_Before\", \"Test_Two_NoPatch_Before\",\n",
        "        \"Test_Two_Patch_After\", \"Test_Two_NoPatch_After\",\n",
        "        \"Test_Zero_Patch_Before\", \"Test_Zero_NoPatch_Before\",\n",
        "        \"Test_Zero_Patch_After\", \"Test_Zero_NoPatch_After\",\n",
        "        \"Worst_Acc_Before\", \"Worst_Acc_After\",\n",
        "        \"Avg_Acc_Before\", \"Avg_Acc_After\"\n",
        "    ])\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "\n",
        "        # Load paths\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        test_two_patch = np.load(test_two_patch_path, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_two_no_patch_path, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_zero_patch_path, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_zero_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Classify \"before muting\"\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Project activations\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "        # Loop through percentages\n",
        "        for percentage in range(0, 51):  # 1% to 15%\n",
        "            print(f\"Testing with {percentage}% muting...\")\n",
        "\n",
        "            # Calculate differences and load top neurons\n",
        "            #abs_diff = np.abs(np.mean(projected_val_patch, axis=0) - np.mean(projected_val_no_patch, axis=0))\n",
        "            #csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\")\n",
        "            #top_neurons = load_top_neurons_from_csv(folder_name, f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\", percentage)\n",
        "\n",
        "            # **Correlation-Based Neurons**\n",
        "            correlation_csv_path = save_neurons_by_correlation(\n",
        "                projected_val_patch, projected_val_no_patch, folder_name, filename=f\"neurons_by_correlation_seed_{seed}_200.csv\"\n",
        "            )\n",
        "            top_neurons_corr = load_top_neurons_from_csv(folder_name, f\"neurons_by_correlation_seed_{seed}_200.csv\", percentage)\n",
        "\n",
        "            top_neurons = top_neurons_corr\n",
        "            # Muting neurons\n",
        "            projected_val_patch_muted = projected_val_patch.copy()\n",
        "            projected_val_no_patch_muted = projected_val_no_patch.copy()\n",
        "            projected_two_test_patch_muted = projected_two_test_patch.copy()\n",
        "            projected_two_test_no_patch_muted = projected_two_test_no_patch.copy()\n",
        "            projected_zero_test_patch_muted = projected_zero_test_patch.copy()\n",
        "            projected_zero_test_no_patch_muted = projected_zero_test_no_patch.copy()\n",
        "\n",
        "            projected_val_patch_muted[:, top_neurons] = 0\n",
        "            projected_val_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_no_patch_muted[:, top_neurons] = 0\n",
        "\n",
        "            # Decode and classify\n",
        "            decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "\n",
        "            predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "            predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "            predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "            predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "            predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "            predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "            accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "            accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "            accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "            accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "            accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0] * len(predictions_test_zero_patch_after))\n",
        "            accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "            # Calculate worst and average group accuracies\n",
        "            worst_acc_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "            worst_acc_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "            avg_acc_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before +\n",
        "                              accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "            avg_acc_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after +\n",
        "                             accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "            # Append results to DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                \"Seed\": seed,\n",
        "                \"Percentage\": percentage,\n",
        "                \"Val_Patch_Before\": accuracy_val_patch_before,\n",
        "                \"Val_NoPatch_Before\": accuracy_val_no_patch_before,\n",
        "                \"Val_Patch_After\": accuracy_val_patch_after,\n",
        "                \"Val_NoPatch_After\": accuracy_val_no_patch_after,\n",
        "                \"Test_Two_Patch_Before\": accuracy_test_two_patch_before,\n",
        "                \"Test_Two_NoPatch_Before\": accuracy_test_two_no_patch_before,\n",
        "                \"Test_Two_Patch_After\": accuracy_test_two_patch_after,\n",
        "                \"Test_Two_NoPatch_After\": accuracy_test_two_no_patch_after,\n",
        "                \"Test_Zero_Patch_Before\": accuracy_test_zero_patch_before,\n",
        "                \"Test_Zero_NoPatch_Before\": accuracy_test_zero_no_patch_before,\n",
        "                \"Test_Zero_Patch_After\": accuracy_test_zero_patch_after,\n",
        "                \"Test_Zero_NoPatch_After\": accuracy_test_zero_no_patch_after,\n",
        "                \"Worst_Acc_Before\": worst_acc_before,\n",
        "                \"Worst_Acc_After\": worst_acc_after,\n",
        "                \"Avg_Acc_Before\": avg_acc_before,\n",
        "                \"Avg_Acc_After\": avg_acc_after\n",
        "            }])\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_csv_path = os.path.join(folder_name, \"dynamic_left_patch_100.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8MZrrcW1gd4"
      },
      "source": [
        "###50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtghdKLlqFAG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"neurons_by_correlation_50.csv\"):\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Number of neurons should be 16k\n",
        "    num_neurons = val_patch_activations.shape[1]\n",
        "    print(f\"Number of val patch neurons: {num_neurons}\")\n",
        "    num_images = val_patch_activations.shape[0]\n",
        "    print(f\"Number of val patch images: {val_patch_activations.shape[0]}\")\n",
        "\n",
        "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
        "    pp = np.concatenate([np.ones(val_patch_activations.shape[0]), np.zeros(val_no_patch_activations.shape[0])])\n",
        "    print(f\"Number of pp labels: {len(pp)}\")\n",
        "\n",
        "    # array to store correlations\n",
        "    correlations = np.zeros(num_neurons)\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        # Combine activations for neuron i from both datassets p and np\n",
        "        act_i = np.concatenate([val_patch_activations[:, i], val_no_patch_activations[:, i]])\n",
        "\n",
        "        # Compute correlation between pp and act_i\n",
        "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
        "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
        "        else:\n",
        "            corr = 0  # Handle constant vectors\n",
        "\n",
        "        correlations[i] = corr\n",
        "\n",
        "    # As previous code\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "    print('shape of correlations', correlations.shape)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(num_neurons),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by correlation in descending order\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "def plot_correlation_histogram(original, projected, title):\n",
        "    correlations = [\n",
        "        np.corrcoef(original[:, i], projected[:, i])[0, 1]\n",
        "        if np.std(original[:, i]) > 0 and np.std(projected[:, i]) > 0\n",
        "        else 0  # Handle constant features\n",
        "        for i in range(original.shape[1])\n",
        "    ]\n",
        "    correlations = np.nan_to_num(correlations)  # Replace NaNs with 0\n",
        "    plt.hist(correlations, bins=50, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Correlation\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences_50.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "\n",
        "\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"dlp_top_neurons_50.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111, 1111, 11111, 111111, 1111111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/dynamic_left_patch/dlp_autoencoder_layer_fc2_seed_{seed}.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_two_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_two_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_zero_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_zero_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_val_zero_dlp_50_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_val_zero_org_50_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/dynamic_left_patch\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Prepare a DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Seed\", \"Percentage\",\n",
        "        \"Val_Patch_Before\", \"Val_NoPatch_Before\",\n",
        "        \"Val_Patch_After\", \"Val_NoPatch_After\",\n",
        "        \"Test_Two_Patch_Before\", \"Test_Two_NoPatch_Before\",\n",
        "        \"Test_Two_Patch_After\", \"Test_Two_NoPatch_After\",\n",
        "        \"Test_Zero_Patch_Before\", \"Test_Zero_NoPatch_Before\",\n",
        "        \"Test_Zero_Patch_After\", \"Test_Zero_NoPatch_After\",\n",
        "        \"Worst_Acc_Before\", \"Worst_Acc_After\",\n",
        "        \"Avg_Acc_Before\", \"Avg_Acc_After\"\n",
        "    ])\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "\n",
        "        # Load paths\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        test_two_patch = np.load(test_two_patch_path, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_two_no_patch_path, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_zero_patch_path, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_zero_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Classify \"before muting\"\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Project activations\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "        # Loop through percentages\n",
        "        for percentage in range(0, 51):  # 1% to 15%\n",
        "            print(f\"Testing with {percentage}% muting...\")\n",
        "\n",
        "            # Calculate differences and load top neurons\n",
        "            #abs_diff = np.abs(np.mean(projected_val_patch, axis=0) - np.mean(projected_val_no_patch, axis=0))\n",
        "            #csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\")\n",
        "            #top_neurons = load_top_neurons_from_csv(folder_name, f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\", percentage)\n",
        "\n",
        "            # **Correlation-Based Neurons**\n",
        "            correlation_csv_path = save_neurons_by_correlation(\n",
        "                projected_val_patch, projected_val_no_patch, folder_name, filename=f\"neurons_by_correlation_seed_{seed}_50.csv\"\n",
        "            )\n",
        "            top_neurons_corr = load_top_neurons_from_csv(folder_name, f\"neurons_by_correlation_seed_{seed}_50.csv\", percentage)\n",
        "\n",
        "            top_neurons = top_neurons_corr\n",
        "            # Muting neurons\n",
        "            projected_val_patch_muted = projected_val_patch.copy()\n",
        "            projected_val_no_patch_muted = projected_val_no_patch.copy()\n",
        "            projected_two_test_patch_muted = projected_two_test_patch.copy()\n",
        "            projected_two_test_no_patch_muted = projected_two_test_no_patch.copy()\n",
        "            projected_zero_test_patch_muted = projected_zero_test_patch.copy()\n",
        "            projected_zero_test_no_patch_muted = projected_zero_test_no_patch.copy()\n",
        "\n",
        "            projected_val_patch_muted[:, top_neurons] = 0\n",
        "            projected_val_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_no_patch_muted[:, top_neurons] = 0\n",
        "\n",
        "            # Decode and classify\n",
        "            decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "\n",
        "            predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "            predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "            predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "            predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "            predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "            predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "            accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "            accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "            accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "            accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "            accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0] * len(predictions_test_zero_patch_after))\n",
        "            accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "            # Calculate worst and average group accuracies\n",
        "            worst_acc_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "            worst_acc_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "            avg_acc_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before +\n",
        "                              accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "            avg_acc_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after +\n",
        "                             accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "            # Append results to DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                \"Seed\": seed,\n",
        "                \"Percentage\": percentage,\n",
        "                \"Val_Patch_Before\": accuracy_val_patch_before,\n",
        "                \"Val_NoPatch_Before\": accuracy_val_no_patch_before,\n",
        "                \"Val_Patch_After\": accuracy_val_patch_after,\n",
        "                \"Val_NoPatch_After\": accuracy_val_no_patch_after,\n",
        "                \"Test_Two_Patch_Before\": accuracy_test_two_patch_before,\n",
        "                \"Test_Two_NoPatch_Before\": accuracy_test_two_no_patch_before,\n",
        "                \"Test_Two_Patch_After\": accuracy_test_two_patch_after,\n",
        "                \"Test_Two_NoPatch_After\": accuracy_test_two_no_patch_after,\n",
        "                \"Test_Zero_Patch_Before\": accuracy_test_zero_patch_before,\n",
        "                \"Test_Zero_NoPatch_Before\": accuracy_test_zero_no_patch_before,\n",
        "                \"Test_Zero_Patch_After\": accuracy_test_zero_patch_after,\n",
        "                \"Test_Zero_NoPatch_After\": accuracy_test_zero_no_patch_after,\n",
        "                \"Worst_Acc_Before\": worst_acc_before,\n",
        "                \"Worst_Acc_After\": worst_acc_after,\n",
        "                \"Avg_Acc_Before\": avg_acc_before,\n",
        "                \"Avg_Acc_After\": avg_acc_after\n",
        "            }])\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_csv_path = os.path.join(folder_name, \"dynamic_left_patch_50.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq4FaVhx1cFi"
      },
      "source": [
        "### 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gX-UhZRLqUYF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def save_neurons_by_correlation(val_patch_activations, val_no_patch_activations, folder_name, filename=\"neurons_by_correlation_25.csv\"):\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Number of neurons should be 16k\n",
        "    num_neurons = val_patch_activations.shape[1]\n",
        "    print(f\"Number of val patch neurons: {num_neurons}\")\n",
        "    num_images = val_patch_activations.shape[0]\n",
        "    print(f\"Number of val patch images: {val_patch_activations.shape[0]}\")\n",
        "\n",
        "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
        "    pp = np.concatenate([np.ones(val_patch_activations.shape[0]), np.zeros(val_no_patch_activations.shape[0])])\n",
        "    print(f\"Number of pp labels: {len(pp)}\")\n",
        "\n",
        "    # array to store correlations\n",
        "    correlations = np.zeros(num_neurons)\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        # Combine activations for neuron i from both datassets p and np\n",
        "        act_i = np.concatenate([val_patch_activations[:, i], val_no_patch_activations[:, i]])\n",
        "\n",
        "        # Compute correlation between pp and act_i\n",
        "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
        "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
        "        else:\n",
        "            corr = 0  # Handle constant vectors\n",
        "\n",
        "        correlations[i] = corr\n",
        "\n",
        "    # As previous code\n",
        "    # Handle NaN correlations (replace NaN with 0)\n",
        "    correlations = np.nan_to_num(correlations)\n",
        "    print('shape of correlations', correlations.shape)\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their correlations\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(num_neurons),\n",
        "        \"Correlation\": correlations\n",
        "    })\n",
        "\n",
        "    # Sort by correlation in descending order\n",
        "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"Neuron correlations saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "def plot_correlation_histogram(original, projected, title):\n",
        "    correlations = [\n",
        "        np.corrcoef(original[:, i], projected[:, i])[0, 1]\n",
        "        if np.std(original[:, i]) > 0 and np.std(projected[:, i]) > 0\n",
        "        else 0  # Handle constant features\n",
        "        for i in range(original.shape[1])\n",
        "    ]\n",
        "    correlations = np.nan_to_num(correlations)  # Replace NaNs with 0\n",
        "    plt.hist(correlations, bins=50, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Correlation\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences_25.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "\n",
        "\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"dlp_top_neurons_25.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111, 1111, 11111, 111111, 1111111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/dynamic_left_patch/dlp_autoencoder_layer_fc2_seed_{seed}.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_two_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_two_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_zero_dlp_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_test_zero_org_100_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_val_zero_dlp_25_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/dynamic_left_patch/fc2_activations_val_zero_org_25_alexnet_mnist_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/dynamic_left_patch\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # Prepare a DataFrame to store results\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Seed\", \"Percentage\",\n",
        "        \"Val_Patch_Before\", \"Val_NoPatch_Before\",\n",
        "        \"Val_Patch_After\", \"Val_NoPatch_After\",\n",
        "        \"Test_Two_Patch_Before\", \"Test_Two_NoPatch_Before\",\n",
        "        \"Test_Two_Patch_After\", \"Test_Two_NoPatch_After\",\n",
        "        \"Test_Zero_Patch_Before\", \"Test_Zero_NoPatch_Before\",\n",
        "        \"Test_Zero_Patch_After\", \"Test_Zero_NoPatch_After\",\n",
        "        \"Worst_Acc_Before\", \"Worst_Acc_After\",\n",
        "        \"Avg_Acc_Before\", \"Avg_Acc_After\"\n",
        "    ])\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "\n",
        "        # Load paths\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        test_two_patch = np.load(test_two_patch_path, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_two_no_patch_path, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_zero_patch_path, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_zero_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Classify \"before muting\"\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Project activations\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "        # Loop through percentages\n",
        "        for percentage in range(0, 51):  # 1% to 15%\n",
        "            print(f\"Testing with {percentage}% muting...\")\n",
        "\n",
        "            # Calculate differences and load top neurons\n",
        "            #abs_diff = np.abs(np.mean(projected_val_patch, axis=0) - np.mean(projected_val_no_patch, axis=0))\n",
        "            #csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\")\n",
        "            #top_neurons = load_top_neurons_from_csv(folder_name, f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\", percentage)\n",
        "\n",
        "            # **Correlation-Based Neurons**\n",
        "            correlation_csv_path = save_neurons_by_correlation(\n",
        "                projected_val_patch, projected_val_no_patch, folder_name, filename=f\"neurons_by_correlation_seed_{seed}_25.csv\"\n",
        "            )\n",
        "            top_neurons_corr = load_top_neurons_from_csv(folder_name, f\"neurons_by_correlation_seed_{seed}_25.csv\", percentage)\n",
        "\n",
        "            top_neurons = top_neurons_corr\n",
        "            # Muting neurons\n",
        "            projected_val_patch_muted = projected_val_patch.copy()\n",
        "            projected_val_no_patch_muted = projected_val_no_patch.copy()\n",
        "            projected_two_test_patch_muted = projected_two_test_patch.copy()\n",
        "            projected_two_test_no_patch_muted = projected_two_test_no_patch.copy()\n",
        "            projected_zero_test_patch_muted = projected_zero_test_patch.copy()\n",
        "            projected_zero_test_no_patch_muted = projected_zero_test_no_patch.copy()\n",
        "\n",
        "            projected_val_patch_muted[:, top_neurons] = 0\n",
        "            projected_val_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_two_test_no_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_patch_muted[:, top_neurons] = 0\n",
        "            projected_zero_test_no_patch_muted[:, top_neurons] = 0\n",
        "\n",
        "            # Decode and classify\n",
        "            decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch_muted).to(device).float()).cpu().numpy()\n",
        "            decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch_muted).to(device).float()).cpu().numpy()\n",
        "\n",
        "            predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "            predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "            predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "            predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "            predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "            predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "            accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "            accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "            accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "            accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "            accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0] * len(predictions_test_zero_patch_after))\n",
        "            accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "            # Calculate worst and average group accuracies\n",
        "            worst_acc_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "            worst_acc_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "            avg_acc_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before +\n",
        "                              accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "            avg_acc_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after +\n",
        "                             accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "            # Append results to DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                \"Seed\": seed,\n",
        "                \"Percentage\": percentage,\n",
        "                \"Val_Patch_Before\": accuracy_val_patch_before,\n",
        "                \"Val_NoPatch_Before\": accuracy_val_no_patch_before,\n",
        "                \"Val_Patch_After\": accuracy_val_patch_after,\n",
        "                \"Val_NoPatch_After\": accuracy_val_no_patch_after,\n",
        "                \"Test_Two_Patch_Before\": accuracy_test_two_patch_before,\n",
        "                \"Test_Two_NoPatch_Before\": accuracy_test_two_no_patch_before,\n",
        "                \"Test_Two_Patch_After\": accuracy_test_two_patch_after,\n",
        "                \"Test_Two_NoPatch_After\": accuracy_test_two_no_patch_after,\n",
        "                \"Test_Zero_Patch_Before\": accuracy_test_zero_patch_before,\n",
        "                \"Test_Zero_NoPatch_Before\": accuracy_test_zero_no_patch_before,\n",
        "                \"Test_Zero_Patch_After\": accuracy_test_zero_patch_after,\n",
        "                \"Test_Zero_NoPatch_After\": accuracy_test_zero_no_patch_after,\n",
        "                \"Worst_Acc_Before\": worst_acc_before,\n",
        "                \"Worst_Acc_After\": worst_acc_after,\n",
        "                \"Avg_Acc_Before\": avg_acc_before,\n",
        "                \"Avg_Acc_After\": avg_acc_after\n",
        "            }])\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "    results_csv_path = os.path.join(folder_name, \"dynamic_left_patch_25.csv\")\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7f8awralIv1"
      },
      "outputs": [],
      "source": [
        "stophere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTQFMi9IDTOm"
      },
      "source": [
        "## Archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4LZJWG6sBjy"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"dlp_top_neurons.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV\n",
        "def load_top_neurons_from_csv(folder_name, filename):\n",
        "    \"\"\"\n",
        "    Load top neurons from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "    top_neurons = neuron_data[\"Neuron_Index\"].values\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111]\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_finetune_dlp_seed_1.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_finetune_dlp_seed_11.pt\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_finetune_dlp_seed_111.pt\"\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        '/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/wb_autoencoder_layer_17_seed_1_unnormalized.pth',\n",
        "        '/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/wb_autoencoder_layer_17_seed_11_unnormalized.pth',\n",
        "        '/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/wb_autoencoder_layer_17_seed_111_unnormalized.pth'\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_two_dlp_alexnet_mnist_finetune_dlp_seed_1.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_two_dlp_alexnet_mnist_finetune_dlp_seed_11.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_two_dlp_alexnet_mnist_finetune_dlp_seed_111.npy\"\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_two_org_alexnet_mnist_finetune_dlp_seed_1.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_two_org_alexnet_mnist_finetune_dlp_seed_11.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_two_org_alexnet_mnist_finetune_dlp_seed_111.npy\"\n",
        "    ]\n",
        "\n",
        "    test_activation_zero_patch_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_zero_dlp_alexnet_mnist_finetune_dlp_seed_1.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_zero_dlp_alexnet_mnist_finetune_dlp_seed_11.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_zero_dlp_alexnet_mnist_finetune_dlp_seed_111.npy\"\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_zero_org_alexnet_mnist_finetune_dlp_seed_1.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_zero_org_alexnet_mnist_finetune_dlp_seed_11.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_test_zero_org_alexnet_mnist_finetune_dlp_seed_111.npy\"\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_val_two_dlp_alexnet_mnist_finetune_dlp_seed_1.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_val_two_dlp_alexnet_mnist_finetune_dlp_seed_11.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_val_two_dlp_alexnet_mnist_finetune_dlp_seed_111.npy\"\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_val_two_org_alexnet_mnist_finetune_dlp_seed_1.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_val_two_org_alexnet_mnist_finetune_dlp_seed_11.npy\",\n",
        "        \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/fc2_activations_val_two_org_alexnet_mnist_finetune_dlp_seed_111.npy\"\n",
        "    ]\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed, (model_path, sae_path, val_patch_path, val_no_patch_path, test_patch_path, test_no_patch_path) in enumerate(\n",
        "            zip(model_paths, autoencoder_paths, val_activation_patch_paths, val_activation_no_patch_paths,\n",
        "                test_activation_patch_paths, test_activation_no_patch_paths), start=1):\n",
        "\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "        print(f\"Model Path: {model_path}\")\n",
        "        print(f\"Autoencoder Path: {sae_path}\")\n",
        "        print(f\"Activation Patch Path: {val_patch_path}\")\n",
        "        print(f\"Activation No Patch Path: {val_no_patch_path}\")\n",
        "        print(f\"Test Activation Patch Path: {test_patch_path}\")\n",
        "        print(f\"Test Activation No Patch Path: {test_no_patch_path}\")\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Direct classification using AlexNet\n",
        "        predictions_val_patch_alexnet = classify_with_alexnet(model, val_activations_patch)\n",
        "        accuracy_val_patch_alexnet = accuracy_score([1] * len(predictions_val_patch_alexnet), predictions_val_patch_alexnet)\n",
        "\n",
        "        predictions_val_no_patch_alexnet = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_no_patch_alexnet = accuracy_score([1] * len(predictions_val_no_patch_alexnet), predictions_val_no_patch_alexnet)\n",
        "\n",
        "        # Classification before muting\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "\n",
        "        # Calculate validation accuracies before muting\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [1] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [1] * len(predictions_val_no_patch_before))\n",
        "\n",
        "\n",
        "\n",
        "        # Project validation activations into sparse space\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "\n",
        "        # Calculate differences and save neuron indexes\n",
        "        avg_val_patch = np.mean(projected_val_patch, axis=0)\n",
        "        avg_val_no_patch = np.mean(projected_val_no_patch, axis=0)\n",
        "        abs_diff = np.abs(avg_val_patch - avg_val_no_patch)\n",
        "        save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"val_neuron_differences_seed_{seed}.csv\")\n",
        "\n",
        "\n",
        "        top_neurons = load_top_neurons_from_csv(folder_name, f\"val_neuron_differences_seed_{seed}.csv\")\n",
        "        neurons_to_mute = top_neurons[:int(len(top_neurons) * 0.1)]\n",
        "        projected_val_patch[:, neurons_to_mute] = 0\n",
        "        projected_val_no_patch[:, neurons_to_mute] = 0\n",
        "\n",
        "        decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch).to(device).float()).cpu().numpy()\n",
        "        decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch).to(device).float()).cpu().numpy()\n",
        "\n",
        "        predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "        predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "\n",
        "        accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [1] * len(predictions_val_patch_after))\n",
        "        accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [1] * len(predictions_val_no_patch_after))\n",
        "\n",
        "        # Print Validation Results\n",
        "        print(f\"Validation Accuracy (Patch, Before Muting): {accuracy_val_patch_before:.4f}\")\n",
        "        print(f\"Validation Accuracy (No Patch, Before Muting): {accuracy_val_no_patch_before:.4f}\")\n",
        "        print(f\"Validation Accuracy (Patch, After Muting): {accuracy_val_patch_after:.4f}\")\n",
        "        print(f\"Validation Accuracy (No Patch, After Muting): {accuracy_val_no_patch_after:.4f}\")\n",
        "\n",
        "############################################################################################################################################\n",
        "        # Test Phase\n",
        "        test_two_patch = np.load(test_activation_two_patch_paths, allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_activation_two_no_patch_paths, allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_activation_zero_patch_paths, allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_activation_zero_no_patch_paths, allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "        # Test classification before muting\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Load top neurons from validation\n",
        "        top_neurons = load_top_neurons_from_csv(folder_name, filename=f\"val_neuron_differences_seed_{seed}.csv\")\n",
        "\n",
        "        # Project test activations into sparse space\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "        #top_neuron_count = int(len(abs_diff) * 0.1)\n",
        "        #top_neurons = np.argsort(abs_diff)[-top_neuron_count:]\n",
        "\n",
        "        # Muting neurons in test data\n",
        "        top_neuron_count = int(len(top_neurons) * 0.1)  # Use top 10% neurons from validation\n",
        "        neurons_to_mute = top_neurons[:top_neuron_count]\n",
        "##???????????????????????????????????????\n",
        "        projected_two_test_patch[:, neurons_to_mute] = 0\n",
        "        projected_two_test_no_patch[:, neurons_to_mute] = 0\n",
        "        projected_zero_test_patch[:, neurons_to_mute] = 0\n",
        "        projected_zero_test_no_patch[:, neurons_to_mute] = 0\n",
        "\n",
        "\n",
        "        # Decode and classify test data\n",
        "        decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch).to(device).float()).cpu().detach().numpy()\n",
        "\n",
        "        # Classification\n",
        "        predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "        predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "        predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "        predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "        accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "        accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0]* len(predictions_test_zero_patch_after))\n",
        "        accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "        # Calculate Worst and Average Group Accuracies\n",
        "        worst_group_accuracy_before = min(accuracy_test_two_patch_before, accuracy_test_two_no_patch_before)\n",
        "        worst_group_accuracy_after = min(accuracy_test_two_patch_after, accuracy_test_two_no_patch_after)\n",
        "\n",
        "        avg_group_accuracy_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before + accuracy_test_zero_patch_before, accuracy_test_zero_no_patch_before ) / 4\n",
        "        avg_group_accuracy_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after + accuracy_test_zero_patch_after, accuracy_test_zero_no_patch_after) / 4\n",
        "\n",
        "        # Print Test Results\n",
        "        print(f\"Test Accuracy (Patch, Before Muting): {accuracy_test_two_patch_before:.4f}\")\n",
        "        print(f\"Test Accuracy (No Patch, Before Muting): {accuracy_test_two_no_patch_before:.4f}\")\n",
        "        print(f\"Test Accuracy (Patch, After Muting): {accuracy_test_zero_patch_after:.4f}\")\n",
        "        print(f\"Test Accuracy (No Patch, After Muting): {accuracy_test_zero_no_patch_after:.4f}\")\n",
        "        print(f\"Worst Group Accuracy (Before Muting): {worst_group_accuracy_before:.4f}\")\n",
        "        print(f\"Worst Group Accuracy (After Muting): {worst_group_accuracy_after:.4f}\")\n",
        "        print(f\"Average Group Accuracy (Before Muting): {avg_group_accuracy_before:.4f}\")\n",
        "        print(f\"Average Group Accuracy (After Muting): {avg_group_accuracy_after:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdg0GoLKAZw3"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "def identify_patch_specific_neurons(avg_activations_patch, avg_activations_no_patch, patch_threshold=0.2, no_patch_threshold=0.05):\n",
        "    \"\"\"\n",
        "    Identify neurons that are highly activated for patched images but not for non-patched ones.\n",
        "    \"\"\"\n",
        "    print(\"Identifying neurons selectively activated by patches...\")\n",
        "\n",
        "    # Calculate activation differences without normalization\n",
        "    high_patch_activation = avg_activations_patch > patch_threshold\n",
        "    low_no_patch_activation = avg_activations_no_patch < no_patch_threshold\n",
        "\n",
        "    # Select neurons that meet both criteria\n",
        "    patch_specific_neurons = np.where(high_patch_activation & low_no_patch_activation)[0]\n",
        "\n",
        "    # Debugging: Print some stats to understand what's happening\n",
        "    print(f\"Average activation for patch: {avg_activations_patch.mean():.4f}, No patch: {avg_activations_no_patch.mean():.4f}\")\n",
        "    print(f\"Number of neurons with high activation for patch: {(high_patch_activation).sum()}\")\n",
        "    print(f\"Number of neurons with low activation for no patch: {(low_no_patch_activation).sum()}\")\n",
        "    print(f\"Found {len(patch_specific_neurons)} patch-specific neurons.\")\n",
        "\n",
        "    return patch_specific_neurons\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        output = model.classifier[6](torch.from_numpy(activation).float().to(device))\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"wb_top_neurons.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Paths and initialization\n",
        "    model_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/models/initial_classifier/alexnet_wbw_lbl_lbw_11train.pt\"\n",
        "    autoencoder_paths = {\n",
        "        \"1\": '/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/activations/Autoencoders/wb_autoencoder_layer_17_seed_1_unnormalized.pth',\n",
        "        \"11\": '/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/activations/Autoencoders/wb_autoencoder_layer_17_seed_11_unnormalized.pth',\n",
        "        \"111\": '/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/activations/Autoencoders/wb_autoencoder_layer_17_seed_111_unnormalized.pth'\n",
        "    }\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load the AlexNet model\n",
        "    model = load_model(model_path, device)\n",
        "\n",
        "    # Define paths to pre-saved activations\n",
        "    activation_patch_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/activations/test_patch/wb_fc2_activations_patch.npy\"\n",
        "    activation_no_patch_path = \"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/activations/test_no_patch/wb_fc2_activations_no_patch.npy\"\n",
        "\n",
        "    # Load pre-saved activations\n",
        "    print(f\"Loading pre-saved AlexNet activations for fc2_activations_patch...\")\n",
        "    activations_patch = np.load(activation_patch_path, allow_pickle=True)\n",
        "    print(f\"Loading pre-saved AlexNet activations for fc2_activations_no_patch...\")\n",
        "    activations_no_patch = np.load(activation_no_patch_path, allow_pickle=True)\n",
        "\n",
        "    # Loop through each autoencoder\n",
        "    for seed, autoencoder_path in autoencoder_paths.items():\n",
        "        print(f\"\\nProcessing with Sparse Autoencoder (Seed {seed})...\")\n",
        "\n",
        "        # Load the autoencoder\n",
        "        autoencoder = load_autoencoder(autoencoder_path, device)\n",
        "\n",
        "        # Project activations into sparse space\n",
        "        projected_patch = project_activations(autoencoder, activations_patch, device)\n",
        "        projected_no_patch = project_activations(autoencoder, activations_no_patch, device)\n",
        "\n",
        "        # Decode the projected activations back to the original space\n",
        "        decoded_patch = autoencoder.decoder(torch.from_numpy(projected_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_no_patch = autoencoder.decoder(torch.from_numpy(projected_no_patch).to(device).float()).cpu().detach().numpy()\n",
        "\n",
        "        # Calculate the absolute differences between patch and no patch\n",
        "        avg_activations_patch = np.mean(projected_patch, axis=0)\n",
        "        avg_activations_no_patch = np.mean(projected_no_patch, axis=0)\n",
        "        abs_diff = np.abs(avg_activations_patch - avg_activations_no_patch)\n",
        "\n",
        "        # Identify the top 10% neurons with the highest differences\n",
        "        top_neuron_count = int(len(abs_diff) * 0.1)\n",
        "        top_neurons = np.argsort(abs_diff)[-top_neuron_count:]\n",
        "\n",
        "        # Classify 'wb_with_patch' without muting\n",
        "        print(\"Classifying 'wb_with_patch' without muting neurons...\")\n",
        "        predictions_patch_without_muting = classify_decoded_activations(model, decoded_patch)\n",
        "        accuracy_patch_without_muting = accuracy_score([1] * len(predictions_patch_without_muting), predictions_patch_without_muting)\n",
        "\n",
        "        # Mute the top neurons for 'wb_with_patch' and classify\n",
        "        projected_patch[:, top_neurons] = 0\n",
        "        decoded_patch_muted = autoencoder.decoder(torch.from_numpy(projected_patch).to(device).float()).cpu().detach().numpy()\n",
        "        predictions_patch_with_muting = classify_decoded_activations(model, decoded_patch_muted)\n",
        "        accuracy_patch_with_muting = accuracy_score([1] * len(predictions_patch_with_muting), predictions_patch_with_muting)\n",
        "\n",
        "        # Classify 'wb_no_patch' without muting\n",
        "        print(\"Classifying 'wb_no_patch' without muting neurons...\")\n",
        "        predictions_no_patch_without_muting = classify_decoded_activations(model, decoded_no_patch)\n",
        "        accuracy_no_patch_without_muting = accuracy_score([1] * len(predictions_no_patch_without_muting), predictions_no_patch_without_muting)\n",
        "\n",
        "        # Mute the top neurons for 'wb_no_patch' and classify\n",
        "        projected_no_patch[:, top_neurons] = 0\n",
        "        decoded_no_patch_muted = autoencoder.decoder(torch.from_numpy(projected_no_patch).to(device).float()).cpu().detach().numpy()\n",
        "        predictions_no_patch_with_muting = classify_decoded_activations(model, decoded_no_patch_muted)\n",
        "        accuracy_no_patch_with_muting = accuracy_score([1] * len(predictions_no_patch_with_muting), predictions_no_patch_with_muting)\n",
        "\n",
        "        # Save top neurons to CSV\n",
        "        csv_folder = f\"/content/drive/MyDrive/Masterthesis/Datasets/Waterbird/activations/difference_analysis_seed_{seed}\"\n",
        "        Path(csv_folder).mkdir(parents=True, exist_ok=True)\n",
        "        save_top_neurons_to_csv(abs_diff, top_neurons, csv_folder, filename=f\"wb_top_neurons_seed_{seed}.csv\")\n",
        "\n",
        "        # Print the results for this autoencoder\n",
        "        print(f\"\\nClassification Accuracy Results (Seed {seed}):\")\n",
        "        print(f\"1. Accuracy (waterbird land without muting): {accuracy_patch_without_muting:.4f}\")\n",
        "        print(f\"2. Accuracy (waterbird land with muting): {accuracy_patch_with_muting:.4f}\")\n",
        "        print(f\"3. Accuracy (waterbird water without muting): {accuracy_no_patch_without_muting:.4f}\")\n",
        "        print(f\"4. Accuracy (waterbird water with muting): {accuracy_no_patch_with_muting:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDfzrj34MmJ6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function 12 to classify decoded activations\n",
        "def classify_decoded_activations(model, decoded_activations):\n",
        "    \"\"\"Classify decoded activations using the softmax layer of the model.\"\"\"\n",
        "    predictions = []\n",
        "    for activation in decoded_activations:\n",
        "        # Convert numpy activation to a tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "\n",
        "        # Pass through classifier[5] (ReLU)\n",
        "        relu_output = model.classifier[5](activation_tensor)\n",
        "\n",
        "        # Pass through classifier[6] (final linear layer)\n",
        "        output = model.classifier[6](relu_output)\n",
        "\n",
        "        # Apply softmax and get the predicted class\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Project activations into sparse space\n",
        "def project_activations(autoencoder, activations, device):\n",
        "    print(\"Projecting Alexnet activations into SAE sparse space...\")\n",
        "    with torch.no_grad():\n",
        "        projected = autoencoder.encoder(torch.from_numpy(activations).to(device).float())\n",
        "    return projected.cpu().numpy()\n",
        "\n",
        "# Save all neuron differences and indexes in descending order\n",
        "def save_all_neurons_to_csv(abs_diff, folder_name, filename=\"all_neuron_differences.csv\"):\n",
        "    \"\"\"\n",
        "    Save all neuron indexes sorted by their differences (descending order) to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving all neuron differences to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": np.arange(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "    return csv_path # return the csv_path\n",
        "\n",
        "\n",
        "\n",
        "def save_top_neurons_to_csv(abs_diff, top_neurons, folder_name, filename=\"dlp_top_neurons.csv\"):\n",
        "    \"\"\"\n",
        "    Save the top neurons with their difference values to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Saving top neurons to CSV file: {filename}\")\n",
        "\n",
        "    # Create a DataFrame with neuron indices and their absolute differences\n",
        "    neuron_data = pd.DataFrame({\n",
        "        \"Neuron_Index\": range(len(abs_diff)),\n",
        "        \"Activation_Difference\": abs_diff\n",
        "    })\n",
        "\n",
        "    # Mark whether each neuron is in the top 10%\n",
        "    neuron_data[\"Selected_for_Muting\"] = neuron_data[\"Neuron_Index\"].isin(top_neurons)\n",
        "\n",
        "    # Sort by absolute difference in descending order\n",
        "    neuron_data.sort_values(by=\"Activation_Difference\", ascending=False, inplace=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data.to_csv(csv_path, index=False)\n",
        "    print(f\"CSV saved at: {csv_path}\")\n",
        "\n",
        "# Function to load top neurons from CSV based on a percentage\n",
        "def load_top_neurons_from_csv(folder_name, filename, percentage):\n",
        "    \"\"\"\n",
        "    Load top neurons based on the specified percentage from the saved CSV file.\n",
        "    \"\"\"\n",
        "    csv_path = os.path.join(folder_name, filename)\n",
        "    neuron_data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Calculate the number of top neurons to select\n",
        "    top_count = int(len(neuron_data) * (percentage / 100))\n",
        "\n",
        "    # Select the top neurons based on their activation difference\n",
        "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
        "    print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
        "    return top_neurons\n",
        "\n",
        "\n",
        "def classify_with_alexnet(model, activations):\n",
        "    \"\"\"\n",
        "    Classify images using the original AlexNet classifier on the fc2 activations.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for activation in activations:\n",
        "        # Convert numpy activation to tensor\n",
        "        activation_tensor = torch.from_numpy(activation).float().to(device)\n",
        "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
        "        output = model.classifier[6](relu_output)  # Apply fc3\n",
        "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Function to calculate accuracy per group\n",
        "def calculate_group_accuracy(predictions, true_labels):\n",
        "    return accuracy_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    seeds = [1, 11, 111]\n",
        "\n",
        "    # Paths to models, activations, and autoencoders for each seed\n",
        "    model_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/models/initial_classifier/alexnet_mnist_dlp_seed_{seed}.pt\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    autoencoder_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/Autoencoders/mnist_dlp/dlp_autoencoder_layer_fc2_seed_{seed}_unnormalized.pth\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_dlp/fc2_activations_test_two_dlp_alexnet_mnist_finetune_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_two_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_dlp/fc2_activations_test_two_org_alexnet_mnist_finetune_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_dlp/fc2_activations_test_zero_dlp_alexnet_mnist_finetune_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    test_activation_zero_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_dlp/fc2_activations_test_zero_org_alexnet_mnist_finetune_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_dlp/fc2_activations_val_zero_dlp_alexnet_mnist_finetune_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "    val_activation_no_patch_paths = [\n",
        "        f\"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/alexnet_mnist_finetune_dlp/fc2_activations_val_zero_org_alexnet_mnist_finetune_dlp_seed_{seed}.npy\"\n",
        "        for seed in seeds\n",
        "    ]\n",
        "\n",
        "    # Output folder for results\n",
        "    folder_name = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/alexnet_mnist_finetune_dlp\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Loop through seeds/models/autoencoders\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "\n",
        "        print(f\"\\nProcessing Seed {seed}\")\n",
        "        model_path = model_paths[seed_idx]\n",
        "        sae_path = autoencoder_paths[seed_idx]\n",
        "        val_patch_path = val_activation_patch_paths[seed_idx]\n",
        "        val_no_patch_path = val_activation_no_patch_paths[seed_idx]\n",
        "        test_two_patch_path = test_activation_two_patch_paths[seed_idx]\n",
        "        test_two_no_patch_path = test_activation_two_no_patch_paths[seed_idx]\n",
        "        test_zero_patch_path = test_activation_zero_patch_paths[seed_idx]\n",
        "        test_zero_no_patch_path = test_activation_zero_no_patch_paths[seed_idx]\n",
        "\n",
        "        print(f\"Model Path: {model_path}\")\n",
        "        print(f\"Autoencoder Path: {sae_path}\")\n",
        "        print(f\"Validation Patch Path: {val_patch_path}\")\n",
        "        print(f\"Validation No Patch Path: {val_no_patch_path}\")\n",
        "        print(f\"Test Two Patch Path: {test_two_patch_path}\")\n",
        "        print(f\"Test Two No Patch Path: {test_two_no_patch_path}\")\n",
        "        print(f\"Test Zero Patch Path: {test_zero_patch_path}\")\n",
        "        print(f\"Test Zero No Patch Path: {test_zero_no_patch_path}\")\n",
        "\n",
        "        # Load the model and autoencoder\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = load_model(model_path, device)\n",
        "        autoencoder = load_autoencoder(device, sae_path)\n",
        "\n",
        "        # Load pre-saved activations\n",
        "        val_activations_patch = np.load(val_patch_path, allow_pickle=True)\n",
        "        val_activations_no_patch = np.load(val_no_patch_path, allow_pickle=True)\n",
        "\n",
        "        # Direct classification using AlexNet\n",
        "        predictions_val_patch_alexnet = classify_with_alexnet(model, val_activations_patch)\n",
        "        accuracy_val_patch_alexnet = accuracy_score([0] * len(predictions_val_patch_alexnet), predictions_val_patch_alexnet)\n",
        "\n",
        "        predictions_val_no_patch_alexnet = classify_with_alexnet(model, val_activations_no_patch)\n",
        "        accuracy_no_patch_alexnet = accuracy_score([0] * len(predictions_val_no_patch_alexnet), predictions_val_no_patch_alexnet)\n",
        "\n",
        "        # Classification before muting\n",
        "        predictions_val_patch_before = classify_with_alexnet(model, val_activations_patch)\n",
        "        predictions_val_no_patch_before = classify_with_alexnet(model, val_activations_no_patch)\n",
        "\n",
        "        # Calculate validation accuracies before muting\n",
        "        accuracy_val_patch_before = calculate_group_accuracy(predictions_val_patch_before, [0] * len(predictions_val_patch_before))\n",
        "        accuracy_val_no_patch_before = calculate_group_accuracy(predictions_val_no_patch_before, [0] * len(predictions_val_no_patch_before))\n",
        "\n",
        "\n",
        "\n",
        "        # Project validation activations into sparse space\n",
        "        projected_val_patch = project_activations(autoencoder, val_activations_patch, device)\n",
        "        projected_val_no_patch = project_activations(autoencoder, val_activations_no_patch, device)\n",
        "\n",
        "        # Calculate differences and save neuron indexes\n",
        "        avg_val_patch = np.mean(projected_val_patch, axis=0)\n",
        "        avg_val_no_patch = np.mean(projected_val_no_patch, axis=0)\n",
        "        abs_diff = np.abs(avg_val_patch - avg_val_no_patch)\n",
        "        csv_path = save_all_neurons_to_csv(abs_diff, folder_name, filename=f\"val_neuron_differences_seed_{seed}.csv\")\n",
        "\n",
        "        csv_folder = \"/content/drive/MyDrive/Masterthesis/Datasets/mnist/activations/difference_analysis/alexnet_mnist_finetune_dlp\"\n",
        "        csv_filename = f\"val_neuron_differences_seed_{seed}.csv\"\n",
        "        neurons_to_mute = load_top_neurons_from_csv(csv_folder, filename=f\"val_neuron_differences_seed_{seed}.csv\", percentage = 3)\n",
        "        #neurons_to_mute = top_neurons[:int(len(top_neurons) * 0.1)]\n",
        "        projected_val_patch[:, neurons_to_mute] = 0\n",
        "        projected_val_no_patch[:, neurons_to_mute] = 0\n",
        "\n",
        "        decoded_val_patch = autoencoder.decoder(torch.from_numpy(projected_val_patch).to(device).float()).cpu().numpy()\n",
        "        decoded_val_no_patch = autoencoder.decoder(torch.from_numpy(projected_val_no_patch).to(device).float()).cpu().numpy()\n",
        "\n",
        "        predictions_val_patch_after = classify_decoded_activations(model, decoded_val_patch)\n",
        "        predictions_val_no_patch_after = classify_decoded_activations(model, decoded_val_no_patch)\n",
        "\n",
        "        accuracy_val_patch_after = calculate_group_accuracy(predictions_val_patch_after, [0] * len(predictions_val_patch_after))\n",
        "        accuracy_val_no_patch_after = calculate_group_accuracy(predictions_val_no_patch_after, [0] * len(predictions_val_no_patch_after))\n",
        "\n",
        "        # Print Validation Results\n",
        "        print(f\"Validation Accuracy (Patch, Before Muting): {accuracy_val_patch_before:.4f}\")\n",
        "        print(f\"Validation Accuracy (No Patch, Before Muting): {accuracy_val_no_patch_before:.4f}\")\n",
        "        print(f\"Validation Accuracy (Patch, After Muting): {accuracy_val_patch_after:.4f}\")\n",
        "        print(f\"Validation Accuracy (No Patch, After Muting): {accuracy_val_no_patch_after:.4f}\")\n",
        "\n",
        "############################################################################################################################################\n",
        "        # Test Phase\n",
        "        test_two_patch = np.load(test_activation_two_patch_paths[seed_idx], allow_pickle=True)\n",
        "        test_two_no_patch = np.load(test_activation_two_no_patch_paths[seed_idx], allow_pickle=True)\n",
        "        test_zero_patch = np.load(test_activation_zero_patch_paths[seed_idx], allow_pickle=True)\n",
        "        test_zero_no_patch = np.load(test_activation_zero_no_patch_paths[seed_idx], allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "        # Test classification before muting\n",
        "        predictions_test_two_patch_before = classify_with_alexnet(model, test_two_patch)\n",
        "        predictions_test_two_no_patch_before = classify_with_alexnet(model, test_two_no_patch)\n",
        "        predictions_test_zero_patch_before = classify_with_alexnet(model, test_zero_patch)\n",
        "        predictions_test_zero_no_patch_before = classify_with_alexnet(model, test_zero_no_patch)\n",
        "\n",
        "\n",
        "\n",
        "        accuracy_test_two_patch_before = calculate_group_accuracy(predictions_test_two_patch_before, [1] * len(predictions_test_two_patch_before))\n",
        "        accuracy_test_two_no_patch_before = calculate_group_accuracy(predictions_test_two_no_patch_before, [1] * len(predictions_test_two_no_patch_before))\n",
        "        accuracy_test_zero_patch_before = calculate_group_accuracy(predictions_test_zero_patch_before, [0] * len(predictions_test_zero_patch_before))\n",
        "        accuracy_test_zero_no_patch_before = calculate_group_accuracy(predictions_test_zero_no_patch_before, [0] * len(predictions_test_zero_no_patch_before))\n",
        "\n",
        "        # Load top neurons from validation\n",
        "        top_neurons = load_top_neurons_from_csv(csv_folder, filename=f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\", percentage=3)\n",
        "\n",
        "        # Project test activations into sparse space\n",
        "        projected_two_test_patch = project_activations(autoencoder, test_two_patch, device)\n",
        "        projected_two_test_no_patch = project_activations(autoencoder, test_two_no_patch, device)\n",
        "        projected_zero_test_patch = project_activations(autoencoder, test_zero_patch, device)\n",
        "        projected_zero_test_no_patch = project_activations(autoencoder, test_zero_no_patch, device)\n",
        "\n",
        "        #top_neuron_count = int(len(abs_diff) * 0.1)\n",
        "        #top_neurons = np.argsort(abs_diff)[-top_neuron_count:]\n",
        "\n",
        "        # Muting neurons in test data\n",
        "        percentage = 10\n",
        "        neurons_to_mute = load_top_neurons_from_csv(csv_folder, filename=f\"mnist_dlp_val_neuron_differences_seed_{seed}.csv\", percentage = 3)\n",
        "        projected_two_test_patch[:, neurons_to_mute] = 0\n",
        "        projected_two_test_no_patch[:, neurons_to_mute] = 0\n",
        "        projected_zero_test_patch[:, neurons_to_mute] = 0\n",
        "        projected_zero_test_no_patch[:, neurons_to_mute] = 0\n",
        "\n",
        "\n",
        "        # Decode and classify test data\n",
        "        decoded_two_test_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_two_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_two_test_no_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_zero_test_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_patch).to(device).float()).cpu().detach().numpy()\n",
        "        decoded_zero_test_no_patch = autoencoder.decoder(torch.from_numpy(projected_zero_test_no_patch).to(device).float()).cpu().detach().numpy()\n",
        "\n",
        "        # Classification\n",
        "        predictions_test_two_patch_after = classify_decoded_activations(model, decoded_two_test_patch)\n",
        "        predictions_test_two_no_patch_after = classify_decoded_activations(model, decoded_two_test_no_patch)\n",
        "        predictions_test_zero_patch_after = classify_decoded_activations(model, decoded_zero_test_patch)\n",
        "        predictions_test_zero_no_patch_after = classify_decoded_activations(model, decoded_zero_test_no_patch)\n",
        "\n",
        "        accuracy_test_two_patch_after = calculate_group_accuracy(predictions_test_two_patch_after, [1] * len(predictions_test_two_patch_after))\n",
        "        accuracy_test_two_no_patch_after = calculate_group_accuracy(predictions_test_two_no_patch_after, [1] * len(predictions_test_two_no_patch_after))\n",
        "        accuracy_test_zero_patch_after = calculate_group_accuracy(predictions_test_zero_patch_after, [0]* len(predictions_test_zero_patch_after))\n",
        "        accuracy_test_zero_no_patch_after = calculate_group_accuracy(predictions_test_zero_no_patch_after, [0] * len(predictions_test_zero_no_patch_after))\n",
        "\n",
        "        # Calculate Worst and Average Group Accuracies\n",
        "        worst_group_accuracy_before = accuracy_test_two_patch_before\n",
        "        worst_group_accuracy_after = accuracy_test_two_patch_after\n",
        "\n",
        "        # Calculate the average group accuracy correctly by dividing the sum of accuracies by 4\n",
        "        avg_group_accuracy_before = (accuracy_test_two_patch_before + accuracy_test_two_no_patch_before + accuracy_test_zero_patch_before + accuracy_test_zero_no_patch_before) / 4\n",
        "        avg_group_accuracy_after = (accuracy_test_two_patch_after + accuracy_test_two_no_patch_after + accuracy_test_zero_patch_after + accuracy_test_zero_no_patch_after) / 4\n",
        "        # Print Test Results\n",
        "        print(f\"Test Accuracy (Patch, Before Muting): {accuracy_test_two_patch_before:.4f}\")\n",
        "        print(f\"Test Accuracy (No Patch, Before Muting): {accuracy_test_two_no_patch_before:.4f}\")\n",
        "        print(f\"Test Accuracy (Patch, After Muting): {accuracy_test_zero_patch_after:.4f}\")\n",
        "        print(f\"Test Accuracy (No Patch, After Muting): {accuracy_test_zero_no_patch_after:.4f}\")\n",
        "        print(f\"Worst Group Accuracy (Before Muting): {worst_group_accuracy_before:.4f}\")\n",
        "        print(f\"Worst Group Accuracy (After Muting): {worst_group_accuracy_after:.4f}\")\n",
        "        print(f\"Average Group Accuracy (Before Muting): {avg_group_accuracy_before:.4f}\")\n",
        "        print(f\"Average Group Accuracy (After Muting): {avg_group_accuracy_after:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-I1fCyvQ2cBS",
        "MTQFMi9IDTOm"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}